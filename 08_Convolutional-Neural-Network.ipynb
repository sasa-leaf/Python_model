{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766447c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f7cce",
   "metadata": {},
   "source": [
    "# 畳み込みニューラルネットワーク（CNN）とは"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a402480c",
   "metadata": {},
   "source": [
    "- 全結合ニューラルネットワーク 「Affine - ReLU」\n",
    ">1. Affineレイヤ（**全結合層**）\n",
    ">2. 隣接する全てのニューロン間で結合がある（fully-connected）\n",
    ">3. データの形に関わらず、1次元に変形するため、データ形状に関する、空間的な情報を生かすことができない。<br><br>\n",
    "- CNN 「Convolution - ReLU - （Pooling）」\n",
    ">1. Convolutionレイヤ（**畳み込み層**）、Poolingレイヤ（**プーリング層**）\n",
    ">2. 出力層に近いところは「Affine - ReLU」、出力層は「Affine - Softmax」\n",
    ">3. **画像**などの形状があるデータを正しく理解できる可能性がある"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b571db",
   "metadata": {},
   "source": [
    "![](image/08_cnn.png)\n",
    "上段：全結合層によるニューラルネットワーク、下段：CNNによるニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183fd3a2",
   "metadata": {},
   "source": [
    "# 畳み込み層"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ad49f",
   "metadata": {},
   "source": [
    "畳み込み層の入出力データを**特徴マップ**（**feature map**）、入力データを**入力特徴マップ**（**input feature map**）、出力データを**出力特徴マップ**（**output feature map**）という"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66a9ff6",
   "metadata": {},
   "source": [
    "## 2次元畳み込み演算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34906a0c",
   "metadata": {},
   "source": [
    "Cocvolutionレイヤ（畳み込み層）では、画像処理のフィルター演算に相当する「**畳み込み演算**」を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb57791",
   "metadata": {},
   "source": [
    "![](image/08_convolution.png)\n",
    "1. ウィンドウ（赤四角）内のそれぞれの場所で、フィルター（カーネル）の要素と入力の対応する要素を乗算\n",
    "2. 和を求める（1と2をまとめて**積和演算**という）\n",
    "3. ウィンドウを一定間隔でスライドさせ、同様に計算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf2c3e8",
   "metadata": {},
   "source": [
    "### パディング・ストライド"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c78836",
   "metadata": {},
   "source": [
    "ゼロパディング：主に出力サイズ調整のため、周囲を任意幅のピクセルの0で埋める<br>\n",
    "ストライド：フィルタを適用する位置の間隔"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d6138",
   "metadata": {},
   "source": [
    "![](image/08_padding-stride.png)\n",
    "これは、パディング幅1、ストライド2の例。<br>\n",
    "基本的に、出力データは進むにつれて小さくなっていくので、パディングによりサイズを大きくするなどする。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683794e1",
   "metadata": {},
   "source": [
    "### サイズの関係"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3deeec6",
   "metadata": {},
   "source": [
    "$$OH=\\dfrac{H+2P-FH}{S}+1$$\n",
    "\n",
    "$$OW=\\dfrac{W+2P-FW}{S}+1$$\n",
    "\n",
    "入力サイズ$(H,W)$　フィルターサイズ$(FH,FW)$　出力サイズ$(OH,OW)$　パディング$P$　ストライド$S$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ca381f",
   "metadata": {},
   "source": [
    "$OH$、$OW$は自然数の値になるようにパディングやストライドを調整する必要がある。<br>\n",
    "ディープラーニングの場合、自然数値を取らない時は、最も近い整数に丸めて先へ進む場合がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969083a0",
   "metadata": {},
   "source": [
    "## 3次元畳み込み演算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68524d55",
   "metadata": {},
   "source": [
    "![](image/08_3d-convolution.png)\n",
    "チャンネル方向に特徴マップが増えた。ブロックで表すとわかりやすい。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3ea7e",
   "metadata": {},
   "source": [
    "### バッチ処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f6a1e",
   "metadata": {},
   "source": [
    "![](image/08_batch-processing.png)\n",
    "畳み込み演算でも、N個のデータをまとめて与えてバッチ処理ができる。CNNでは、4次元のデータが流れる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a4b1f",
   "metadata": {},
   "source": [
    "# プーリング層"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0345fb1",
   "metadata": {},
   "source": [
    "プーリングは、縦・横方向の空間を小さくする演算。<br>\n",
    "対象領域から最大値をとるMaxプーリング、平均値をとるAverageプーリングなどがある。<br>\n",
    "一般に、ウィンドウサイズとストライドは同じ値に設定する。\n",
    "- **学習パラメータがない**（最大値もしくは平均値を取るだけなどの処理）\n",
    "- **チャンネル数は変化しない**（チャンネルごとに独立して計算）\n",
    "- **微小な位置変化にロバスト（頑健）**（入力値の小さなズレに対し、同じような結果を返す）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ba0f3f",
   "metadata": {},
   "source": [
    "![](image/08_max-pooling.png)\n",
    "ストライド3で３×３のMaxプーリング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e7e60",
   "metadata": {},
   "source": [
    "# レイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a40dcd",
   "metadata": {},
   "source": [
    "## `im2col`データ展開"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e804e0",
   "metadata": {},
   "source": [
    "- `im2col`はバッチも含めた4次元データを2次元に変換する。\n",
    "- `Numpy`で`for`文を使うと処理が遅くなるため、フィルター（重み）にとって都合の良いように入力データ展開をする`im2col`を利用する。\n",
    "- メモリを多く消費するが、線形代数ライブラリを有効活用できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edfe9b4",
   "metadata": {},
   "source": [
    "![](image/08_im2col.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda4b8f4",
   "metadata": {},
   "source": [
    "`im2col`によって変換した2次元データと、一列に展開した重みの行列計算をする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783405d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e351d4d",
   "metadata": {},
   "source": [
    "また、レイヤの逆伝播の際には`im2col`の逆の操作が必要であるため、`col2im`を以下で実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1d2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667d569f",
   "metadata": {},
   "source": [
    "## Convolutionレイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c206484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 中間データ（backward時に使用）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 重み・バイアスパラメータの勾配\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T # フィルターの展開\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8035ca4f",
   "metadata": {},
   "source": [
    "**`reshape(xx, -1)`**\n",
    "- 多次元配列の辻褄が合うようにまとまる\n",
    "\n",
    "**`transpose()`**\n",
    "- 0から始まるインデックスを指定すると、多次元配列の順番の軸を入れ替える"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee4cff",
   "metadata": {},
   "source": [
    "## Poolingレイヤ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad71afdd",
   "metadata": {},
   "source": [
    "![画像を表示できません。](image/08_im2col-reshape.png)\n",
    "`im2col`でデータを展開し、展開した行列に対し、行ごとに最大値を求め、適切な形状に変形する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275e0a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=2, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c639af",
   "metadata": {},
   "source": [
    "# CNNの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3235d",
   "metadata": {},
   "source": [
    "「Convolution - ReLU - Pooling - Affine - ReLU - Affine - Softmax」の構成のCNNを実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8cf4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from source.common01.layers import *\n",
    "from source.common01.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"\n",
    "    input_size : 入力サイズ（MNISTの場合は784）\n",
    "    hidden_size_list : 隠れ層のニューロンの数のリスト（e.g. [100, 100, 100]）\n",
    "    output_size : 出力サイズ（MNISTの場合は10）\n",
    "    activation : 'relu' or 'sigmoid'\n",
    "    weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n",
    "        'relu'または'he'を指定した場合は「Heの初期値」を設定\n",
    "        'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"損失関数を求める\n",
    "        引数のxは入力データ、tは教師ラベル\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（数値微分）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（誤差逆伝搬法）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"pickle/cnn_params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"pickle/cnn_params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb8bc02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2998645313178936\n",
      "=== epoch:1, train acc:0.117, test acc:0.165 ===\n",
      "train loss:2.2980388353162806\n",
      "train loss:2.2922844191931735\n",
      "train loss:2.284460929955969\n",
      "train loss:2.2701891768511953\n",
      "train loss:2.274494583304696\n",
      "train loss:2.2382389500646487\n",
      "train loss:2.2328418317090604\n",
      "train loss:2.244962082080329\n",
      "train loss:2.170468518919479\n",
      "train loss:2.1523984383122614\n",
      "train loss:2.1683184409618765\n",
      "train loss:2.076912060550911\n",
      "train loss:2.047503326256887\n",
      "train loss:1.9935953630708227\n",
      "train loss:1.9801291063027735\n",
      "train loss:1.8734957274912816\n",
      "train loss:1.7652407946340198\n",
      "train loss:1.6280684845448652\n",
      "train loss:1.6810002095241847\n",
      "train loss:1.5958539514008239\n",
      "train loss:1.596866404592111\n",
      "train loss:1.4948912048113254\n",
      "train loss:1.294579427422219\n",
      "train loss:1.2823307859757733\n",
      "train loss:1.2454139338447066\n",
      "train loss:1.263909249294536\n",
      "train loss:1.0399375951043084\n",
      "train loss:1.0160711646973688\n",
      "train loss:0.9882513309420677\n",
      "train loss:0.935081878776311\n",
      "train loss:0.9015274053599956\n",
      "train loss:0.8068968415439062\n",
      "train loss:0.7839271418299982\n",
      "train loss:0.8134294817011307\n",
      "train loss:0.5525713194115905\n",
      "train loss:0.6797347275158748\n",
      "train loss:0.6497655693871255\n",
      "train loss:0.6070719044549272\n",
      "train loss:0.6709288913352534\n",
      "train loss:0.6924907571066253\n",
      "train loss:0.6429793142621159\n",
      "train loss:0.5538654950699978\n",
      "train loss:0.7162085719277539\n",
      "train loss:0.6086895137905618\n",
      "train loss:0.7723131352473497\n",
      "train loss:0.502868965036875\n",
      "train loss:0.4649323074078533\n",
      "train loss:0.6087229262052679\n",
      "train loss:0.4752679766787446\n",
      "train loss:0.45934632236296674\n",
      "train loss:0.48490905259480355\n",
      "train loss:0.5440993615674767\n",
      "train loss:0.5645466371298267\n",
      "train loss:0.630972019325214\n",
      "train loss:0.49055484645761893\n",
      "train loss:0.48420877524056655\n",
      "train loss:0.418020804367809\n",
      "train loss:0.544740599610972\n",
      "train loss:0.633981738419585\n",
      "train loss:0.8142259263721803\n",
      "train loss:0.5403785145988291\n",
      "train loss:0.3901597279493804\n",
      "train loss:0.4066346890042204\n",
      "train loss:0.5567221373764134\n",
      "train loss:0.43847625768563886\n",
      "train loss:0.5354112782916745\n",
      "train loss:0.35342553255377696\n",
      "train loss:0.2487652500760576\n",
      "train loss:0.5216925875010456\n",
      "train loss:0.358410256768002\n",
      "train loss:0.41006050874452477\n",
      "train loss:0.3739102532941033\n",
      "train loss:0.481856254032104\n",
      "train loss:0.40688573155131125\n",
      "train loss:0.48652693097178434\n",
      "train loss:0.40688454507545396\n",
      "train loss:0.24809601390573882\n",
      "train loss:0.2770372300513403\n",
      "train loss:0.33585402294753663\n",
      "train loss:0.4147046501964224\n",
      "train loss:0.3831116920918508\n",
      "train loss:0.3177246963950342\n",
      "train loss:0.2595262746441155\n",
      "train loss:0.35605934112939425\n",
      "train loss:0.32148930201746273\n",
      "train loss:0.4631470365551904\n",
      "train loss:0.32246383311613\n",
      "train loss:0.32269316387301294\n",
      "train loss:0.38936621901327684\n",
      "train loss:0.41372039196090055\n",
      "train loss:0.3781418018096928\n",
      "train loss:0.6955814130518364\n",
      "train loss:0.6251972778639049\n",
      "train loss:0.3395808144747205\n",
      "train loss:0.42379922229158207\n",
      "train loss:0.3807896020163264\n",
      "train loss:0.41758571542193595\n",
      "train loss:0.3804462454075366\n",
      "train loss:0.22590111128230123\n",
      "train loss:0.2506280862359396\n",
      "train loss:0.2398484988847234\n",
      "train loss:0.41564058547597327\n",
      "train loss:0.37695478064551247\n",
      "train loss:0.32046784473119794\n",
      "train loss:0.30188270283839086\n",
      "train loss:0.3106175749634484\n",
      "train loss:0.33359065555576123\n",
      "train loss:0.3465382644395712\n",
      "train loss:0.25032737478909367\n",
      "train loss:0.3869038757791556\n",
      "train loss:0.33246591179824264\n",
      "train loss:0.45240940901904914\n",
      "train loss:0.49519323273971116\n",
      "train loss:0.21641343232404392\n",
      "train loss:0.3624698869015355\n",
      "train loss:0.4584383518793381\n",
      "train loss:0.31723461817335047\n",
      "train loss:0.44532962422479555\n",
      "train loss:0.3106426868957509\n",
      "train loss:0.27155776457492753\n",
      "train loss:0.35380168109129634\n",
      "train loss:0.4175660854677996\n",
      "train loss:0.5386752160522043\n",
      "train loss:0.32721252049471844\n",
      "train loss:0.33671723789324937\n",
      "train loss:0.24899087777254064\n",
      "train loss:0.32710039349919057\n",
      "train loss:0.2148841842172792\n",
      "train loss:0.3044133342506095\n",
      "train loss:0.2973654451407148\n",
      "train loss:0.3085370012183093\n",
      "train loss:0.2931233469935939\n",
      "train loss:0.3622535688207978\n",
      "train loss:0.34958305929360634\n",
      "train loss:0.24898425040839683\n",
      "train loss:0.30568583712924097\n",
      "train loss:0.22305467158888187\n",
      "train loss:0.2726662734397406\n",
      "train loss:0.28772482743113764\n",
      "train loss:0.1975749320204277\n",
      "train loss:0.35320407204386306\n",
      "train loss:0.3274053464196337\n",
      "train loss:0.4005497884270004\n",
      "train loss:0.42301525576151855\n",
      "train loss:0.2784362684045381\n",
      "train loss:0.2764393678060814\n",
      "train loss:0.40788701507776315\n",
      "train loss:0.2593296996254789\n",
      "train loss:0.2793646005527949\n",
      "train loss:0.24607120434634835\n",
      "train loss:0.3285925379886614\n",
      "train loss:0.4125320813072615\n",
      "train loss:0.26935379596409836\n",
      "train loss:0.21780486968184098\n",
      "train loss:0.3172839848009103\n",
      "train loss:0.25773437297116164\n",
      "train loss:0.22024906650259354\n",
      "train loss:0.29702714452718565\n",
      "train loss:0.2917855712445936\n",
      "train loss:0.21236933343183942\n",
      "train loss:0.37261131918274615\n",
      "train loss:0.46091699036303313\n",
      "train loss:0.2012232550693165\n",
      "train loss:0.3336176033969352\n",
      "train loss:0.25105324440940296\n",
      "train loss:0.43461620925042915\n",
      "train loss:0.2654155691156231\n",
      "train loss:0.36381353193973953\n",
      "train loss:0.20320365570577517\n",
      "train loss:0.33436998410509966\n",
      "train loss:0.2604885584630937\n",
      "train loss:0.3034415030394835\n",
      "train loss:0.2634556632248051\n",
      "train loss:0.4798114831138813\n",
      "train loss:0.2206271563065122\n",
      "train loss:0.3474940822871195\n",
      "train loss:0.48641460325812813\n",
      "train loss:0.22147074455809113\n",
      "train loss:0.26582325635336124\n",
      "train loss:0.27339759076250764\n",
      "train loss:0.33302583486999837\n",
      "train loss:0.2949959585106435\n",
      "train loss:0.26998350816957467\n",
      "train loss:0.4677292238437133\n",
      "train loss:0.39223946267682147\n",
      "train loss:0.215784878753889\n",
      "train loss:0.19874044862022092\n",
      "train loss:0.37785193282811486\n",
      "train loss:0.26666497494330793\n",
      "train loss:0.29654871570069913\n",
      "train loss:0.3003104883455341\n",
      "train loss:0.2222025006849518\n",
      "train loss:0.21601255790907342\n",
      "train loss:0.2236051715272657\n",
      "train loss:0.20325764970910598\n",
      "train loss:0.265732743798601\n",
      "train loss:0.3768899851573692\n",
      "train loss:0.19886932198078847\n",
      "train loss:0.26376925493887454\n",
      "train loss:0.17100669890278347\n",
      "train loss:0.20609941613396882\n",
      "train loss:0.2926911828662173\n",
      "train loss:0.4260763565693476\n",
      "train loss:0.299574786768505\n",
      "train loss:0.2733096460220408\n",
      "train loss:0.22331403346468878\n",
      "train loss:0.16592225033537866\n",
      "train loss:0.2497906850170177\n",
      "train loss:0.25437525837906944\n",
      "train loss:0.291599031931251\n",
      "train loss:0.23715850286298912\n",
      "train loss:0.30339809196211354\n",
      "train loss:0.22038665315080583\n",
      "train loss:0.34798692125057784\n",
      "train loss:0.21890854204653237\n",
      "train loss:0.23459509212583948\n",
      "train loss:0.18819601795317528\n",
      "train loss:0.2174931442296488\n",
      "train loss:0.23856788082108085\n",
      "train loss:0.2692642173435508\n",
      "train loss:0.2789585751985057\n",
      "train loss:0.26109555653011546\n",
      "train loss:0.3293522926344635\n",
      "train loss:0.17590631599947565\n",
      "train loss:0.3036542342351728\n",
      "train loss:0.22207355018301697\n",
      "train loss:0.21192814598222653\n",
      "train loss:0.16935664515754442\n",
      "train loss:0.15649867990222122\n",
      "train loss:0.25775528860072777\n",
      "train loss:0.3388042624256129\n",
      "train loss:0.40903760181803855\n",
      "train loss:0.30931541841931975\n",
      "train loss:0.20696344140308864\n",
      "train loss:0.2761227887913574\n",
      "train loss:0.2845680105977223\n",
      "train loss:0.169717840209987\n",
      "train loss:0.16497244230254304\n",
      "train loss:0.2971832365448009\n",
      "train loss:0.36106240381858745\n",
      "train loss:0.31510964231705535\n",
      "train loss:0.19800488834040444\n",
      "train loss:0.29654900018762953\n",
      "train loss:0.3993450792267271\n",
      "train loss:0.2725602107536712\n",
      "train loss:0.17520042407458067\n",
      "train loss:0.30115638283747187\n",
      "train loss:0.18133705441560188\n",
      "train loss:0.29109093093213145\n",
      "train loss:0.2788776850151386\n",
      "train loss:0.4015391915937939\n",
      "train loss:0.1677766819709189\n",
      "train loss:0.22199013344062166\n",
      "train loss:0.27393234451462584\n",
      "train loss:0.31824947859308333\n",
      "train loss:0.34752822198288313\n",
      "train loss:0.1893773506406281\n",
      "train loss:0.2524740774860178\n",
      "train loss:0.16453483648272532\n",
      "train loss:0.2440815670402816\n",
      "train loss:0.19173330038843817\n",
      "train loss:0.34553581941155787\n",
      "train loss:0.20139481759503305\n",
      "train loss:0.19755451593381093\n",
      "train loss:0.11054673010266881\n",
      "train loss:0.3220873528753883\n",
      "train loss:0.1959447828124376\n",
      "train loss:0.19314609032819421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.14128850264111337\n",
      "train loss:0.41144510230525294\n",
      "train loss:0.1769497335921153\n",
      "train loss:0.3718404516642825\n",
      "train loss:0.19002296412414654\n",
      "train loss:0.3562261374590143\n",
      "train loss:0.238142998088318\n",
      "train loss:0.2162933543398559\n",
      "train loss:0.20070655847050156\n",
      "train loss:0.21812318951460127\n",
      "train loss:0.08964038783679971\n",
      "train loss:0.22972384389826206\n",
      "train loss:0.12055078832990876\n",
      "train loss:0.2259040806261028\n",
      "train loss:0.37949901330441677\n",
      "train loss:0.20465393588855574\n",
      "train loss:0.3329992389390914\n",
      "train loss:0.16265478965644942\n",
      "train loss:0.17825486677636676\n",
      "train loss:0.19907855454776757\n",
      "train loss:0.31081276708574695\n",
      "train loss:0.16065864100021163\n",
      "train loss:0.3048969322337976\n",
      "train loss:0.16388525593672554\n",
      "train loss:0.15900494091964867\n",
      "train loss:0.24541791711915237\n",
      "train loss:0.16072976572746167\n",
      "train loss:0.1951588206538475\n",
      "train loss:0.13518013489057462\n",
      "train loss:0.1858051378637796\n",
      "train loss:0.11134324876462261\n",
      "train loss:0.32441690177156873\n",
      "train loss:0.24407558648803132\n",
      "train loss:0.1403657731750625\n",
      "train loss:0.21200082861089706\n",
      "train loss:0.14926370236928607\n",
      "train loss:0.14892436425151268\n",
      "train loss:0.1416330483609728\n",
      "train loss:0.1976202432096498\n",
      "train loss:0.1641047857352788\n",
      "train loss:0.11996602127236437\n",
      "train loss:0.13870212042961236\n",
      "train loss:0.2347801537756208\n",
      "train loss:0.21845075320945637\n",
      "train loss:0.13949582339120858\n",
      "train loss:0.17418037556904967\n",
      "train loss:0.1507079005660704\n",
      "train loss:0.16883292064683636\n",
      "train loss:0.20060778914308897\n",
      "train loss:0.18272747865172667\n",
      "train loss:0.28073048146936036\n",
      "train loss:0.28983644736335284\n",
      "train loss:0.19915467742363624\n",
      "train loss:0.12383136778042153\n",
      "train loss:0.12638328713106403\n",
      "train loss:0.1338302710489934\n",
      "train loss:0.16994280498657663\n",
      "train loss:0.18604221249312292\n",
      "train loss:0.22789750920515092\n",
      "train loss:0.35346031048836823\n",
      "train loss:0.09737037513184812\n",
      "train loss:0.21293947994883175\n",
      "train loss:0.12650516826562053\n",
      "train loss:0.26885789529625526\n",
      "train loss:0.16614124520440718\n",
      "train loss:0.07537558557556598\n",
      "train loss:0.21387355961680804\n",
      "train loss:0.2376972451419154\n",
      "train loss:0.23635170045991863\n",
      "train loss:0.12857138215695854\n",
      "train loss:0.10691188061124052\n",
      "train loss:0.22122277939458518\n",
      "train loss:0.15465889959301063\n",
      "train loss:0.10176311856623448\n",
      "train loss:0.19179540954137583\n",
      "train loss:0.31333453565156577\n",
      "train loss:0.23146888306931654\n",
      "train loss:0.1298722105200353\n",
      "train loss:0.2028152173913752\n",
      "train loss:0.4421778990635452\n",
      "train loss:0.20610670460677183\n",
      "train loss:0.06509866937938255\n",
      "train loss:0.16168023249251465\n",
      "train loss:0.17133390629473627\n",
      "train loss:0.12915308480676513\n",
      "train loss:0.26333856221654084\n",
      "train loss:0.2914976701125117\n",
      "train loss:0.17835951747581663\n",
      "train loss:0.24028363720075174\n",
      "train loss:0.16707771883414793\n",
      "train loss:0.33221061224488607\n",
      "train loss:0.10247359759598325\n",
      "train loss:0.2295013713841004\n",
      "train loss:0.19671644391212356\n",
      "train loss:0.13721425826506028\n",
      "train loss:0.16963803929831278\n",
      "train loss:0.1989949291063162\n",
      "train loss:0.2615895734230536\n",
      "train loss:0.23872513641163942\n",
      "train loss:0.16056628972201747\n",
      "train loss:0.2019466128603242\n",
      "train loss:0.17819544266191023\n",
      "train loss:0.09956934048812766\n",
      "train loss:0.3663293345582838\n",
      "train loss:0.22207487977010487\n",
      "train loss:0.21846674600380542\n",
      "train loss:0.20763783836915953\n",
      "train loss:0.2776209079910339\n",
      "train loss:0.22551658693838791\n",
      "train loss:0.1113391623465411\n",
      "train loss:0.12137645203952502\n",
      "train loss:0.08742493622711098\n",
      "train loss:0.1378817688953772\n",
      "train loss:0.26910486743060397\n",
      "train loss:0.18203584169020728\n",
      "train loss:0.1789887299740508\n",
      "train loss:0.12741225123953762\n",
      "train loss:0.34069874309937503\n",
      "train loss:0.21731992149573678\n",
      "train loss:0.17150675537058954\n",
      "train loss:0.1167384244825263\n",
      "train loss:0.15282657314337128\n",
      "train loss:0.10741075213235327\n",
      "train loss:0.15422157433010805\n",
      "train loss:0.1442266052645566\n",
      "train loss:0.09982064910259142\n",
      "train loss:0.15430621076310527\n",
      "train loss:0.22365880618489448\n",
      "train loss:0.08386069106938082\n",
      "train loss:0.2104400644026656\n",
      "train loss:0.22064817960873767\n",
      "train loss:0.11149128414531523\n",
      "train loss:0.1255559953756304\n",
      "train loss:0.15788302394738848\n",
      "train loss:0.13606142047537195\n",
      "train loss:0.1904367127650836\n",
      "train loss:0.21182776284520827\n",
      "train loss:0.12687155725904314\n",
      "train loss:0.19346429715508595\n",
      "train loss:0.3015061633948966\n",
      "train loss:0.12020047095663257\n",
      "train loss:0.14008117860255076\n",
      "train loss:0.19702081544518651\n",
      "train loss:0.15846788835156012\n",
      "train loss:0.07419983755812236\n",
      "train loss:0.18696863517310594\n",
      "train loss:0.09836595746682077\n",
      "train loss:0.2608422201936561\n",
      "train loss:0.13768024635038423\n",
      "train loss:0.09486408621354289\n",
      "train loss:0.12585591362026433\n",
      "train loss:0.1081333602771986\n",
      "train loss:0.150916512056564\n",
      "train loss:0.2492249725756086\n",
      "train loss:0.269675301187543\n",
      "train loss:0.20785408232434915\n",
      "train loss:0.12763426823491275\n",
      "train loss:0.1722816556522921\n",
      "train loss:0.19455420702906337\n",
      "train loss:0.26634216700982816\n",
      "train loss:0.1138688265665762\n",
      "train loss:0.11478878960100902\n",
      "train loss:0.1561396624535632\n",
      "train loss:0.13655825362534665\n",
      "train loss:0.07366483791098682\n",
      "train loss:0.14822230018373772\n",
      "train loss:0.13810757862938228\n",
      "train loss:0.08567116163379149\n",
      "train loss:0.08806338487836243\n",
      "train loss:0.22816380049443982\n",
      "train loss:0.14740567045860029\n",
      "train loss:0.14734208655653297\n",
      "train loss:0.210205136626835\n",
      "train loss:0.13086584074923535\n",
      "train loss:0.17976077895888878\n",
      "train loss:0.22132456673042125\n",
      "train loss:0.2165739426359714\n",
      "train loss:0.16534281575416884\n",
      "train loss:0.10794535938943853\n",
      "train loss:0.16147644159623326\n",
      "train loss:0.11707430570361282\n",
      "train loss:0.2062958685462578\n",
      "train loss:0.10885919190414718\n",
      "train loss:0.08929980866337987\n",
      "train loss:0.1610277337543423\n",
      "train loss:0.226090161434217\n",
      "train loss:0.2210218930338406\n",
      "train loss:0.1269335598811571\n",
      "train loss:0.12038750213894218\n",
      "train loss:0.27752537888394113\n",
      "train loss:0.12824745833801898\n",
      "train loss:0.12310032379453245\n",
      "train loss:0.07364166491916806\n",
      "train loss:0.12612813845378437\n",
      "train loss:0.07456287149304909\n",
      "train loss:0.2608602078140599\n",
      "train loss:0.24335152716052985\n",
      "train loss:0.2585717473244081\n",
      "train loss:0.08150456610069316\n",
      "train loss:0.07200186492823286\n",
      "train loss:0.12053994403181671\n",
      "train loss:0.09375190097615793\n",
      "train loss:0.19425799778798528\n",
      "train loss:0.20071250495539622\n",
      "train loss:0.19490999156509084\n",
      "train loss:0.22666899150193057\n",
      "train loss:0.11318238298295277\n",
      "train loss:0.2201988529308453\n",
      "train loss:0.11556731164927586\n",
      "train loss:0.11994010607917145\n",
      "train loss:0.20562189895747557\n",
      "train loss:0.12230297663198816\n",
      "train loss:0.09929960671971667\n",
      "train loss:0.1906211594669875\n",
      "train loss:0.19163748774220626\n",
      "train loss:0.17731978874228865\n",
      "train loss:0.11423478727539292\n",
      "train loss:0.1294529279320514\n",
      "train loss:0.14196909391936413\n",
      "train loss:0.13454509469772633\n",
      "train loss:0.1179472576063834\n",
      "train loss:0.08093969886243675\n",
      "train loss:0.11757914516140597\n",
      "train loss:0.15024729332426773\n",
      "train loss:0.13705522942352844\n",
      "train loss:0.11768078296485776\n",
      "train loss:0.14998053292217142\n",
      "train loss:0.18807377595203603\n",
      "train loss:0.256451196178587\n",
      "train loss:0.09519272561674674\n",
      "train loss:0.14150333201872362\n",
      "train loss:0.09607613704068779\n",
      "train loss:0.16624496926405277\n",
      "train loss:0.20432868836761017\n",
      "train loss:0.10316716831298496\n",
      "train loss:0.14343839659226992\n",
      "train loss:0.10169981311232118\n",
      "train loss:0.09621366273783005\n",
      "train loss:0.15325145185711408\n",
      "train loss:0.05660482275895504\n",
      "train loss:0.06194619317661866\n",
      "train loss:0.22036395217720434\n",
      "train loss:0.06017928140289875\n",
      "train loss:0.13285435905064596\n",
      "train loss:0.087497126541917\n",
      "train loss:0.10940407984640038\n",
      "train loss:0.10494010917127078\n",
      "train loss:0.09764939308218709\n",
      "train loss:0.08017411862775069\n",
      "train loss:0.14424670064945866\n",
      "train loss:0.279785476145066\n",
      "train loss:0.31756113218540427\n",
      "train loss:0.17022388908675207\n",
      "train loss:0.211270698072504\n",
      "train loss:0.12439542230861454\n",
      "train loss:0.2073143152935673\n",
      "train loss:0.16434926375253656\n",
      "train loss:0.10507359558321154\n",
      "train loss:0.11216022247514372\n",
      "train loss:0.16407095770241092\n",
      "train loss:0.07592669028993722\n",
      "train loss:0.08629365611611832\n",
      "train loss:0.21732585004664043\n",
      "train loss:0.09143959432608574\n",
      "train loss:0.1646720801955826\n",
      "train loss:0.1062959720950789\n",
      "train loss:0.19844298463137672\n",
      "train loss:0.1822731326654961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08114050279315506\n",
      "train loss:0.13400597331885022\n",
      "train loss:0.08489874316525169\n",
      "train loss:0.1248010988535752\n",
      "train loss:0.140554243923285\n",
      "train loss:0.084491677997728\n",
      "train loss:0.16251957518978838\n",
      "train loss:0.07361802960881708\n",
      "train loss:0.09194647122678949\n",
      "train loss:0.19733575086877816\n",
      "train loss:0.16987841008814417\n",
      "train loss:0.11621246345391036\n",
      "train loss:0.05635801351413965\n",
      "train loss:0.09426185200266801\n",
      "train loss:0.12196133936212297\n",
      "train loss:0.11612465939109116\n",
      "train loss:0.14978371108865496\n",
      "train loss:0.06989409906153198\n",
      "train loss:0.09533175680640386\n",
      "train loss:0.17693644806203024\n",
      "train loss:0.08071076827524576\n",
      "train loss:0.07284183275870648\n",
      "train loss:0.10693019145865527\n",
      "train loss:0.06884718051032904\n",
      "train loss:0.243241990202375\n",
      "train loss:0.10972836645453654\n",
      "train loss:0.0948951668545456\n",
      "train loss:0.16991564887052413\n",
      "train loss:0.06298651225884046\n",
      "train loss:0.12631813923252092\n",
      "train loss:0.145451618638882\n",
      "train loss:0.08364306214174504\n",
      "train loss:0.1559113718767092\n",
      "train loss:0.07341169800797019\n",
      "train loss:0.15721756254702574\n",
      "train loss:0.06610491368422285\n",
      "train loss:0.12328125063287193\n",
      "train loss:0.18248833473652978\n",
      "train loss:0.06132636599035214\n",
      "train loss:0.14209562127617772\n",
      "train loss:0.10951417404290575\n",
      "train loss:0.0932990357275776\n",
      "train loss:0.09377623257758799\n",
      "train loss:0.20083119206362712\n",
      "train loss:0.30459940572110783\n",
      "train loss:0.0705002840179274\n",
      "train loss:0.06669476640374246\n",
      "train loss:0.14531708797160656\n",
      "train loss:0.20545828693279777\n",
      "train loss:0.14061887570675027\n",
      "train loss:0.1056904103123086\n",
      "train loss:0.07972186436714666\n",
      "train loss:0.14489991141817357\n",
      "train loss:0.08287450993473819\n",
      "train loss:0.07211340802498759\n",
      "train loss:0.10932447794425441\n",
      "train loss:0.10778885311678936\n",
      "train loss:0.1146159438103138\n",
      "train loss:0.10353832284033054\n",
      "train loss:0.17983182068991715\n",
      "train loss:0.16664442634970364\n",
      "train loss:0.17601294519283045\n",
      "train loss:0.10718238532772821\n",
      "train loss:0.10465291367962953\n",
      "=== epoch:2, train acc:0.967, test acc:0.96 ===\n",
      "train loss:0.09778737582871697\n",
      "train loss:0.14505990774526828\n",
      "train loss:0.1188813385927695\n",
      "train loss:0.0756345932340669\n",
      "train loss:0.11356231271334888\n",
      "train loss:0.10159615616332675\n",
      "train loss:0.11053472336163972\n",
      "train loss:0.15797133004027392\n",
      "train loss:0.11781163674665983\n",
      "train loss:0.05926546764290509\n",
      "train loss:0.08611935773417727\n",
      "train loss:0.07225499915848659\n",
      "train loss:0.09161052693867056\n",
      "train loss:0.16932735554432873\n",
      "train loss:0.13591348039740483\n",
      "train loss:0.16394567444611036\n",
      "train loss:0.13788862319029668\n",
      "train loss:0.12075158952101006\n",
      "train loss:0.1206105496231343\n",
      "train loss:0.19703702948966417\n",
      "train loss:0.11624482199847341\n",
      "train loss:0.18215491061351533\n",
      "train loss:0.05869920288299612\n",
      "train loss:0.08514347851049335\n",
      "train loss:0.10451085170105383\n",
      "train loss:0.04289488448843323\n",
      "train loss:0.08473758316609489\n",
      "train loss:0.09012142300793176\n",
      "train loss:0.09319121058642116\n",
      "train loss:0.09540574156883792\n",
      "train loss:0.16782988365090404\n",
      "train loss:0.1257496178617333\n",
      "train loss:0.11618736520081924\n",
      "train loss:0.03382010311665295\n",
      "train loss:0.05789433204059828\n",
      "train loss:0.14580691676103352\n",
      "train loss:0.09430043435310456\n",
      "train loss:0.07617498715861125\n",
      "train loss:0.09690345544933011\n",
      "train loss:0.06524318283098623\n",
      "train loss:0.11094595489766766\n",
      "train loss:0.05194097170093821\n",
      "train loss:0.18226437754907626\n",
      "train loss:0.0560571875729897\n",
      "train loss:0.16653564861364858\n",
      "train loss:0.0778375290847206\n",
      "train loss:0.10991654570314464\n",
      "train loss:0.14871694102238467\n",
      "train loss:0.15020927878746423\n",
      "train loss:0.219176867988432\n",
      "train loss:0.12380592749620885\n",
      "train loss:0.2838185696505127\n",
      "train loss:0.05637396334115237\n",
      "train loss:0.1293021020455763\n",
      "train loss:0.15742555679185308\n",
      "train loss:0.05450508869931131\n",
      "train loss:0.07626395185294778\n",
      "train loss:0.1052250994538103\n",
      "train loss:0.07675501885627398\n",
      "train loss:0.07799813088470695\n",
      "train loss:0.08535413783593679\n",
      "train loss:0.2334162808511567\n",
      "train loss:0.07992658634286604\n",
      "train loss:0.19060471234743848\n",
      "train loss:0.12629503010818\n",
      "train loss:0.13814368928143725\n",
      "train loss:0.13575354238154103\n",
      "train loss:0.06199375015528373\n",
      "train loss:0.1400344257016302\n",
      "train loss:0.13178580021046746\n",
      "train loss:0.13946535627203357\n",
      "train loss:0.20979848365535733\n",
      "train loss:0.1512147735262165\n",
      "train loss:0.027562002502804606\n",
      "train loss:0.043158121825998375\n",
      "train loss:0.10197444529562973\n",
      "train loss:0.08707819771461514\n",
      "train loss:0.06492154500786561\n",
      "train loss:0.07462022563950933\n",
      "train loss:0.07080568909559927\n",
      "train loss:0.059120662941388256\n",
      "train loss:0.06155387133902819\n",
      "train loss:0.09503752417220132\n",
      "train loss:0.20613492313134382\n",
      "train loss:0.12721285430757842\n",
      "train loss:0.11759687401049476\n",
      "train loss:0.12114160245546572\n",
      "train loss:0.06873659697567973\n",
      "train loss:0.09164535046878715\n",
      "train loss:0.13084302268499692\n",
      "train loss:0.07935385402505968\n",
      "train loss:0.16269041032099987\n",
      "train loss:0.05100681462660959\n",
      "train loss:0.092630659468264\n",
      "train loss:0.08668748764230992\n",
      "train loss:0.0904882005523919\n",
      "train loss:0.05021568535140362\n",
      "train loss:0.05518856058953623\n",
      "train loss:0.09010986401701927\n",
      "train loss:0.046106567418465534\n",
      "train loss:0.05790021989678623\n",
      "train loss:0.10559444719863649\n",
      "train loss:0.11552070929755033\n",
      "train loss:0.11571194143444288\n",
      "train loss:0.1158905933207458\n",
      "train loss:0.1447055200729417\n",
      "train loss:0.13250624646841577\n",
      "train loss:0.049056215629572436\n",
      "train loss:0.024668412089743845\n",
      "train loss:0.09273216613267316\n",
      "train loss:0.24055870633309406\n",
      "train loss:0.0830229858898177\n",
      "train loss:0.14010358268286102\n",
      "train loss:0.0914704686162406\n",
      "train loss:0.11804391501025938\n",
      "train loss:0.1854480901244162\n",
      "train loss:0.13153391269015585\n",
      "train loss:0.07214228052927982\n",
      "train loss:0.059594515812203035\n",
      "train loss:0.12120611256356789\n",
      "train loss:0.13082419273286874\n",
      "train loss:0.10250477296013351\n",
      "train loss:0.18023211366050126\n",
      "train loss:0.1272011539637058\n",
      "train loss:0.10170326647552827\n",
      "train loss:0.07679176619563345\n",
      "train loss:0.1043890081102778\n",
      "train loss:0.11577998195039617\n",
      "train loss:0.15320318477940315\n",
      "train loss:0.06134899848740399\n",
      "train loss:0.10662029111415341\n",
      "train loss:0.06438031145032884\n",
      "train loss:0.08768867332131729\n",
      "train loss:0.13465671909802832\n",
      "train loss:0.17881198822678518\n",
      "train loss:0.043701783733438276\n",
      "train loss:0.08685436947326172\n",
      "train loss:0.10647899107959852\n",
      "train loss:0.07312119584740685\n",
      "train loss:0.1814863677105577\n",
      "train loss:0.2485397757003779\n",
      "train loss:0.07337855084104224\n",
      "train loss:0.09730470877322847\n",
      "train loss:0.08013585126780405\n",
      "train loss:0.03277707340484264\n",
      "train loss:0.1154204087008593\n",
      "train loss:0.10620500764462816\n",
      "train loss:0.05658085240328111\n",
      "train loss:0.07740630679144464\n",
      "train loss:0.10962060045106567\n",
      "train loss:0.0665463962505894\n",
      "train loss:0.0836306438300112\n",
      "train loss:0.037314269106104\n",
      "train loss:0.10114736225575478\n",
      "train loss:0.07955550272281581\n",
      "train loss:0.11486802570529858\n",
      "train loss:0.05476725512098713\n",
      "train loss:0.08590187376750391\n",
      "train loss:0.15975593917461928\n",
      "train loss:0.06805091490547557\n",
      "train loss:0.10164308410920789\n",
      "train loss:0.06459272673007213\n",
      "train loss:0.04092866625459296\n",
      "train loss:0.10538647446816313\n",
      "train loss:0.10129065572181543\n",
      "train loss:0.10797538860359934\n",
      "train loss:0.04974337947024847\n",
      "train loss:0.046296069120368565\n",
      "train loss:0.1710451228460341\n",
      "train loss:0.11088687958845458\n",
      "train loss:0.2101053357620186\n",
      "train loss:0.03746120539052897\n",
      "train loss:0.08016832816651448\n",
      "train loss:0.07874411353182274\n",
      "train loss:0.039333590180276976\n",
      "train loss:0.12990370770869203\n",
      "train loss:0.060209783597044195\n",
      "train loss:0.09281993050030081\n",
      "train loss:0.09812235833726612\n",
      "train loss:0.06384902052324279\n",
      "train loss:0.07175128356191314\n",
      "train loss:0.08552484299515319\n",
      "train loss:0.06882940624020623\n",
      "train loss:0.23370788614997146\n",
      "train loss:0.22019189391785055\n",
      "train loss:0.036848659820822964\n",
      "train loss:0.16127485560291\n",
      "train loss:0.04766884777723998\n",
      "train loss:0.0963760149247489\n",
      "train loss:0.08525771236324955\n",
      "train loss:0.30707071585772633\n",
      "train loss:0.08350452385938967\n",
      "train loss:0.06204678304279196\n",
      "train loss:0.2470200167574328\n",
      "train loss:0.13134556639625936\n",
      "train loss:0.0867243002206774\n",
      "train loss:0.09026389069872065\n",
      "train loss:0.07190067762531108\n",
      "train loss:0.07794133279599923\n",
      "train loss:0.042970542284817\n",
      "train loss:0.0800078874216694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.09135460860542906\n",
      "train loss:0.05167821902579965\n",
      "train loss:0.04162543190776862\n",
      "train loss:0.13511780429767842\n",
      "train loss:0.1217304834324841\n",
      "train loss:0.03935935024843742\n",
      "train loss:0.047411794450359715\n",
      "train loss:0.027345348202458788\n",
      "train loss:0.055636301589847156\n",
      "train loss:0.08162320894165795\n",
      "train loss:0.11893741850414137\n",
      "train loss:0.08433262679348742\n",
      "train loss:0.055645354541617814\n",
      "train loss:0.22055997319755283\n",
      "train loss:0.028533031145986345\n",
      "train loss:0.06654794050557633\n",
      "train loss:0.06696863960929648\n",
      "train loss:0.08608376150926199\n",
      "train loss:0.10004880388830932\n",
      "train loss:0.0608279119800648\n",
      "train loss:0.07646505153705244\n",
      "train loss:0.03740676126369546\n",
      "train loss:0.04674899367978511\n",
      "train loss:0.06263104279662576\n",
      "train loss:0.08594197289186248\n",
      "train loss:0.1264935801773865\n",
      "train loss:0.1275069460924908\n",
      "train loss:0.07625952806445326\n",
      "train loss:0.04332899367366573\n",
      "train loss:0.09387954796170414\n",
      "train loss:0.10044410142771039\n",
      "train loss:0.10748039774593604\n",
      "train loss:0.10357130019626162\n",
      "train loss:0.05134490317065191\n",
      "train loss:0.14490789307191743\n",
      "train loss:0.13631025814751574\n",
      "train loss:0.1134244479915774\n",
      "train loss:0.06482751776909526\n",
      "train loss:0.13097497759790286\n",
      "train loss:0.03408486190059711\n",
      "train loss:0.09805131628293745\n",
      "train loss:0.06407033999191125\n",
      "train loss:0.24741298915689797\n",
      "train loss:0.06872868357346412\n",
      "train loss:0.2356450619123519\n",
      "train loss:0.11654114598411162\n",
      "train loss:0.04071302475471284\n",
      "train loss:0.03545340506629336\n",
      "train loss:0.10229274651955621\n",
      "train loss:0.07633087151729004\n",
      "train loss:0.10860678341119134\n",
      "train loss:0.04796917502168641\n",
      "train loss:0.17866323192098504\n",
      "train loss:0.05503012200698941\n",
      "train loss:0.06767004649986846\n",
      "train loss:0.1736842861889475\n",
      "train loss:0.1587834291329355\n",
      "train loss:0.10433405103431383\n",
      "train loss:0.04105979856026396\n",
      "train loss:0.06672291053472201\n",
      "train loss:0.14449328934524527\n",
      "train loss:0.12759719976909914\n",
      "train loss:0.19684152770818653\n",
      "train loss:0.08303550110585588\n",
      "train loss:0.11647703842458429\n",
      "train loss:0.10316503131275702\n",
      "train loss:0.1350517399204762\n",
      "train loss:0.08004041430732599\n",
      "train loss:0.18752696091524676\n",
      "train loss:0.05338281267511255\n",
      "train loss:0.1669332992208895\n",
      "train loss:0.05315664489857391\n",
      "train loss:0.04471818513242565\n",
      "train loss:0.08128475879887725\n",
      "train loss:0.0843472858939599\n",
      "train loss:0.14527374039708518\n",
      "train loss:0.05491615640206389\n",
      "train loss:0.07923665853668882\n",
      "train loss:0.04729921581608843\n",
      "train loss:0.17338194194576795\n",
      "train loss:0.11643693662587294\n",
      "train loss:0.15088211016030764\n",
      "train loss:0.02652693992588048\n",
      "train loss:0.18984755920061983\n",
      "train loss:0.09454343842415022\n",
      "train loss:0.19680826701940798\n",
      "train loss:0.03612052518643127\n",
      "train loss:0.03709342274475731\n",
      "train loss:0.04581908416809535\n",
      "train loss:0.09404539523282064\n",
      "train loss:0.08310063898435839\n",
      "train loss:0.07687231543270065\n",
      "train loss:0.026674138520557337\n",
      "train loss:0.07331497295520487\n",
      "train loss:0.06353652205987757\n",
      "train loss:0.04678310754009231\n",
      "train loss:0.06931439574682294\n",
      "train loss:0.050859090878890095\n",
      "train loss:0.13193859370063643\n",
      "train loss:0.10856752070171768\n",
      "train loss:0.07663225881133873\n",
      "train loss:0.11221589553273599\n",
      "train loss:0.060612682863022564\n",
      "train loss:0.03004952817071441\n",
      "train loss:0.0971149504996845\n",
      "train loss:0.10932176642292109\n",
      "train loss:0.10964512359605924\n",
      "train loss:0.07142047198441212\n",
      "train loss:0.04904740786275808\n",
      "train loss:0.07816943621150158\n",
      "train loss:0.05278380082034274\n",
      "train loss:0.05121754751250308\n",
      "train loss:0.035927398016930796\n",
      "train loss:0.16035699218605656\n",
      "train loss:0.09414625226789847\n",
      "train loss:0.05286512017351724\n",
      "train loss:0.028130508345237518\n",
      "train loss:0.08575775624093117\n",
      "train loss:0.019625165953800917\n",
      "train loss:0.08193256236596168\n",
      "train loss:0.05024114782803944\n",
      "train loss:0.061481533978726785\n",
      "train loss:0.07428522058093537\n",
      "train loss:0.02543942178546859\n",
      "train loss:0.05271633281182798\n",
      "train loss:0.09005335409487998\n",
      "train loss:0.09796717073694314\n",
      "train loss:0.06766538558410304\n",
      "train loss:0.06393627369327591\n",
      "train loss:0.07134220309189113\n",
      "train loss:0.03738941813587301\n",
      "train loss:0.11905885910333489\n",
      "train loss:0.06385454699267214\n",
      "train loss:0.11266354791403721\n",
      "train loss:0.023416398646453552\n",
      "train loss:0.07130110711588851\n",
      "train loss:0.04987769393831452\n",
      "train loss:0.03599631136785677\n",
      "train loss:0.12364929974363446\n",
      "train loss:0.16545578459887633\n",
      "train loss:0.15224826417537496\n",
      "train loss:0.11638534868259522\n",
      "train loss:0.0726362011045924\n",
      "train loss:0.06138412215510551\n",
      "train loss:0.061595478021270134\n",
      "train loss:0.04979365088243065\n",
      "train loss:0.05337445080096322\n",
      "train loss:0.04456034579689914\n",
      "train loss:0.07886287975271655\n",
      "train loss:0.16345738481988734\n",
      "train loss:0.049804502011471394\n",
      "train loss:0.04538745954589816\n",
      "train loss:0.056472002509011174\n",
      "train loss:0.03178979565413938\n",
      "train loss:0.04529696774513775\n",
      "train loss:0.07329485044697306\n",
      "train loss:0.024546841022210462\n",
      "train loss:0.10594781532300587\n",
      "train loss:0.026113653487493095\n",
      "train loss:0.05176424998728574\n",
      "train loss:0.19168283372952094\n",
      "train loss:0.06507924255148324\n",
      "train loss:0.14373325448686114\n",
      "train loss:0.03252446075229896\n",
      "train loss:0.05239885882473308\n",
      "train loss:0.13705689146776118\n",
      "train loss:0.05139936956597688\n",
      "train loss:0.1023856814245944\n",
      "train loss:0.09686948257725693\n",
      "train loss:0.12029799809993516\n",
      "train loss:0.0677528418740485\n",
      "train loss:0.06455548856460788\n",
      "train loss:0.10919538964579574\n",
      "train loss:0.026173730055488113\n",
      "train loss:0.026987471756859397\n",
      "train loss:0.09459911435285029\n",
      "train loss:0.09777876111732448\n",
      "train loss:0.04789829371785304\n",
      "train loss:0.03137228698664292\n",
      "train loss:0.06295865085700292\n",
      "train loss:0.12100728564330014\n",
      "train loss:0.11360632542495164\n",
      "train loss:0.09832194311262428\n",
      "train loss:0.07684177936841204\n",
      "train loss:0.0807966563305809\n",
      "train loss:0.11832149711390778\n",
      "train loss:0.1354256792726477\n",
      "train loss:0.17685522768592765\n",
      "train loss:0.10455359995127993\n",
      "train loss:0.01880887902855311\n",
      "train loss:0.055889621369675915\n",
      "train loss:0.05470370998104053\n",
      "train loss:0.16731511617346415\n",
      "train loss:0.08310931129856267\n",
      "train loss:0.08076365098324058\n",
      "train loss:0.06823209111528762\n",
      "train loss:0.055713753061541894\n",
      "train loss:0.06816952635624728\n",
      "train loss:0.11776879727801003\n",
      "train loss:0.10520212512735469\n",
      "train loss:0.14115672716376104\n",
      "train loss:0.08010622082793968\n",
      "train loss:0.06486313299127\n",
      "train loss:0.06950538813283173\n",
      "train loss:0.04683382672497309\n",
      "train loss:0.05745218306869792\n",
      "train loss:0.04652439223311\n",
      "train loss:0.09112634752631067\n",
      "train loss:0.10795855648612365\n",
      "train loss:0.10678194091815776\n",
      "train loss:0.05966929927160814\n",
      "train loss:0.043763280654681616\n",
      "train loss:0.2025529281518773\n",
      "train loss:0.04706703098799363\n",
      "train loss:0.07172058797626629\n",
      "train loss:0.04718991507559322\n",
      "train loss:0.04178254309469618\n",
      "train loss:0.15441480179789083\n",
      "train loss:0.05030426347111563\n",
      "train loss:0.021472967355475926\n",
      "train loss:0.09479217962233187\n",
      "train loss:0.0461651705249733\n",
      "train loss:0.07950070812069866\n",
      "train loss:0.045117207149856134\n",
      "train loss:0.0394148163996311\n",
      "train loss:0.14937804827395654\n",
      "train loss:0.09054433020556411\n",
      "train loss:0.039129552468539004\n",
      "train loss:0.02062004396119503\n",
      "train loss:0.03857032041470412\n",
      "train loss:0.0486317368060424\n",
      "train loss:0.05416662716634996\n",
      "train loss:0.07207953210850032\n",
      "train loss:0.07114107269787655\n",
      "train loss:0.03825317919792712\n",
      "train loss:0.05425868072403541\n",
      "train loss:0.059041932508373016\n",
      "train loss:0.1143246207769873\n",
      "train loss:0.08130014045094161\n",
      "train loss:0.17580573135795152\n",
      "train loss:0.024990343410534813\n",
      "train loss:0.04518789772387697\n",
      "train loss:0.03715571957253085\n",
      "train loss:0.06106314546072978\n",
      "train loss:0.03013039754074188\n",
      "train loss:0.10086517534409849\n",
      "train loss:0.09082772567753981\n",
      "train loss:0.03495335983347711\n",
      "train loss:0.09998538386694106\n",
      "train loss:0.03465954526531218\n",
      "train loss:0.03259819073408698\n",
      "train loss:0.06418514112444228\n",
      "train loss:0.10337690203486125\n",
      "train loss:0.06737447321482803\n",
      "train loss:0.06973944741153615\n",
      "train loss:0.10227854737129735\n",
      "train loss:0.07154005513248132\n",
      "train loss:0.06852923986670129\n",
      "train loss:0.02867995232877512\n",
      "train loss:0.07536613871713746\n",
      "train loss:0.045595450460268194\n",
      "train loss:0.06689358420146077\n",
      "train loss:0.04940361447165038\n",
      "train loss:0.043824811792082946\n",
      "train loss:0.04763675922850023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0715262305286314\n",
      "train loss:0.1680921040786505\n",
      "train loss:0.049472695082044035\n",
      "train loss:0.064930727688567\n",
      "train loss:0.05025451299971477\n",
      "train loss:0.03083560247806278\n",
      "train loss:0.048514217617445655\n",
      "train loss:0.03363383612345138\n",
      "train loss:0.033631423279362575\n",
      "train loss:0.08904456100306739\n",
      "train loss:0.028707067210893243\n",
      "train loss:0.08425933339849837\n",
      "train loss:0.04210336467470795\n",
      "train loss:0.022836789853302085\n",
      "train loss:0.1740795008738422\n",
      "train loss:0.19901180404455712\n",
      "train loss:0.04664972760089557\n",
      "train loss:0.0526772349634484\n",
      "train loss:0.02622725852400441\n",
      "train loss:0.019028228928557725\n",
      "train loss:0.06378853941875576\n",
      "train loss:0.060628104974255505\n",
      "train loss:0.07369355472744153\n",
      "train loss:0.01663002173042224\n",
      "train loss:0.08598497107193002\n",
      "train loss:0.19562456816826596\n",
      "train loss:0.12033965208101918\n",
      "train loss:0.08969361257814143\n",
      "train loss:0.13002743186187982\n",
      "train loss:0.05298593654011394\n",
      "train loss:0.06224327344722589\n",
      "train loss:0.039391551915252745\n",
      "train loss:0.12485287946235563\n",
      "train loss:0.07178206901813233\n",
      "train loss:0.0271878244139894\n",
      "train loss:0.024256187102882687\n",
      "train loss:0.031232374273160602\n",
      "train loss:0.03423951009129371\n",
      "train loss:0.04259259967928493\n",
      "train loss:0.09837291256307062\n",
      "train loss:0.05023557179685842\n",
      "train loss:0.025707109823703004\n",
      "train loss:0.05620091093651692\n",
      "train loss:0.03904699877128371\n",
      "train loss:0.04962976692289594\n",
      "train loss:0.1190542184269318\n",
      "train loss:0.05901773936400425\n",
      "train loss:0.012491824544930146\n",
      "train loss:0.09716833358957398\n",
      "train loss:0.06249294713748836\n",
      "train loss:0.06254526737518848\n",
      "train loss:0.056113608653721794\n",
      "train loss:0.03932585742367186\n",
      "train loss:0.05299091565118148\n",
      "train loss:0.06701281032587952\n",
      "train loss:0.19866561104624123\n",
      "train loss:0.09699838340779192\n",
      "train loss:0.0847993264038283\n",
      "train loss:0.030583326828288813\n",
      "train loss:0.08736818118646633\n",
      "train loss:0.06548199869262684\n",
      "train loss:0.06572068850621084\n",
      "train loss:0.08167972823796309\n",
      "train loss:0.03956179859661699\n",
      "train loss:0.03930671222276078\n",
      "train loss:0.07780864955872531\n",
      "train loss:0.14514764846548833\n",
      "train loss:0.0651420268870316\n",
      "train loss:0.12115003774770847\n",
      "train loss:0.04972708695056394\n",
      "train loss:0.12801727912051866\n",
      "train loss:0.11833013351816785\n",
      "train loss:0.22092025024836068\n",
      "train loss:0.03752094179358495\n",
      "train loss:0.03365180215971981\n",
      "train loss:0.1304167378605826\n",
      "train loss:0.07415606361949972\n",
      "train loss:0.0396198727003237\n",
      "train loss:0.07150623267362369\n",
      "train loss:0.07528804708617355\n",
      "train loss:0.10455188563592323\n",
      "train loss:0.06448836243707226\n",
      "train loss:0.03072869210494877\n",
      "train loss:0.11823058427571778\n",
      "train loss:0.036372993023353735\n",
      "train loss:0.0850920530873511\n",
      "train loss:0.08578059974192107\n",
      "train loss:0.08182700836320392\n",
      "train loss:0.06160900898434705\n",
      "train loss:0.04357036127816467\n",
      "train loss:0.06859595513133827\n",
      "train loss:0.03744835664339804\n",
      "train loss:0.11002865023280357\n",
      "train loss:0.06750949232382156\n",
      "train loss:0.05362199401291726\n",
      "train loss:0.07059171044724828\n",
      "train loss:0.04263485691802492\n",
      "train loss:0.017517613359663727\n",
      "train loss:0.024655233496910088\n",
      "train loss:0.05813811460283815\n",
      "train loss:0.035219514758069115\n",
      "train loss:0.08242188796958023\n",
      "train loss:0.05524847156960507\n",
      "train loss:0.048609139711416297\n",
      "train loss:0.07404581478823807\n",
      "train loss:0.05641939134166542\n",
      "train loss:0.03639682692660564\n",
      "train loss:0.09719952145694949\n",
      "train loss:0.018501196811176568\n",
      "train loss:0.12404531512388065\n",
      "train loss:0.025515662249986613\n",
      "train loss:0.10601208946043707\n",
      "train loss:0.046482342038886015\n",
      "train loss:0.04977294107066074\n",
      "train loss:0.03734321482071386\n",
      "train loss:0.05090949143063446\n",
      "train loss:0.08319236313087246\n",
      "train loss:0.054176935775135646\n",
      "train loss:0.03436279813760776\n",
      "train loss:0.08703258566438991\n",
      "train loss:0.03445538148976956\n",
      "train loss:0.051093991078924164\n",
      "train loss:0.02508047421331107\n",
      "train loss:0.06577848325291508\n",
      "train loss:0.09778201789511415\n",
      "train loss:0.05775669235955105\n",
      "train loss:0.050965276239474014\n",
      "train loss:0.10311886878805579\n",
      "train loss:0.2131386703280042\n",
      "train loss:0.042347474982053095\n",
      "train loss:0.10900505962658555\n",
      "train loss:0.06948428532432606\n",
      "train loss:0.03987855163235835\n",
      "train loss:0.08354557388067078\n",
      "=== epoch:3, train acc:0.975, test acc:0.978 ===\n",
      "train loss:0.05626918779248468\n",
      "train loss:0.07322723193116812\n",
      "train loss:0.07035298667969245\n",
      "train loss:0.04848946439375919\n",
      "train loss:0.0552151915334913\n",
      "train loss:0.030884603857107198\n",
      "train loss:0.024134214488282076\n",
      "train loss:0.02088997097795893\n",
      "train loss:0.020705386154628056\n",
      "train loss:0.11328075131685739\n",
      "train loss:0.06475443217095887\n",
      "train loss:0.06990242579980786\n",
      "train loss:0.09105512930006894\n",
      "train loss:0.04438121036251834\n",
      "train loss:0.03284726033703579\n",
      "train loss:0.02908006215937451\n",
      "train loss:0.05618613903594596\n",
      "train loss:0.0655631433877043\n",
      "train loss:0.08010947999011846\n",
      "train loss:0.0198454920554553\n",
      "train loss:0.06478140628393164\n",
      "train loss:0.17555291177343813\n",
      "train loss:0.029184495490399837\n",
      "train loss:0.04107931552179701\n",
      "train loss:0.06709298386241608\n",
      "train loss:0.011228077376865275\n",
      "train loss:0.028160020658816873\n",
      "train loss:0.04146487949360309\n",
      "train loss:0.0711775933726532\n",
      "train loss:0.10004277535895209\n",
      "train loss:0.16008960189480198\n",
      "train loss:0.03958065695365046\n",
      "train loss:0.07384688316739547\n",
      "train loss:0.041854685247114415\n",
      "train loss:0.019742516077262143\n",
      "train loss:0.011100557259259283\n",
      "train loss:0.05629123776624901\n",
      "train loss:0.0620093577397917\n",
      "train loss:0.03363641366615907\n",
      "train loss:0.032896855813301956\n",
      "train loss:0.03187359079578513\n",
      "train loss:0.04697704400176348\n",
      "train loss:0.03345722228844197\n",
      "train loss:0.04747773801728229\n",
      "train loss:0.02322617512366013\n",
      "train loss:0.05017778694787009\n",
      "train loss:0.010826066819061788\n",
      "train loss:0.06421768163322439\n",
      "train loss:0.2458344812446297\n",
      "train loss:0.05029194671190114\n",
      "train loss:0.04346583694978163\n",
      "train loss:0.06450562319039836\n",
      "train loss:0.06669317418205156\n",
      "train loss:0.06734980998626598\n",
      "train loss:0.04212147897544744\n",
      "train loss:0.053941617271647146\n",
      "train loss:0.019303114205367664\n",
      "train loss:0.053206357822123816\n",
      "train loss:0.057800015393447916\n",
      "train loss:0.043709770387867504\n",
      "train loss:0.10070417984736761\n",
      "train loss:0.024044802898028753\n",
      "train loss:0.06754216030780022\n",
      "train loss:0.17048905060022856\n",
      "train loss:0.04035731961625014\n",
      "train loss:0.03628087336808411\n",
      "train loss:0.08208852097570395\n",
      "train loss:0.051905955403200525\n",
      "train loss:0.024056075274273378\n",
      "train loss:0.06147221928161573\n",
      "train loss:0.03804491638059195\n",
      "train loss:0.11574010823245082\n",
      "train loss:0.02869776331091993\n",
      "train loss:0.01323308945249569\n",
      "train loss:0.03924017876725169\n",
      "train loss:0.058189389142590094\n",
      "train loss:0.14471563765170414\n",
      "train loss:0.13804623145879058\n",
      "train loss:0.04927427313106761\n",
      "train loss:0.06998458351334612\n",
      "train loss:0.04239454027816472\n",
      "train loss:0.07921864009628815\n",
      "train loss:0.020443609943573235\n",
      "train loss:0.17634935943172303\n",
      "train loss:0.07703997220085554\n",
      "train loss:0.1316932621421585\n",
      "train loss:0.07041195233758324\n",
      "train loss:0.10476282173445696\n",
      "train loss:0.0688811617257831\n",
      "train loss:0.05739784473261918\n",
      "train loss:0.12127825543819705\n",
      "train loss:0.02906118281850294\n",
      "train loss:0.15281252206272952\n",
      "train loss:0.013227221848083826\n",
      "train loss:0.031133736728872305\n",
      "train loss:0.03481678047218097\n",
      "train loss:0.10766526106262665\n",
      "train loss:0.11115195720954998\n",
      "train loss:0.07586825639057841\n",
      "train loss:0.04701739022150193\n",
      "train loss:0.0992564338738529\n",
      "train loss:0.1258508793266771\n",
      "train loss:0.03430648677187042\n",
      "train loss:0.07337341138896693\n",
      "train loss:0.07585387109107054\n",
      "train loss:0.07320320764566368\n",
      "train loss:0.08340625284473357\n",
      "train loss:0.08765474059063091\n",
      "train loss:0.015612301380906498\n",
      "train loss:0.05397609554388793\n",
      "train loss:0.042948066260946494\n",
      "train loss:0.08645928753039543\n",
      "train loss:0.06278513666533503\n",
      "train loss:0.025922735927354435\n",
      "train loss:0.019168830322391063\n",
      "train loss:0.0341343647054453\n",
      "train loss:0.03348201344143883\n",
      "train loss:0.0368178457995621\n",
      "train loss:0.0684371118610867\n",
      "train loss:0.09073417644697358\n",
      "train loss:0.1105929282320589\n",
      "train loss:0.02805456532149654\n",
      "train loss:0.08080293117449036\n",
      "train loss:0.07831853386972172\n",
      "train loss:0.0401017774913508\n",
      "train loss:0.08209826738032654\n",
      "train loss:0.028017692511703482\n",
      "train loss:0.0904977766562777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02215506414530214\n",
      "train loss:0.0513135855123864\n",
      "train loss:0.05492272523909562\n",
      "train loss:0.021951126318924274\n",
      "train loss:0.08839888098689974\n",
      "train loss:0.055589728763800646\n",
      "train loss:0.047174977881841974\n",
      "train loss:0.05487935461727582\n",
      "train loss:0.0858024075921072\n",
      "train loss:0.08349000514034705\n",
      "train loss:0.03462326914457064\n",
      "train loss:0.04071205273145859\n",
      "train loss:0.03761907944502531\n",
      "train loss:0.036071143968824666\n",
      "train loss:0.022468850521086457\n",
      "train loss:0.10321344907696231\n",
      "train loss:0.021057910927503615\n",
      "train loss:0.02499881585295908\n",
      "train loss:0.018452084458925343\n",
      "train loss:0.05053127565324595\n",
      "train loss:0.07479369874328988\n",
      "train loss:0.025367552367216564\n",
      "train loss:0.06706679045657676\n",
      "train loss:0.03591550102370218\n",
      "train loss:0.03519950099522862\n",
      "train loss:0.08163696500528735\n",
      "train loss:0.028115660683011915\n",
      "train loss:0.088775103566323\n",
      "train loss:0.050376772782518266\n",
      "train loss:0.062259848442191325\n",
      "train loss:0.03220349210384268\n",
      "train loss:0.038261735585671884\n",
      "train loss:0.06347657912328915\n",
      "train loss:0.0600564368527918\n",
      "train loss:0.217545846965821\n",
      "train loss:0.0399167910766015\n",
      "train loss:0.045964630377677146\n",
      "train loss:0.04364399454547201\n",
      "train loss:0.10034666136498355\n",
      "train loss:0.049399646332969914\n",
      "train loss:0.02842243444620613\n",
      "train loss:0.01886765657560584\n",
      "train loss:0.06579517620358265\n",
      "train loss:0.04623105030590895\n",
      "train loss:0.0573799770527212\n",
      "train loss:0.047089037705134215\n",
      "train loss:0.059405954377641554\n",
      "train loss:0.03847388918385458\n",
      "train loss:0.03400275859461924\n",
      "train loss:0.0698442870263182\n",
      "train loss:0.05790456834965361\n",
      "train loss:0.11335686544474836\n",
      "train loss:0.03860285656218188\n",
      "train loss:0.04791118351826187\n",
      "train loss:0.057522541399064694\n",
      "train loss:0.07034360544154918\n",
      "train loss:0.028424483292323277\n",
      "train loss:0.04699040642331342\n",
      "train loss:0.06375205593565432\n",
      "train loss:0.027327962161858243\n",
      "train loss:0.0611417251257321\n",
      "train loss:0.01065088868259682\n",
      "train loss:0.03868305556339442\n",
      "train loss:0.09493371115890684\n",
      "train loss:0.06887504739701175\n",
      "train loss:0.05309843730692619\n",
      "train loss:0.058900145663605886\n",
      "train loss:0.030952288957473716\n",
      "train loss:0.06783051414833326\n",
      "train loss:0.05039238850717008\n",
      "train loss:0.07876098118063536\n",
      "train loss:0.0727253339002319\n",
      "train loss:0.15946110615507697\n",
      "train loss:0.06921778233752128\n",
      "train loss:0.019783242592170347\n",
      "train loss:0.028563657347401624\n",
      "train loss:0.07061958345213849\n",
      "train loss:0.05419333475071911\n",
      "train loss:0.046835563630327794\n",
      "train loss:0.04949447238681181\n",
      "train loss:0.044948909397373574\n",
      "train loss:0.057501226872310365\n",
      "train loss:0.0894037456181671\n",
      "train loss:0.0767642033942833\n",
      "train loss:0.03913169264496965\n",
      "train loss:0.02060415610898185\n",
      "train loss:0.032706434103244184\n",
      "train loss:0.0714133050169777\n",
      "train loss:0.08935535408291206\n",
      "train loss:0.041978529637321245\n",
      "train loss:0.053331892254386816\n",
      "train loss:0.08558257403595734\n",
      "train loss:0.05663276133504053\n",
      "train loss:0.028288461646311318\n",
      "train loss:0.04963688000588161\n",
      "train loss:0.07648935925497882\n",
      "train loss:0.0138862737015528\n",
      "train loss:0.05676077181820571\n",
      "train loss:0.019187814313899633\n",
      "train loss:0.08239556521940139\n",
      "train loss:0.043484352202540474\n",
      "train loss:0.034817192520260075\n",
      "train loss:0.04846183841514901\n",
      "train loss:0.0663311452609702\n",
      "train loss:0.023535869587042804\n",
      "train loss:0.05695621335335484\n",
      "train loss:0.015441387311210681\n",
      "train loss:0.04525712262526769\n",
      "train loss:0.10682028638238114\n",
      "train loss:0.04435779354095197\n",
      "train loss:0.07921752782487945\n",
      "train loss:0.021175764367421867\n",
      "train loss:0.050636384119957994\n",
      "train loss:0.04030045181929616\n",
      "train loss:0.028101067253447968\n",
      "train loss:0.06144543557234993\n",
      "train loss:0.055051855291411614\n",
      "train loss:0.021132187909788037\n",
      "train loss:0.027687835220473425\n",
      "train loss:0.06533109410501048\n",
      "train loss:0.05062817942138327\n",
      "train loss:0.05476879521634137\n",
      "train loss:0.057790421910023405\n",
      "train loss:0.013673334807759506\n",
      "train loss:0.06229978797594514\n",
      "train loss:0.016305199750948404\n",
      "train loss:0.12688516507242464\n",
      "train loss:0.025862741403743485\n",
      "train loss:0.08838914268017159\n",
      "train loss:0.0731642571346288\n",
      "train loss:0.06831073998010119\n",
      "train loss:0.08543041443919037\n",
      "train loss:0.10677927841115917\n",
      "train loss:0.05408590463047574\n",
      "train loss:0.06168321012384714\n",
      "train loss:0.11194311782234065\n",
      "train loss:0.023157962555304418\n",
      "train loss:0.15162080026690733\n",
      "train loss:0.05628496893826071\n",
      "train loss:0.024488483326888168\n",
      "train loss:0.10248705539921107\n",
      "train loss:0.06518843536970106\n",
      "train loss:0.08015582154551618\n",
      "train loss:0.04755763018129061\n",
      "train loss:0.05870288100161353\n",
      "train loss:0.04614168315449345\n",
      "train loss:0.13816410933037623\n",
      "train loss:0.03691926411374283\n",
      "train loss:0.06050541306744349\n",
      "train loss:0.026905788339268714\n",
      "train loss:0.04640862629914286\n",
      "train loss:0.020460483670818208\n",
      "train loss:0.024023911227506266\n",
      "train loss:0.10826408515881253\n",
      "train loss:0.0168536013112993\n",
      "train loss:0.03473045496936591\n",
      "train loss:0.030505040212473026\n",
      "train loss:0.0732846935022958\n",
      "train loss:0.03729695291869415\n",
      "train loss:0.09207442406995693\n",
      "train loss:0.021022279275146393\n",
      "train loss:0.06403404167298211\n",
      "train loss:0.03204104428913705\n",
      "train loss:0.035721545709157636\n",
      "train loss:0.14636303960659108\n",
      "train loss:0.039470844721489845\n",
      "train loss:0.02851389787498838\n",
      "train loss:0.01991064185238121\n",
      "train loss:0.046372379433304994\n",
      "train loss:0.0682575991579004\n",
      "train loss:0.027221050620775657\n",
      "train loss:0.08567478414114035\n",
      "train loss:0.06065546599745827\n",
      "train loss:0.07550013439842868\n",
      "train loss:0.02658107024339266\n",
      "train loss:0.06915990450018804\n",
      "train loss:0.047589798471048696\n",
      "train loss:0.14494354458143216\n",
      "train loss:0.02198944400800047\n",
      "train loss:0.056918718446687826\n",
      "train loss:0.04403407107161543\n",
      "train loss:0.07218081062233042\n",
      "train loss:0.05576358659536546\n",
      "train loss:0.06844785013251638\n",
      "train loss:0.04929067505336957\n",
      "train loss:0.029587004569887575\n",
      "train loss:0.039296817626088866\n",
      "train loss:0.033795403635140026\n",
      "train loss:0.138019009618314\n",
      "train loss:0.011687472717633419\n",
      "train loss:0.07213405161075444\n",
      "train loss:0.046234281983926546\n",
      "train loss:0.021463323442062837\n",
      "train loss:0.03760219188410562\n",
      "train loss:0.0075585794545848075\n",
      "train loss:0.01699447299730582\n",
      "train loss:0.10263742820661215\n",
      "train loss:0.050816224494837\n",
      "train loss:0.09690778023597661\n",
      "train loss:0.07858282109830099\n",
      "train loss:0.02644468967897267\n",
      "train loss:0.0731131613493942\n",
      "train loss:0.036706390228974733\n",
      "train loss:0.040482753514742634\n",
      "train loss:0.04664095054154686\n",
      "train loss:0.07078778049224245\n",
      "train loss:0.016862404275144495\n",
      "train loss:0.023447741787857693\n",
      "train loss:0.023691210226365854\n",
      "train loss:0.053191034739240396\n",
      "train loss:0.07106709108049654\n",
      "train loss:0.06599687462080968\n",
      "train loss:0.039825629142760395\n",
      "train loss:0.04234096728400031\n",
      "train loss:0.08304502050175307\n",
      "train loss:0.055072472277876025\n",
      "train loss:0.05617500644813113\n",
      "train loss:0.062710512030316\n",
      "train loss:0.08793805463871067\n",
      "train loss:0.013073194475174814\n",
      "train loss:0.04913776924189083\n",
      "train loss:0.029008841115283478\n",
      "train loss:0.02585974777719097\n",
      "train loss:0.1307162215580988\n",
      "train loss:0.011211343719745567\n",
      "train loss:0.0530700735386307\n",
      "train loss:0.053103410624146044\n",
      "train loss:0.07905898140958764\n",
      "train loss:0.06767473957798019\n",
      "train loss:0.0590035224499128\n",
      "train loss:0.03620455053882973\n",
      "train loss:0.04412227807244163\n",
      "train loss:0.15836986747127588\n",
      "train loss:0.033486990772217305\n",
      "train loss:0.02841789701408998\n",
      "train loss:0.03540471248929461\n",
      "train loss:0.036828535810794254\n",
      "train loss:0.012435151627408507\n",
      "train loss:0.019753001611659417\n",
      "train loss:0.14075183563430152\n",
      "train loss:0.024468341681634316\n",
      "train loss:0.07589583469166009\n",
      "train loss:0.0896013217652945\n",
      "train loss:0.08119630723629095\n",
      "train loss:0.08167478006268952\n",
      "train loss:0.05931925865856806\n",
      "train loss:0.020178713956887643\n",
      "train loss:0.09706328253612856\n",
      "train loss:0.06269394316894131\n",
      "train loss:0.04392135734774213\n",
      "train loss:0.08058167400690378\n",
      "train loss:0.042866301702511815\n",
      "train loss:0.06386015999169802\n",
      "train loss:0.11607495705803636\n",
      "train loss:0.0896888646753402\n",
      "train loss:0.06701669724383104\n",
      "train loss:0.028386859830007976\n",
      "train loss:0.11617517992977762\n",
      "train loss:0.03078218255920272\n",
      "train loss:0.106638972202271\n",
      "train loss:0.036843098839899044\n",
      "train loss:0.03708308592988291\n",
      "train loss:0.037796744832481445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.021154021281605172\n",
      "train loss:0.06332277054796469\n",
      "train loss:0.16923762439170612\n",
      "train loss:0.022269792837689425\n",
      "train loss:0.033660405660026343\n",
      "train loss:0.04276108742029791\n",
      "train loss:0.06756708505004935\n",
      "train loss:0.04702436318005457\n",
      "train loss:0.052557572295798556\n",
      "train loss:0.0316169674704189\n",
      "train loss:0.08440283750435187\n",
      "train loss:0.030809803943712785\n",
      "train loss:0.04373379343439125\n",
      "train loss:0.0646635656852574\n",
      "train loss:0.03068464614609094\n",
      "train loss:0.060373376784641615\n",
      "train loss:0.03655891739315129\n",
      "train loss:0.008613981835485868\n",
      "train loss:0.05946583008718617\n",
      "train loss:0.08745137108471238\n",
      "train loss:0.05120375629723159\n",
      "train loss:0.0861930978530432\n",
      "train loss:0.12217686371292422\n",
      "train loss:0.017975474752510413\n",
      "train loss:0.06744504743811805\n",
      "train loss:0.03364447474471712\n",
      "train loss:0.053169520698203486\n",
      "train loss:0.022221740951800423\n",
      "train loss:0.04207565623607356\n",
      "train loss:0.07535780041821348\n",
      "train loss:0.022293874169047826\n",
      "train loss:0.06859320958545044\n",
      "train loss:0.026951426608721612\n",
      "train loss:0.05390470460530996\n",
      "train loss:0.04788146269226853\n",
      "train loss:0.0604928362312176\n",
      "train loss:0.07842591481065582\n",
      "train loss:0.016394019069167612\n",
      "train loss:0.17112539576307742\n",
      "train loss:0.058741567565189244\n",
      "train loss:0.04605301630706299\n",
      "train loss:0.022812002568038604\n",
      "train loss:0.20443184534388442\n",
      "train loss:0.0535436272207435\n",
      "train loss:0.04491041185795383\n",
      "train loss:0.024707408585394015\n",
      "train loss:0.11608403882975697\n",
      "train loss:0.02425616895681317\n",
      "train loss:0.03595971031577973\n",
      "train loss:0.024204718531298356\n",
      "train loss:0.03877991034622842\n",
      "train loss:0.0976481756751895\n",
      "train loss:0.06286516646896319\n",
      "train loss:0.05264289318235863\n",
      "train loss:0.017046995240139456\n",
      "train loss:0.04586717903018199\n",
      "train loss:0.036833927840596886\n",
      "train loss:0.03519992553366264\n",
      "train loss:0.019502290881340183\n",
      "train loss:0.16340727962301693\n",
      "train loss:0.043048729900822355\n",
      "train loss:0.030675646911409317\n",
      "train loss:0.035046119203400596\n",
      "train loss:0.036271619573433604\n",
      "train loss:0.04546758224182388\n",
      "train loss:0.045717963807074276\n",
      "train loss:0.05224538463738427\n",
      "train loss:0.05783999213287177\n",
      "train loss:0.0851596489991379\n",
      "train loss:0.09442501942697143\n",
      "train loss:0.031030148376525558\n",
      "train loss:0.02669450972856115\n",
      "train loss:0.03269504959110878\n",
      "train loss:0.05733950043476341\n",
      "train loss:0.16726458305083336\n",
      "train loss:0.046690930685679415\n",
      "train loss:0.007730868441734397\n",
      "train loss:0.027337756638560987\n",
      "train loss:0.015476339554227985\n",
      "train loss:0.01580555201999132\n",
      "train loss:0.047661667882972276\n",
      "train loss:0.010407884762302498\n",
      "train loss:0.02121152962937014\n",
      "train loss:0.12656449398628708\n",
      "train loss:0.02415523418691357\n",
      "train loss:0.08290379475685734\n",
      "train loss:0.008724446932495711\n",
      "train loss:0.027768313501245784\n",
      "train loss:0.01576350869461908\n",
      "train loss:0.06630742396239796\n",
      "train loss:0.04252036935426369\n",
      "train loss:0.06486481688436127\n",
      "train loss:0.05787943923264871\n",
      "train loss:0.024640472386630953\n",
      "train loss:0.01696586835019469\n",
      "train loss:0.05298198348346302\n",
      "train loss:0.08117923569866446\n",
      "train loss:0.06849443305662674\n",
      "train loss:0.07973426222534054\n",
      "train loss:0.014616252431663614\n",
      "train loss:0.005567653171581314\n",
      "train loss:0.04500500522035988\n",
      "train loss:0.018381255812197513\n",
      "train loss:0.025799057659830593\n",
      "train loss:0.06847581455366374\n",
      "train loss:0.06762215700596554\n",
      "train loss:0.043339814415580886\n",
      "train loss:0.06790868356122241\n",
      "train loss:0.016948095323990147\n",
      "train loss:0.04326491109506294\n",
      "train loss:0.01754938065978712\n",
      "train loss:0.03777162352620621\n",
      "train loss:0.019150354582084517\n",
      "train loss:0.019812944170382648\n",
      "train loss:0.049860613821629755\n",
      "train loss:0.038833691197825225\n",
      "train loss:0.0373679904115073\n",
      "train loss:0.017290405907079337\n",
      "train loss:0.05784254079615253\n",
      "train loss:0.0381503479826417\n",
      "train loss:0.03238368844223485\n",
      "train loss:0.029366015944971423\n",
      "train loss:0.04201352448454921\n",
      "train loss:0.05770799058448059\n",
      "train loss:0.13981703907809803\n",
      "train loss:0.04359087509237062\n",
      "train loss:0.04425618996931368\n",
      "train loss:0.04924017448473677\n",
      "train loss:0.05051411814574681\n",
      "train loss:0.09321860308989668\n",
      "train loss:0.15340850578979728\n",
      "train loss:0.014296689248446988\n",
      "train loss:0.049465967080538034\n",
      "train loss:0.03733996687086961\n",
      "train loss:0.031234935801861523\n",
      "train loss:0.07287380092434922\n",
      "train loss:0.0719494659818418\n",
      "train loss:0.05743286515721457\n",
      "train loss:0.0227802883059321\n",
      "train loss:0.012204579229078407\n",
      "train loss:0.0770013924619316\n",
      "train loss:0.05330676622444105\n",
      "train loss:0.019539462191595816\n",
      "train loss:0.03764908777880302\n",
      "train loss:0.023857588357365303\n",
      "train loss:0.02352585886819226\n",
      "train loss:0.036763070590693156\n",
      "train loss:0.016114567057251228\n",
      "train loss:0.02723298036006572\n",
      "train loss:0.1032337465536071\n",
      "train loss:0.01745884376594072\n",
      "train loss:0.006024152898721581\n",
      "train loss:0.08909860177373907\n",
      "train loss:0.039412457221873406\n",
      "train loss:0.10130713436507888\n",
      "train loss:0.01739396746028032\n",
      "train loss:0.011416651514228522\n",
      "train loss:0.11732652547118734\n",
      "train loss:0.02654352911773076\n",
      "train loss:0.046337295752804375\n",
      "train loss:0.02004232634666573\n",
      "train loss:0.04894192048629334\n",
      "train loss:0.03097323058695347\n",
      "train loss:0.05810418801538584\n",
      "train loss:0.009500932583654816\n",
      "train loss:0.07177413184285407\n",
      "train loss:0.0509364658589004\n",
      "train loss:0.06958734920147944\n",
      "train loss:0.022823089058372426\n",
      "train loss:0.0275503667380104\n",
      "train loss:0.017184361112812643\n",
      "train loss:0.025343740955892993\n",
      "train loss:0.08689818592527977\n",
      "train loss:0.04521877568797846\n",
      "train loss:0.023732508437011926\n",
      "train loss:0.03367112687405637\n",
      "train loss:0.0367479817763489\n",
      "train loss:0.0679530905943174\n",
      "train loss:0.030266219069419648\n",
      "train loss:0.016045749569063\n",
      "train loss:0.06076430708077532\n",
      "train loss:0.02615154698120068\n",
      "train loss:0.023325709771576584\n",
      "train loss:0.02061572908971641\n",
      "train loss:0.04477145172901435\n",
      "train loss:0.0579984834321749\n",
      "train loss:0.09603525690164942\n",
      "train loss:0.09627222105952825\n",
      "train loss:0.04118097594206862\n",
      "train loss:0.0603908677821832\n",
      "train loss:0.040930139347679056\n",
      "train loss:0.02254179309573967\n",
      "train loss:0.03988724266747749\n",
      "train loss:0.03558280240488946\n",
      "train loss:0.07414232432760094\n",
      "train loss:0.02460537531187368\n",
      "train loss:0.04342968124279777\n",
      "train loss:0.03260709696885016\n",
      "train loss:0.020615436960364608\n",
      "train loss:0.034206675859261626\n",
      "train loss:0.07396902402570397\n",
      "train loss:0.0649599526563054\n",
      "train loss:0.08249796479550313\n",
      "train loss:0.019727284728772915\n",
      "train loss:0.03779674342268701\n",
      "train loss:0.05569246773822039\n",
      "train loss:0.027062214800731815\n",
      "train loss:0.035640072397188444\n",
      "train loss:0.06724979554698281\n",
      "=== epoch:4, train acc:0.983, test acc:0.986 ===\n",
      "train loss:0.08191642360344353\n",
      "train loss:0.037983657915449685\n",
      "train loss:0.01574548013833873\n",
      "train loss:0.05001112864127189\n",
      "train loss:0.04905931609625482\n",
      "train loss:0.07943422562078807\n",
      "train loss:0.029737464534017342\n",
      "train loss:0.019476415700938464\n",
      "train loss:0.042445237318134064\n",
      "train loss:0.16942823820788572\n",
      "train loss:0.02425785530822791\n",
      "train loss:0.06665794150301511\n",
      "train loss:0.027181744445077226\n",
      "train loss:0.07524709715439737\n",
      "train loss:0.034820906722225625\n",
      "train loss:0.134037981808566\n",
      "train loss:0.02277994486989311\n",
      "train loss:0.030454877914359038\n",
      "train loss:0.02913492155634082\n",
      "train loss:0.015197171050962764\n",
      "train loss:0.028380278736342194\n",
      "train loss:0.11463708235798223\n",
      "train loss:0.03325982030145157\n",
      "train loss:0.01726311934143292\n",
      "train loss:0.02320209998197837\n",
      "train loss:0.05253574425206978\n",
      "train loss:0.02826706123522997\n",
      "train loss:0.05028888078695187\n",
      "train loss:0.01701257477968787\n",
      "train loss:0.09712453002976845\n",
      "train loss:0.02312381587801211\n",
      "train loss:0.034687994661236975\n",
      "train loss:0.01105222924900696\n",
      "train loss:0.026498784161300973\n",
      "train loss:0.01744632754225579\n",
      "train loss:0.03223210664264056\n",
      "train loss:0.05144683976456409\n",
      "train loss:0.029664158875886533\n",
      "train loss:0.028227893629427996\n",
      "train loss:0.020334913457990104\n",
      "train loss:0.02253449015565139\n",
      "train loss:0.031998606670779854\n",
      "train loss:0.04427932736585153\n",
      "train loss:0.02497762024474591\n",
      "train loss:0.052285366800970026\n",
      "train loss:0.04022999605883796\n",
      "train loss:0.010689137151071136\n",
      "train loss:0.022591411975860377\n",
      "train loss:0.027824346913402964\n",
      "train loss:0.028380354702590104\n",
      "train loss:0.04835336375746718\n",
      "train loss:0.048336148007170336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.013864498871105994\n",
      "train loss:0.00947775115471683\n",
      "train loss:0.012400519562705577\n",
      "train loss:0.06823642928347554\n",
      "train loss:0.022642790790722008\n",
      "train loss:0.07480228235041425\n",
      "train loss:0.07287933284204028\n",
      "train loss:0.009507569214835372\n",
      "train loss:0.027894138766274904\n",
      "train loss:0.06361087546759256\n",
      "train loss:0.01739822684665764\n",
      "train loss:0.06130763296100107\n",
      "train loss:0.06333354320751373\n",
      "train loss:0.03568218159100797\n",
      "train loss:0.04366194605899334\n",
      "train loss:0.15165180556806504\n",
      "train loss:0.019664937998820332\n",
      "train loss:0.02438727915874342\n",
      "train loss:0.07459694502308874\n",
      "train loss:0.04930515131048224\n",
      "train loss:0.11797639109544868\n",
      "train loss:0.0543597065749348\n",
      "train loss:0.0077161347845895135\n",
      "train loss:0.04933376226476504\n",
      "train loss:0.0099406952706617\n",
      "train loss:0.058205717513178434\n",
      "train loss:0.02014384403082121\n",
      "train loss:0.03223053446038484\n",
      "train loss:0.12606136920017227\n",
      "train loss:0.009468817821620713\n",
      "train loss:0.09932383343197212\n",
      "train loss:0.03881595501206408\n",
      "train loss:0.03643234083314285\n",
      "train loss:0.022398648297078706\n",
      "train loss:0.025598657904763\n",
      "train loss:0.05737074670581189\n",
      "train loss:0.0729642710426504\n",
      "train loss:0.05785294477461547\n",
      "train loss:0.027441468968461332\n",
      "train loss:0.023022519780962335\n",
      "train loss:0.038692696671740266\n",
      "train loss:0.04046131259812411\n",
      "train loss:0.055829113645780776\n",
      "train loss:0.08040085065408606\n",
      "train loss:0.049672105436950435\n",
      "train loss:0.025752659801860686\n",
      "train loss:0.019687712746495424\n",
      "train loss:0.033096602738469316\n",
      "train loss:0.026783152703630287\n",
      "train loss:0.03758756036218847\n",
      "train loss:0.05364227558381164\n",
      "train loss:0.0286470883600376\n",
      "train loss:0.013447606461411155\n",
      "train loss:0.008181962771297378\n",
      "train loss:0.025802470211646864\n",
      "train loss:0.06050036683079943\n",
      "train loss:0.04646264092254657\n",
      "train loss:0.09465179259713748\n",
      "train loss:0.07191573944396759\n",
      "train loss:0.04715142722631909\n",
      "train loss:0.03974015821466198\n",
      "train loss:0.006250475086658877\n",
      "train loss:0.033646141661167084\n",
      "train loss:0.042560152544882046\n",
      "train loss:0.028518240034405236\n",
      "train loss:0.01762038411432712\n",
      "train loss:0.09467344002609375\n",
      "train loss:0.030363988335078283\n",
      "train loss:0.040111710151067695\n",
      "train loss:0.12282247706237209\n",
      "train loss:0.14646582300793226\n",
      "train loss:0.016594371341700533\n",
      "train loss:0.017381432794179627\n",
      "train loss:0.032391004851185394\n",
      "train loss:0.09571023496615697\n",
      "train loss:0.023708964629891704\n",
      "train loss:0.013915705678539756\n",
      "train loss:0.0328845962740568\n",
      "train loss:0.04983719233354718\n",
      "train loss:0.05116153467306142\n",
      "train loss:0.10766738695322398\n",
      "train loss:0.051656168228766564\n",
      "train loss:0.019937091375521295\n",
      "train loss:0.0212315219870471\n",
      "train loss:0.04722256607255839\n",
      "train loss:0.053694476278441136\n",
      "train loss:0.020259333654726874\n",
      "train loss:0.029773324536537076\n",
      "train loss:0.21243260044936332\n",
      "train loss:0.11462304814063132\n",
      "train loss:0.12607980642747849\n",
      "train loss:0.0309849329013345\n",
      "train loss:0.03774394384387558\n",
      "train loss:0.025233600534728975\n",
      "train loss:0.033629975543569814\n",
      "train loss:0.03044001066388797\n",
      "train loss:0.05331486631152107\n",
      "train loss:0.04059193356974975\n",
      "train loss:0.03521433721060975\n",
      "train loss:0.030197959091566254\n",
      "train loss:0.10088111835877366\n",
      "train loss:0.033976759807013625\n",
      "train loss:0.06706656601752592\n",
      "train loss:0.08896085985662312\n",
      "train loss:0.031244291275674085\n",
      "train loss:0.09057617073982623\n",
      "train loss:0.03883764942813948\n",
      "train loss:0.0892613813041068\n",
      "train loss:0.057201703198408234\n",
      "train loss:0.026778024826638477\n",
      "train loss:0.011598099358449743\n",
      "train loss:0.030262124503320015\n",
      "train loss:0.019110348546280603\n",
      "train loss:0.02265575981148575\n",
      "train loss:0.03238754232632006\n",
      "train loss:0.10869391727879348\n",
      "train loss:0.030952589577331015\n",
      "train loss:0.033116395598547246\n",
      "train loss:0.03743227847940501\n",
      "train loss:0.08349070393146223\n",
      "train loss:0.019227995346082757\n",
      "train loss:0.016538809520592824\n",
      "train loss:0.011194246583020985\n",
      "train loss:0.027201163644832157\n",
      "train loss:0.021644463058216105\n",
      "train loss:0.012679460234532551\n",
      "train loss:0.023946511490333985\n",
      "train loss:0.04112395690850757\n",
      "train loss:0.03583747315810286\n",
      "train loss:0.036887845383620096\n",
      "train loss:0.014890092013082659\n",
      "train loss:0.04553062244741155\n",
      "train loss:0.026315288191364184\n",
      "train loss:0.060561599205000816\n",
      "train loss:0.020990036986615338\n",
      "train loss:0.02456938774046144\n",
      "train loss:0.04643162762733136\n",
      "train loss:0.015064428347671828\n",
      "train loss:0.04511359600623639\n",
      "train loss:0.040985455701583524\n",
      "train loss:0.013215472370477847\n",
      "train loss:0.05879966750215928\n",
      "train loss:0.025579074986029383\n",
      "train loss:0.06586203857580951\n",
      "train loss:0.0183221527576219\n",
      "train loss:0.08232707299333006\n",
      "train loss:0.021787696613091295\n",
      "train loss:0.08123461318372813\n",
      "train loss:0.03860183380869311\n",
      "train loss:0.021223539967794407\n",
      "train loss:0.012018288009256034\n",
      "train loss:0.023207951859507237\n",
      "train loss:0.04867411293140164\n",
      "train loss:0.037024725848841034\n",
      "train loss:0.0364491884663736\n",
      "train loss:0.010312552304113607\n",
      "train loss:0.0403792735510241\n",
      "train loss:0.05459005515863761\n",
      "train loss:0.012458409426163698\n",
      "train loss:0.05762798644891674\n",
      "train loss:0.01884795606037983\n",
      "train loss:0.05547661728915911\n",
      "train loss:0.09812978374604824\n",
      "train loss:0.011653519786793682\n",
      "train loss:0.03186620272617472\n",
      "train loss:0.028100842899925284\n",
      "train loss:0.02678597949142341\n",
      "train loss:0.016404735397052388\n",
      "train loss:0.0640530676515838\n",
      "train loss:0.08240252702373342\n",
      "train loss:0.04245606042793874\n",
      "train loss:0.07041533081156455\n",
      "train loss:0.02328155952370502\n",
      "train loss:0.09242931281013547\n",
      "train loss:0.04331657652804475\n",
      "train loss:0.017415842741217363\n",
      "train loss:0.04932028222742932\n",
      "train loss:0.06500256678516386\n",
      "train loss:0.016708389436936172\n",
      "train loss:0.0570470603194352\n",
      "train loss:0.024895863916349518\n",
      "train loss:0.055167961221500465\n",
      "train loss:0.05639636318661613\n",
      "train loss:0.032737979324654554\n",
      "train loss:0.02117351810043891\n",
      "train loss:0.021920142822036217\n",
      "train loss:0.05207365116774062\n",
      "train loss:0.014131140015189121\n",
      "train loss:0.00958974755639021\n",
      "train loss:0.011783804995298283\n",
      "train loss:0.07091830103256445\n",
      "train loss:0.017632936556414035\n",
      "train loss:0.03142992978467213\n",
      "train loss:0.07966522979597987\n",
      "train loss:0.04332386810640019\n",
      "train loss:0.00901934043958005\n",
      "train loss:0.03970202609855405\n",
      "train loss:0.014630900629069007\n",
      "train loss:0.05101712220929294\n",
      "train loss:0.010943053985662312\n",
      "train loss:0.05889222047216863\n",
      "train loss:0.014727701644220794\n",
      "train loss:0.07003499520705078\n",
      "train loss:0.007406073025402804\n",
      "train loss:0.03257094732535187\n",
      "train loss:0.026624767076692604\n",
      "train loss:0.022453500535980376\n",
      "train loss:0.032565782610830527\n",
      "train loss:0.015754908915479694\n",
      "train loss:0.01921535766817169\n",
      "train loss:0.008424797880225574\n",
      "train loss:0.02719587199082504\n",
      "train loss:0.06966228867541144\n",
      "train loss:0.03623706427735199\n",
      "train loss:0.04535416102942837\n",
      "train loss:0.04373301888117529\n",
      "train loss:0.01715699932887123\n",
      "train loss:0.023258104933980013\n",
      "train loss:0.0510621978235197\n",
      "train loss:0.022708788520701084\n",
      "train loss:0.012123573178819928\n",
      "train loss:0.017992035644545663\n",
      "train loss:0.08779464663082535\n",
      "train loss:0.01866220690870092\n",
      "train loss:0.011300024835793693\n",
      "train loss:0.026884769105623353\n",
      "train loss:0.06706839823300194\n",
      "train loss:0.009004659843185105\n",
      "train loss:0.01721556099254223\n",
      "train loss:0.032388190302597326\n",
      "train loss:0.029727720306715378\n",
      "train loss:0.014735846457096522\n",
      "train loss:0.01685960968331933\n",
      "train loss:0.08168187437251144\n",
      "train loss:0.03975342924056887\n",
      "train loss:0.005837260299584777\n",
      "train loss:0.008973136476228664\n",
      "train loss:0.03820453373886645\n",
      "train loss:0.007104259512917711\n",
      "train loss:0.02227363018975663\n",
      "train loss:0.04570050052358439\n",
      "train loss:0.05051240960131368\n",
      "train loss:0.028216295705374803\n",
      "train loss:0.05227076808340495\n",
      "train loss:0.0031828260875148427\n",
      "train loss:0.16922249703101197\n",
      "train loss:0.01464445758683739\n",
      "train loss:0.05239764478817796\n",
      "train loss:0.01218286108773883\n",
      "train loss:0.016884304835704942\n",
      "train loss:0.019449658229814183\n",
      "train loss:0.0633712318901063\n",
      "train loss:0.012520568111305991\n",
      "train loss:0.013756806069967448\n",
      "train loss:0.017506721975044617\n",
      "train loss:0.024925018866708656\n",
      "train loss:0.01736829667088597\n",
      "train loss:0.030118168541027494\n",
      "train loss:0.02431749281432234\n",
      "train loss:0.03430012373956058\n",
      "train loss:0.037370086328681565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.022783480446968304\n",
      "train loss:0.004458991845216255\n",
      "train loss:0.02010179772430692\n",
      "train loss:0.02724715062873944\n",
      "train loss:0.0498628731353078\n",
      "train loss:0.049021397464232466\n",
      "train loss:0.024240245168333042\n",
      "train loss:0.07963746518558429\n",
      "train loss:0.028354263317769576\n",
      "train loss:0.027056917142097646\n",
      "train loss:0.061835992112118\n",
      "train loss:0.007621823718679668\n",
      "train loss:0.04819604899677725\n",
      "train loss:0.14103266155363076\n",
      "train loss:0.016562093398516064\n",
      "train loss:0.061272504136808036\n",
      "train loss:0.04737845463133909\n",
      "train loss:0.008012144685935403\n",
      "train loss:0.06924868882873585\n",
      "train loss:0.024244496064352358\n",
      "train loss:0.0694652113944347\n",
      "train loss:0.006711703541551659\n",
      "train loss:0.030249174330020136\n",
      "train loss:0.005301146017787521\n",
      "train loss:0.07225818274336342\n",
      "train loss:0.03473866078391306\n",
      "train loss:0.017273483718623403\n",
      "train loss:0.028437982458044672\n",
      "train loss:0.0294156601260854\n",
      "train loss:0.027917433948370273\n",
      "train loss:0.02462479634988871\n",
      "train loss:0.020133311937870362\n",
      "train loss:0.018958308795195142\n",
      "train loss:0.14081919583054914\n",
      "train loss:0.013889151262370779\n",
      "train loss:0.08465774616786273\n",
      "train loss:0.03311371813847605\n",
      "train loss:0.044338256409570495\n",
      "train loss:0.042329791677677975\n",
      "train loss:0.10599888248074926\n",
      "train loss:0.03232415425929254\n",
      "train loss:0.01892091327138212\n",
      "train loss:0.05042281874751077\n",
      "train loss:0.06631015547730777\n",
      "train loss:0.05458761200128359\n",
      "train loss:0.05377773712920921\n",
      "train loss:0.008216236478557288\n",
      "train loss:0.10094113386243656\n",
      "train loss:0.05596771218658848\n",
      "train loss:0.07711144929782432\n",
      "train loss:0.06084331564259138\n",
      "train loss:0.028480514062916608\n",
      "train loss:0.0967082743372858\n",
      "train loss:0.017675668080904997\n",
      "train loss:0.033640079359656246\n",
      "train loss:0.021603928599732168\n",
      "train loss:0.02389532000280154\n",
      "train loss:0.024665757748822244\n",
      "train loss:0.06188897177451733\n",
      "train loss:0.04460161484380871\n",
      "train loss:0.01863758792537666\n",
      "train loss:0.042223451316427206\n",
      "train loss:0.05265430379501635\n",
      "train loss:0.013466591790115511\n",
      "train loss:0.012291069282370733\n",
      "train loss:0.010459125381287132\n",
      "train loss:0.03374990437898486\n",
      "train loss:0.02742563355816345\n",
      "train loss:0.03605339696862872\n",
      "train loss:0.05318634604433524\n",
      "train loss:0.019810446016427105\n",
      "train loss:0.07582847502113554\n",
      "train loss:0.004693684416323302\n",
      "train loss:0.11234553631903868\n",
      "train loss:0.0457413719288256\n",
      "train loss:0.04449241447345458\n",
      "train loss:0.07027531460836035\n",
      "train loss:0.06516153783857148\n",
      "train loss:0.029236669791148483\n",
      "train loss:0.016025855601247935\n",
      "train loss:0.09192550971039436\n",
      "train loss:0.12211591934245308\n",
      "train loss:0.009397990064800023\n",
      "train loss:0.018869597297754545\n",
      "train loss:0.016800186582685724\n",
      "train loss:0.03034193864140072\n",
      "train loss:0.014600912481660417\n",
      "train loss:0.01368972228725595\n",
      "train loss:0.08693334499430895\n",
      "train loss:0.023677295592735917\n",
      "train loss:0.018735319565705903\n",
      "train loss:0.021373738677554766\n",
      "train loss:0.109307843969129\n",
      "train loss:0.012947621392119128\n",
      "train loss:0.065170734726934\n",
      "train loss:0.019701546238713317\n",
      "train loss:0.019895786255291818\n",
      "train loss:0.018360082688659095\n",
      "train loss:0.016541815430046958\n",
      "train loss:0.017695296835495283\n",
      "train loss:0.02857614831063429\n",
      "train loss:0.038551184396044165\n",
      "train loss:0.023150447229055984\n",
      "train loss:0.07375428575202321\n",
      "train loss:0.08286825287135217\n",
      "train loss:0.011669147152019046\n",
      "train loss:0.016436099306258754\n",
      "train loss:0.026610766765203197\n",
      "train loss:0.05187193397376669\n",
      "train loss:0.014637846343038581\n",
      "train loss:0.06546633386770685\n",
      "train loss:0.034474144563560044\n",
      "train loss:0.05371359588363936\n",
      "train loss:0.01808562317136281\n",
      "train loss:0.05373688096771373\n",
      "train loss:0.019695859647152206\n",
      "train loss:0.015246372894916064\n",
      "train loss:0.045637749547209075\n",
      "train loss:0.03952375060920151\n",
      "train loss:0.03332788289530974\n",
      "train loss:0.058598386717590406\n",
      "train loss:0.020112950670854047\n",
      "train loss:0.03222221192601222\n",
      "train loss:0.026840488017901745\n",
      "train loss:0.0249807233044481\n",
      "train loss:0.03437367679610388\n",
      "train loss:0.015495026583790863\n",
      "train loss:0.012639748111552116\n",
      "train loss:0.043312764680166975\n",
      "train loss:0.0331450911912937\n",
      "train loss:0.017905391057312384\n",
      "train loss:0.019154372054975954\n",
      "train loss:0.06339654887768177\n",
      "train loss:0.07667819611345272\n",
      "train loss:0.036519142840648576\n",
      "train loss:0.05886818874116287\n",
      "train loss:0.028877681124126406\n",
      "train loss:0.02124946752041141\n",
      "train loss:0.0659604883047408\n",
      "train loss:0.03794991395034124\n",
      "train loss:0.036768610348062225\n",
      "train loss:0.02837511553830533\n",
      "train loss:0.0570058644770854\n",
      "train loss:0.014056806823093933\n",
      "train loss:0.027066978191314983\n",
      "train loss:0.04273301513892572\n",
      "train loss:0.03361346814852813\n",
      "train loss:0.008574500665646105\n",
      "train loss:0.010797385590924302\n",
      "train loss:0.011822964192358818\n",
      "train loss:0.012322774629334439\n",
      "train loss:0.03881767572232829\n",
      "train loss:0.028966653451195243\n",
      "train loss:0.021752218970597367\n",
      "train loss:0.051257661062820814\n",
      "train loss:0.035817206677388504\n",
      "train loss:0.030845860187363648\n",
      "train loss:0.05650085262918918\n",
      "train loss:0.03852784665066904\n",
      "train loss:0.06951843428644387\n",
      "train loss:0.012917598766853939\n",
      "train loss:0.06767050418499747\n",
      "train loss:0.0036977023333705557\n",
      "train loss:0.02303153020966191\n",
      "train loss:0.01640142191341489\n",
      "train loss:0.14284782330948598\n",
      "train loss:0.0031146680877175053\n",
      "train loss:0.009243981788535227\n",
      "train loss:0.0449391517136865\n",
      "train loss:0.01870405071773464\n",
      "train loss:0.01240321076422695\n",
      "train loss:0.035971834952546175\n",
      "train loss:0.015889876061758297\n",
      "train loss:0.0307162111087754\n",
      "train loss:0.020087048668674442\n",
      "train loss:0.043597966489609064\n",
      "train loss:0.10034617215895393\n",
      "train loss:0.08539162192105582\n",
      "train loss:0.016727068704589055\n",
      "train loss:0.006882989776713837\n",
      "train loss:0.016780609031424764\n",
      "train loss:0.04127520573816759\n",
      "train loss:0.06179253813946985\n",
      "train loss:0.012566203931970665\n",
      "train loss:0.04453455520979987\n",
      "train loss:0.005927659535789276\n",
      "train loss:0.004267492650943919\n",
      "train loss:0.040643033635733516\n",
      "train loss:0.027864887975738988\n",
      "train loss:0.007946279246262962\n",
      "train loss:0.05638567772293168\n",
      "train loss:0.01227456553995515\n",
      "train loss:0.010968919419456744\n",
      "train loss:0.022637719463848117\n",
      "train loss:0.06733555147098895\n",
      "train loss:0.03429369180994145\n",
      "train loss:0.04113395947315092\n",
      "train loss:0.02540550811289377\n",
      "train loss:0.022513314175573517\n",
      "train loss:0.11305877079112853\n",
      "train loss:0.03764021942463463\n",
      "train loss:0.013990490890913133\n",
      "train loss:0.024245958486208162\n",
      "train loss:0.02276964496339132\n",
      "train loss:0.0257554828374877\n",
      "train loss:0.033636274212713715\n",
      "train loss:0.020704443258095333\n",
      "train loss:0.016144724032048446\n",
      "train loss:0.019133563795276178\n",
      "train loss:0.11733678935462055\n",
      "train loss:0.07466278031086201\n",
      "train loss:0.013713823074599998\n",
      "train loss:0.026679382166245057\n",
      "train loss:0.012055188235973813\n",
      "train loss:0.047430729069348844\n",
      "train loss:0.06338418153976061\n",
      "train loss:0.04719601235618689\n",
      "train loss:0.028433157111893103\n",
      "train loss:0.016515572335028247\n",
      "train loss:0.014864954494330474\n",
      "train loss:0.04061672537917871\n",
      "train loss:0.02622250661558369\n",
      "train loss:0.04697515937734899\n",
      "train loss:0.03773061335630778\n",
      "train loss:0.011967497721896618\n",
      "train loss:0.007032843294678697\n",
      "train loss:0.02455332984210867\n",
      "train loss:0.017114575949030923\n",
      "train loss:0.0582010473508076\n",
      "train loss:0.0738120160320647\n",
      "train loss:0.008578945461937304\n",
      "train loss:0.06941804616126236\n",
      "train loss:0.0491657694783427\n",
      "train loss:0.03174470195188209\n",
      "train loss:0.06291435423503458\n",
      "train loss:0.02943073841191038\n",
      "train loss:0.0363570978320799\n",
      "train loss:0.01571226374162723\n",
      "train loss:0.02299798005794325\n",
      "train loss:0.027637373023746498\n",
      "train loss:0.02324564778343019\n",
      "train loss:0.06294437739263184\n",
      "train loss:0.010268773250881992\n",
      "train loss:0.008706195624043012\n",
      "train loss:0.06156810800341955\n",
      "train loss:0.025752395597730543\n",
      "train loss:0.02165125746894615\n",
      "train loss:0.010232997426535731\n",
      "train loss:0.01301120093764282\n",
      "train loss:0.07997949866313381\n",
      "train loss:0.08200360677844128\n",
      "train loss:0.014503106067510199\n",
      "train loss:0.06528460028088284\n",
      "train loss:0.0364160352573444\n",
      "train loss:0.03349870251329603\n",
      "train loss:0.013352610474482038\n",
      "train loss:0.03088286896639941\n",
      "train loss:0.014520805456174351\n",
      "train loss:0.02440158348515104\n",
      "train loss:0.036220698351092574\n",
      "train loss:0.020697680169371836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.014267634533693598\n",
      "train loss:0.00727417796640861\n",
      "train loss:0.020602368133847592\n",
      "train loss:0.05564961795059297\n",
      "train loss:0.021654849087704924\n",
      "train loss:0.041367187184788046\n",
      "train loss:0.026673505186748093\n",
      "train loss:0.05860979661116824\n",
      "train loss:0.01761473540916038\n",
      "train loss:0.01923249378770716\n",
      "train loss:0.00474009539750252\n",
      "train loss:0.03298153835302739\n",
      "train loss:0.0699005703110726\n",
      "train loss:0.010022205732275458\n",
      "train loss:0.015913983020198138\n",
      "train loss:0.08585671647867969\n",
      "train loss:0.02321753453960542\n",
      "train loss:0.024167259121225956\n",
      "train loss:0.014460241191651927\n",
      "train loss:0.008229310957850818\n",
      "train loss:0.13340634516282396\n",
      "train loss:0.05689297744648011\n",
      "train loss:0.03717767845188684\n",
      "train loss:0.026639335050259914\n",
      "train loss:0.026408854275708687\n",
      "train loss:0.032184281470204024\n",
      "=== epoch:5, train acc:0.988, test acc:0.987 ===\n",
      "train loss:0.012948381162389035\n",
      "train loss:0.04097038859391728\n",
      "train loss:0.028129502248434014\n",
      "train loss:0.03824360190670281\n",
      "train loss:0.06645836021819786\n",
      "train loss:0.02396987779939368\n",
      "train loss:0.004751642710331642\n",
      "train loss:0.033442490743890024\n",
      "train loss:0.05358913726755829\n",
      "train loss:0.047328723788401944\n",
      "train loss:0.012243712041810562\n",
      "train loss:0.023585507146537642\n",
      "train loss:0.04208807168933732\n",
      "train loss:0.02165818127785359\n",
      "train loss:0.03679927170624303\n",
      "train loss:0.04731553368208826\n",
      "train loss:0.014954099581745713\n",
      "train loss:0.027901104372647346\n",
      "train loss:0.01013874387747421\n",
      "train loss:0.019455345148295753\n",
      "train loss:0.05538680771804785\n",
      "train loss:0.028794600021556222\n",
      "train loss:0.033432537562210256\n",
      "train loss:0.021035364885160134\n",
      "train loss:0.02309467314976749\n",
      "train loss:0.0507676199448835\n",
      "train loss:0.1127640348377756\n",
      "train loss:0.024318806901690165\n",
      "train loss:0.010924496908657533\n",
      "train loss:0.012817809164892726\n",
      "train loss:0.020562108279602666\n",
      "train loss:0.0728153349709885\n",
      "train loss:0.010825139285759204\n",
      "train loss:0.022489286526323503\n",
      "train loss:0.03898571228639636\n",
      "train loss:0.04064005749598415\n",
      "train loss:0.07674207386008537\n",
      "train loss:0.04308182678535413\n",
      "train loss:0.05584631383823147\n",
      "train loss:0.02449440617106221\n",
      "train loss:0.01675943675750618\n",
      "train loss:0.005201256306970132\n",
      "train loss:0.019372613216125503\n",
      "train loss:0.01047013655901693\n",
      "train loss:0.008579964171244663\n",
      "train loss:0.012608665115926352\n",
      "train loss:0.021835512652783627\n",
      "train loss:0.03708721825697594\n",
      "train loss:0.007132692470525346\n",
      "train loss:0.03504888221050049\n",
      "train loss:0.06433689259325151\n",
      "train loss:0.06068748427111496\n",
      "train loss:0.010045430143017056\n",
      "train loss:0.05557478780436556\n",
      "train loss:0.0388917759712992\n",
      "train loss:0.020288763245130906\n",
      "train loss:0.02688353868776965\n",
      "train loss:0.013926825386617062\n",
      "train loss:0.11665192577130705\n",
      "train loss:0.022862095091058254\n",
      "train loss:0.02541435547702155\n",
      "train loss:0.04448842050001058\n",
      "train loss:0.05027805956442312\n",
      "train loss:0.03212365483755167\n",
      "train loss:0.11205652594127853\n",
      "train loss:0.030050029236181892\n",
      "train loss:0.07513550383129532\n",
      "train loss:0.0823869127957295\n",
      "train loss:0.015648568236630002\n",
      "train loss:0.07649952094492479\n",
      "train loss:0.0151357336665131\n",
      "train loss:0.02584592536805409\n",
      "train loss:0.008159632336784324\n",
      "train loss:0.06202920066903925\n",
      "train loss:0.011885723216524034\n",
      "train loss:0.014025959093848189\n",
      "train loss:0.03001921992893426\n",
      "train loss:0.02370224953227774\n",
      "train loss:0.11042322779804943\n",
      "train loss:0.02796951327470892\n",
      "train loss:0.04890245685988794\n",
      "train loss:0.02335752879186356\n",
      "train loss:0.016245938419053044\n",
      "train loss:0.009830970473514958\n",
      "train loss:0.007548095751283071\n",
      "train loss:0.10779103864618088\n",
      "train loss:0.022120694554693007\n",
      "train loss:0.03393138307273317\n",
      "train loss:0.016836540025539245\n",
      "train loss:0.010567059769412681\n",
      "train loss:0.010667245903406359\n",
      "train loss:0.04164299078181794\n",
      "train loss:0.017453218979644122\n",
      "train loss:0.02125430538119155\n",
      "train loss:0.008650280411821502\n",
      "train loss:0.029757820450403122\n",
      "train loss:0.012158919524957307\n",
      "train loss:0.07598410596788259\n",
      "train loss:0.03143294875130967\n",
      "train loss:0.0067554599174191165\n",
      "train loss:0.04900904831028709\n",
      "train loss:0.016857917634049244\n",
      "train loss:0.010317021734872528\n",
      "train loss:0.0035082920441621445\n",
      "train loss:0.08112318455056058\n",
      "train loss:0.025603303488733284\n",
      "train loss:0.019888166931042582\n",
      "train loss:0.01956696472213866\n",
      "train loss:0.009065017151690032\n",
      "train loss:0.010995185034925805\n",
      "train loss:0.011487161202626106\n",
      "train loss:0.047521667731168164\n",
      "train loss:0.1037626176311062\n",
      "train loss:0.007112774318975857\n",
      "train loss:0.014828994105345548\n",
      "train loss:0.07393052554821618\n",
      "train loss:0.02807963321080058\n",
      "train loss:0.009615669456136846\n",
      "train loss:0.049651995309806\n",
      "train loss:0.05277523674169136\n",
      "train loss:0.04110469588096916\n",
      "train loss:0.04021300269492688\n",
      "train loss:0.02267442581531692\n",
      "train loss:0.007166056193712067\n",
      "train loss:0.034980600057147905\n",
      "train loss:0.017221905389490425\n",
      "train loss:0.03194812738706458\n",
      "train loss:0.013518862464400105\n",
      "train loss:0.013061249796486884\n",
      "train loss:0.023327558215765966\n",
      "train loss:0.026065215367436622\n",
      "train loss:0.03448449690249125\n",
      "train loss:0.007265853864039249\n",
      "train loss:0.05176856790607738\n",
      "train loss:0.010358608854942815\n",
      "train loss:0.02916584403465157\n",
      "train loss:0.020054192800667198\n",
      "train loss:0.00440395607902962\n",
      "train loss:0.020237266254513123\n",
      "train loss:0.06265839392345433\n",
      "train loss:0.023467764088364765\n",
      "train loss:0.0265453267020265\n",
      "train loss:0.04968907184540601\n",
      "train loss:0.044590870431661156\n",
      "train loss:0.02100962168207725\n",
      "train loss:0.0026132018923704812\n",
      "train loss:0.007516856289851137\n",
      "train loss:0.09016376625918639\n",
      "train loss:0.022560955864814436\n",
      "train loss:0.02278497603870794\n",
      "train loss:0.02424610122562529\n",
      "train loss:0.025676818783488077\n",
      "train loss:0.03143166926479202\n",
      "train loss:0.017311705799397267\n",
      "train loss:0.04374323174088514\n",
      "train loss:0.017088396194122578\n",
      "train loss:0.036974274990340804\n",
      "train loss:0.003216006870919835\n",
      "train loss:0.039153491384155005\n",
      "train loss:0.020121815158454587\n",
      "train loss:0.021905231331358476\n",
      "train loss:0.03007214537750498\n",
      "train loss:0.028960148647252205\n",
      "train loss:0.02839811246608321\n",
      "train loss:0.0074332428168871175\n",
      "train loss:0.024738809216373236\n",
      "train loss:0.020307578308214128\n",
      "train loss:0.06297050413365507\n",
      "train loss:0.01933209180814572\n",
      "train loss:0.0065356663782181\n",
      "train loss:0.012309845857535258\n",
      "train loss:0.03987258033438979\n",
      "train loss:0.027246350842869572\n",
      "train loss:0.015297155719179603\n",
      "train loss:0.010202157924324318\n",
      "train loss:0.010808779490914269\n",
      "train loss:0.01891079139456078\n",
      "train loss:0.007483445823913658\n",
      "train loss:0.026734659840317355\n",
      "train loss:0.024564002743615778\n",
      "train loss:0.04087266224251087\n",
      "train loss:0.03816149892523177\n",
      "train loss:0.021420990541593476\n",
      "train loss:0.023631968766429607\n",
      "train loss:0.009825855680000899\n",
      "train loss:0.041768842505578385\n",
      "train loss:0.006961872294442534\n",
      "train loss:0.08436929010321154\n",
      "train loss:0.006141571096699915\n",
      "train loss:0.02908519169148319\n",
      "train loss:0.015153579936112603\n",
      "train loss:0.011718403906718322\n",
      "train loss:0.026487625891223273\n",
      "train loss:0.02368062053537099\n",
      "train loss:0.009858723907979518\n",
      "train loss:0.02479700756965732\n",
      "train loss:0.022499289930583012\n",
      "train loss:0.014278226673712502\n",
      "train loss:0.04490518061157549\n",
      "train loss:0.024159765487774713\n",
      "train loss:0.020863361379198017\n",
      "train loss:0.06877763235839823\n",
      "train loss:0.02821533707745741\n",
      "train loss:0.010688233605282553\n",
      "train loss:0.008322783086021678\n",
      "train loss:0.043085631544818426\n",
      "train loss:0.01393098376752217\n",
      "train loss:0.06271054084265441\n",
      "train loss:0.027319669217547023\n",
      "train loss:0.01855570450467293\n",
      "train loss:0.008216152493453109\n",
      "train loss:0.005681785116050068\n",
      "train loss:0.031018270537288384\n",
      "train loss:0.0029808062597167354\n",
      "train loss:0.012549305766205117\n",
      "train loss:0.022039462205499002\n",
      "train loss:0.011957274273914787\n",
      "train loss:0.04116372041623202\n",
      "train loss:0.02862408338065977\n",
      "train loss:0.0030396167272709156\n",
      "train loss:0.040238352985804623\n",
      "train loss:0.024063475146389287\n",
      "train loss:0.05008343336067747\n",
      "train loss:0.017153034433444\n",
      "train loss:0.012758509787287679\n",
      "train loss:0.0038077553174557387\n",
      "train loss:0.01342945536411267\n",
      "train loss:0.008474538782752717\n",
      "train loss:0.04716322755225145\n",
      "train loss:0.022298932460431794\n",
      "train loss:0.020888539578791013\n",
      "train loss:0.012724573015651941\n",
      "train loss:0.04119210840996554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05524064267212024\n",
      "train loss:0.018344686207803006\n",
      "train loss:0.0077154524645521826\n",
      "train loss:0.02450000775404341\n",
      "train loss:0.02952222077254099\n",
      "train loss:0.00551206962341179\n",
      "train loss:0.02050741325642579\n",
      "train loss:0.03452851005434995\n",
      "train loss:0.07497621642107534\n",
      "train loss:0.053708048393774986\n",
      "train loss:0.014004130512473754\n",
      "train loss:0.03226393658906162\n",
      "train loss:0.0947077289283081\n",
      "train loss:0.003729130103625956\n",
      "train loss:0.015311390647095285\n",
      "train loss:0.04621640079219132\n",
      "train loss:0.010468917671634081\n",
      "train loss:0.12514210191809835\n",
      "train loss:0.08662530927772231\n",
      "train loss:0.0054460073087388705\n",
      "train loss:0.004103714637330698\n",
      "train loss:0.010876430956189075\n",
      "train loss:0.013787893915687193\n",
      "train loss:0.04068223068209751\n",
      "train loss:0.07305127530104073\n",
      "train loss:0.1370255143547711\n",
      "train loss:0.024964056427945285\n",
      "train loss:0.025035967082178257\n",
      "train loss:0.025837154912274493\n",
      "train loss:0.029487213202855883\n",
      "train loss:0.01920379732689834\n",
      "train loss:0.01665896710233071\n",
      "train loss:0.043024540936725565\n",
      "train loss:0.04494820630518963\n",
      "train loss:0.050259889704737576\n",
      "train loss:0.01432274153491732\n",
      "train loss:0.0302028491558705\n",
      "train loss:0.05525346624069751\n",
      "train loss:0.017768993997670318\n",
      "train loss:0.04652841380549685\n",
      "train loss:0.007305110491070171\n",
      "train loss:0.008286465414219062\n",
      "train loss:0.09947191117210995\n",
      "train loss:0.02882904299551165\n",
      "train loss:0.0573083779523695\n",
      "train loss:0.027853509266956834\n",
      "train loss:0.026724421789245483\n",
      "train loss:0.047384997172580504\n",
      "train loss:0.029325688644223146\n",
      "train loss:0.01645656061217024\n",
      "train loss:0.03415487254199905\n",
      "train loss:0.045300833089078375\n",
      "train loss:0.010410699126144419\n",
      "train loss:0.017980606043885728\n",
      "train loss:0.007716794635876736\n",
      "train loss:0.07056439359215207\n",
      "train loss:0.022740995724489038\n",
      "train loss:0.06189111480873205\n",
      "train loss:0.04337580395286537\n",
      "train loss:0.022881830662080698\n",
      "train loss:0.03346263503466747\n",
      "train loss:0.016488362654862945\n",
      "train loss:0.023297613099873056\n",
      "train loss:0.017978389830375446\n",
      "train loss:0.05138364635684655\n",
      "train loss:0.026671671368640987\n",
      "train loss:0.01821845472415931\n",
      "train loss:0.02021875169936596\n",
      "train loss:0.02381815897985677\n",
      "train loss:0.027141892809145522\n",
      "train loss:0.03641227552608499\n",
      "train loss:0.009831706638746907\n",
      "train loss:0.017390032749337564\n",
      "train loss:0.054208964397745286\n",
      "train loss:0.023915433728826926\n",
      "train loss:0.07375074742530807\n",
      "train loss:0.008702875689161378\n",
      "train loss:0.12671655208429564\n",
      "train loss:0.06574461290586019\n",
      "train loss:0.009426615165916398\n",
      "train loss:0.0085119497697154\n",
      "train loss:0.08705370443219979\n",
      "train loss:0.03529801965171473\n",
      "train loss:0.01337261421527569\n",
      "train loss:0.021057431448262078\n",
      "train loss:0.0185702397754684\n",
      "train loss:0.006569668961289443\n",
      "train loss:0.005752838992569571\n",
      "train loss:0.036161977510200144\n",
      "train loss:0.03724245501023833\n",
      "train loss:0.04596469071638178\n",
      "train loss:0.048045576864968444\n",
      "train loss:0.04189454714638283\n",
      "train loss:0.005956386301894776\n",
      "train loss:0.040755080549922613\n",
      "train loss:0.09079162602334702\n",
      "train loss:0.012825047961251253\n",
      "train loss:0.012775648871130321\n",
      "train loss:0.010852487713999992\n",
      "train loss:0.06681639788807192\n",
      "train loss:0.0531775901203192\n",
      "train loss:0.047645025872219075\n",
      "train loss:0.08473627870548744\n",
      "train loss:0.017427722245225548\n",
      "train loss:0.1257369149984627\n",
      "train loss:0.02077083341558854\n",
      "train loss:0.0083416626740491\n",
      "train loss:0.024061267512360773\n",
      "train loss:0.012479013375814944\n",
      "train loss:0.032508536876708585\n",
      "train loss:0.003905511927112108\n",
      "train loss:0.015394456686352502\n",
      "train loss:0.025639524931794465\n",
      "train loss:0.03337768656713416\n",
      "train loss:0.023229225024635203\n",
      "train loss:0.00490228695331358\n",
      "train loss:0.008763362130389708\n",
      "train loss:0.019830563931498815\n",
      "train loss:0.0035399768743670824\n",
      "train loss:0.011158664054196202\n",
      "train loss:0.02828030487943217\n",
      "train loss:0.03862585229342461\n",
      "train loss:0.01763033073963372\n",
      "train loss:0.00859816796527528\n",
      "train loss:0.036303204734685776\n",
      "train loss:0.11734688830185716\n",
      "train loss:0.01015065551020198\n",
      "train loss:0.045173354940348596\n",
      "train loss:0.004220704651295046\n",
      "train loss:0.022465054939499737\n",
      "train loss:0.016263081942299706\n",
      "train loss:0.02386093623889233\n",
      "train loss:0.01750032184150744\n",
      "train loss:0.04437115481033019\n",
      "train loss:0.03974724940110189\n",
      "train loss:0.014739272945137088\n",
      "train loss:0.016803559522090613\n",
      "train loss:0.004312175609944542\n",
      "train loss:0.014309358487205295\n",
      "train loss:0.005582766976554163\n",
      "train loss:0.012788468213664993\n",
      "train loss:0.03640021959135125\n",
      "train loss:0.02995997324532816\n",
      "train loss:0.009454590779544967\n",
      "train loss:0.006347183870721123\n",
      "train loss:0.04846778182245909\n",
      "train loss:0.02673256661950642\n",
      "train loss:0.010243683016817235\n",
      "train loss:0.00793270782196424\n",
      "train loss:0.011004442379763812\n",
      "train loss:0.013826735988410617\n",
      "train loss:0.1610376344132483\n",
      "train loss:0.0029108808044992023\n",
      "train loss:0.010239969108235507\n",
      "train loss:0.017473185055256447\n",
      "train loss:0.0021280732442036294\n",
      "train loss:0.0815232442602949\n",
      "train loss:0.04047584311302246\n",
      "train loss:0.02435783763616122\n",
      "train loss:0.02649089268221968\n",
      "train loss:0.0022986504397109926\n",
      "train loss:0.010215881260583442\n",
      "train loss:0.0053331782590827536\n",
      "train loss:0.04702205623406737\n",
      "train loss:0.04381354427575827\n",
      "train loss:0.01216262910282858\n",
      "train loss:0.06817783863638766\n",
      "train loss:0.014165273625151383\n",
      "train loss:0.022822996037364776\n",
      "train loss:0.024693970541679634\n",
      "train loss:0.008169184908249406\n",
      "train loss:0.09448097009155122\n",
      "train loss:0.014741605172822811\n",
      "train loss:0.014966763370767857\n",
      "train loss:0.018670126684615335\n",
      "train loss:0.05665722647220664\n",
      "train loss:0.048426696748676654\n",
      "train loss:0.004206722520874504\n",
      "train loss:0.0305175219833172\n",
      "train loss:0.028564379053797304\n",
      "train loss:0.017767310427522803\n",
      "train loss:0.0035874718336887756\n",
      "train loss:0.017381905956867567\n",
      "train loss:0.024143925375932556\n",
      "train loss:0.01102222493971255\n",
      "train loss:0.07516235339253519\n",
      "train loss:0.010788395475918729\n",
      "train loss:0.014353822646542981\n",
      "train loss:0.01939921933933825\n",
      "train loss:0.02084415480072756\n",
      "train loss:0.04127727666923056\n",
      "train loss:0.01102560207381057\n",
      "train loss:0.014377852144555687\n",
      "train loss:0.020292713681541712\n",
      "train loss:0.05307860669472347\n",
      "train loss:0.021436675139036826\n",
      "train loss:0.023780220219380106\n",
      "train loss:0.003743233692024851\n",
      "train loss:0.0400104295430669\n",
      "train loss:0.01148452907961685\n",
      "train loss:0.0037340457971139734\n",
      "train loss:0.033584397239266386\n",
      "train loss:0.052969399853146\n",
      "train loss:0.014919335951026675\n",
      "train loss:0.013220950516343746\n",
      "train loss:0.01545501834145234\n",
      "train loss:0.03433962509508277\n",
      "train loss:0.08348342659971245\n",
      "train loss:0.02177261239025777\n",
      "train loss:0.09142422468541289\n",
      "train loss:0.031931018425262525\n",
      "train loss:0.02007031077361\n",
      "train loss:0.003207138041544043\n",
      "train loss:0.005013955643101669\n",
      "train loss:0.04074384710052473\n",
      "train loss:0.012476885562143311\n",
      "train loss:0.01636714740309257\n",
      "train loss:0.02258773260082676\n",
      "train loss:0.03797521554016556\n",
      "train loss:0.014753871395692753\n",
      "train loss:0.023762530932712463\n",
      "train loss:0.012729198326705857\n",
      "train loss:0.018050680478620358\n",
      "train loss:0.03945600533439304\n",
      "train loss:0.0655919767478218\n",
      "train loss:0.014020178728875666\n",
      "train loss:0.01296912811983858\n",
      "train loss:0.015765802844592513\n",
      "train loss:0.009581963187589996\n",
      "train loss:0.022884880731057607\n",
      "train loss:0.03210934930815355\n",
      "train loss:0.04280158713616758\n",
      "train loss:0.02738523317715838\n",
      "train loss:0.009835003760051291\n",
      "train loss:0.011884997494400817\n",
      "train loss:0.013919177126341864\n",
      "train loss:0.009913934862671862\n",
      "train loss:0.01943365311395517\n",
      "train loss:0.029620948513911897\n",
      "train loss:0.020444719255568847\n",
      "train loss:0.012080183123017839\n",
      "train loss:0.018722798164015984\n",
      "train loss:0.02410046260129879\n",
      "train loss:0.011176679789248953\n",
      "train loss:0.004927573753907156\n",
      "train loss:0.009775519365282294\n",
      "train loss:0.02334907781914091\n",
      "train loss:0.007340723021220821\n",
      "train loss:0.018223763210167145\n",
      "train loss:0.00501521141029713\n",
      "train loss:0.011640323258673934\n",
      "train loss:0.05164354239399302\n",
      "train loss:0.017136828862604776\n",
      "train loss:0.018263341728678516\n",
      "train loss:0.013917204318622405\n",
      "train loss:0.02761398836751301\n",
      "train loss:0.05903764186152317\n",
      "train loss:0.018075592418248198\n",
      "train loss:0.0059077431724721165\n",
      "train loss:0.056803269258773825\n",
      "train loss:0.025698454648573697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01764594070545067\n",
      "train loss:0.006071993624807206\n",
      "train loss:0.019385608619892757\n",
      "train loss:0.020678653632941767\n",
      "train loss:0.02560679037741829\n",
      "train loss:0.004233618012430503\n",
      "train loss:0.020435312010702034\n",
      "train loss:0.04194840617938217\n",
      "train loss:0.022500926795893994\n",
      "train loss:0.015573176236968744\n",
      "train loss:0.009804514980640236\n",
      "train loss:0.011674977382990018\n",
      "train loss:0.00708865375993562\n",
      "train loss:0.09218325722377\n",
      "train loss:0.010822827665351935\n",
      "train loss:0.056613728700825795\n",
      "train loss:0.018109467837819918\n",
      "train loss:0.02409124952259399\n",
      "train loss:0.020599033868113525\n",
      "train loss:0.041546809079189735\n",
      "train loss:0.02261712278687483\n",
      "train loss:0.007526101270713462\n",
      "train loss:0.058806058016338696\n",
      "train loss:0.007413102024062812\n",
      "train loss:0.015470582196446168\n",
      "train loss:0.01905424276605907\n",
      "train loss:0.01709104222300622\n",
      "train loss:0.011613752011665937\n",
      "train loss:0.02906848167315629\n",
      "train loss:0.01258319292902809\n",
      "train loss:0.007683238919219747\n",
      "train loss:0.02107524596484152\n",
      "train loss:0.0046073235577330455\n",
      "train loss:0.02305655185492074\n",
      "train loss:0.027878439542749774\n",
      "train loss:0.010957014410351983\n",
      "train loss:0.023910611232331812\n",
      "train loss:0.011617942503114664\n",
      "train loss:0.09145649741011526\n",
      "train loss:0.050775594154849335\n",
      "train loss:0.05226196696657562\n",
      "train loss:0.01090527430703227\n",
      "train loss:0.006430773575545881\n",
      "train loss:0.006210504949576834\n",
      "train loss:0.023761908046790996\n",
      "train loss:0.005500955974231285\n",
      "train loss:0.11827063234911232\n",
      "train loss:0.003211418356956801\n",
      "train loss:0.01671714188480685\n",
      "train loss:0.036391592374755574\n",
      "train loss:0.009436671763186253\n",
      "train loss:0.006001431499354381\n",
      "train loss:0.03857608177493866\n",
      "train loss:0.018490788476744225\n",
      "train loss:0.008409782967122893\n",
      "train loss:0.019105444526474395\n",
      "train loss:0.038388028461847606\n",
      "train loss:0.034811915293654176\n",
      "train loss:0.010348052643690313\n",
      "train loss:0.03775848312789342\n",
      "train loss:0.06910855988771168\n",
      "train loss:0.04745299402699468\n",
      "train loss:0.0028442055860331476\n",
      "train loss:0.011164471408351907\n",
      "train loss:0.02569000874801821\n",
      "train loss:0.025318286427340818\n",
      "train loss:0.041367190568761286\n",
      "train loss:0.022198015106259558\n",
      "train loss:0.048355270482546786\n",
      "train loss:0.0102022434508125\n",
      "train loss:0.06747437731315523\n",
      "train loss:0.016701738965527436\n",
      "train loss:0.033928544574767135\n",
      "train loss:0.025080403589559236\n",
      "train loss:0.00294682065664562\n",
      "train loss:0.036976527760134985\n",
      "train loss:0.04464017072016416\n",
      "train loss:0.060119365501138285\n",
      "train loss:0.014538170839470758\n",
      "train loss:0.031321759381295104\n",
      "train loss:0.015899057822091736\n",
      "train loss:0.018318995284316738\n",
      "train loss:0.08465120692292526\n",
      "train loss:0.04358017099240986\n",
      "train loss:0.012811991989578246\n",
      "train loss:0.03940693501591559\n",
      "train loss:0.01169644474228943\n",
      "train loss:0.009625437965302203\n",
      "train loss:0.06425055046803108\n",
      "train loss:0.02656274067562163\n",
      "train loss:0.014106898510481865\n",
      "train loss:0.014688969266237119\n",
      "train loss:0.07045299386312048\n",
      "train loss:0.010722982804784214\n",
      "train loss:0.020607408017930283\n",
      "train loss:0.008730196248492868\n",
      "train loss:0.015268432837484882\n",
      "train loss:0.015473758580169179\n",
      "train loss:0.018204311837256702\n",
      "train loss:0.01711689518240907\n",
      "train loss:0.022245781221244675\n",
      "train loss:0.027421793396091285\n",
      "train loss:0.024557525504376013\n",
      "train loss:0.04078145994716933\n",
      "train loss:0.0274981505985531\n",
      "train loss:0.008750819022055871\n",
      "=== epoch:6, train acc:0.99, test acc:0.986 ===\n",
      "train loss:0.02666038098693486\n",
      "train loss:0.019151111641481384\n",
      "train loss:0.04384262298302659\n",
      "train loss:0.04295984154688475\n",
      "train loss:0.036361685225282624\n",
      "train loss:0.04169717606050529\n",
      "train loss:0.007504221841981088\n",
      "train loss:0.0332674920107142\n",
      "train loss:0.01375553683690563\n",
      "train loss:0.03892848082971018\n",
      "train loss:0.02019318686406031\n",
      "train loss:0.012727865878304394\n",
      "train loss:0.03027035281782467\n",
      "train loss:0.023088338869214287\n",
      "train loss:0.023501902689264494\n",
      "train loss:0.013328065667555638\n",
      "train loss:0.003999183494210312\n",
      "train loss:0.015898581829977748\n",
      "train loss:0.05718139472327637\n",
      "train loss:0.025735493897073226\n",
      "train loss:0.013921365677325213\n",
      "train loss:0.01531036498940644\n",
      "train loss:0.05841934675216546\n",
      "train loss:0.057748806129011655\n",
      "train loss:0.00689207699922711\n",
      "train loss:0.05289494964525202\n",
      "train loss:0.0332631603404367\n",
      "train loss:0.007365360467152665\n",
      "train loss:0.04557007148025858\n",
      "train loss:0.0506018552926315\n",
      "train loss:0.014000660981775836\n",
      "train loss:0.02169978713116703\n",
      "train loss:0.010541769996664905\n",
      "train loss:0.0793484247645107\n",
      "train loss:0.045059294808426006\n",
      "train loss:0.011439389246823535\n",
      "train loss:0.04927081954582845\n",
      "train loss:0.0037578098182883025\n",
      "train loss:0.010538650756493701\n",
      "train loss:0.021391264579911747\n",
      "train loss:0.005274610132504017\n",
      "train loss:0.02005272803874441\n",
      "train loss:0.003768398013213299\n",
      "train loss:0.029846288207923292\n",
      "train loss:0.010505317699529141\n",
      "train loss:0.02616201386089734\n",
      "train loss:0.042819046572545115\n",
      "train loss:0.014540177300448208\n",
      "train loss:0.056903407529307864\n",
      "train loss:0.02833261585328833\n",
      "train loss:0.026915076658536017\n",
      "train loss:0.0065612365712891495\n",
      "train loss:0.02714990711502472\n",
      "train loss:0.012005428404554225\n",
      "train loss:0.0693464209129622\n",
      "train loss:0.008657060834891324\n",
      "train loss:0.025570950399968703\n",
      "train loss:0.006968391911750947\n",
      "train loss:0.010179758233920852\n",
      "train loss:0.018073494597551306\n",
      "train loss:0.018085646162881792\n",
      "train loss:0.023243466124725262\n",
      "train loss:0.026841600483081582\n",
      "train loss:0.03743370989451152\n",
      "train loss:0.01589974016798445\n",
      "train loss:0.004988628660878194\n",
      "train loss:0.005773183806123277\n",
      "train loss:0.014185158156256322\n",
      "train loss:0.030790242128310975\n",
      "train loss:0.006750482457139376\n",
      "train loss:0.008830953829207297\n",
      "train loss:0.01717000842090755\n",
      "train loss:0.001796621940399249\n",
      "train loss:0.18545400409110546\n",
      "train loss:0.017245080351138108\n",
      "train loss:0.049228208251153226\n",
      "train loss:0.01206414751418531\n",
      "train loss:0.011502499320742337\n",
      "train loss:0.013840876690946467\n",
      "train loss:0.013406505331272295\n",
      "train loss:0.03173686226085466\n",
      "train loss:0.00874619508655045\n",
      "train loss:0.03220401396224528\n",
      "train loss:0.00404555471630043\n",
      "train loss:0.03251345873974461\n",
      "train loss:0.005144814008141739\n",
      "train loss:0.013173938764266386\n",
      "train loss:0.049416910242676755\n",
      "train loss:0.01811799725352566\n",
      "train loss:0.04905938799323012\n",
      "train loss:0.017132094421854552\n",
      "train loss:0.04322843386019995\n",
      "train loss:0.01293710536313751\n",
      "train loss:0.02262546248842641\n",
      "train loss:0.011978060144851152\n",
      "train loss:0.007006900079422384\n",
      "train loss:0.012174079670725155\n",
      "train loss:0.016578822946271922\n",
      "train loss:0.0026394864363316227\n",
      "train loss:0.03403306249380643\n",
      "train loss:0.03828629955165374\n",
      "train loss:0.0015716056610161119\n",
      "train loss:0.006340191427867355\n",
      "train loss:0.011568883289039487\n",
      "train loss:0.032838630012770965\n",
      "train loss:0.014469045091365089\n",
      "train loss:0.012212867256706022\n",
      "train loss:0.016450120767148694\n",
      "train loss:0.0024457681878276107\n",
      "train loss:0.028697159132382515\n",
      "train loss:0.009632325611997335\n",
      "train loss:0.009238008014031206\n",
      "train loss:0.014539527574714077\n",
      "train loss:0.031078155954867685\n",
      "train loss:0.01432520808561754\n",
      "train loss:0.0206258506097433\n",
      "train loss:0.003936586436353615\n",
      "train loss:0.025247428371918422\n",
      "train loss:0.023136451362807998\n",
      "train loss:0.032289071389230026\n",
      "train loss:0.05675245392947018\n",
      "train loss:0.005610133155849028\n",
      "train loss:0.010451848473898653\n",
      "train loss:0.014037532706015831\n",
      "train loss:0.01282684196299137\n",
      "train loss:0.016579331351086093\n",
      "train loss:0.020312923436477788\n",
      "train loss:0.006491937992675296\n",
      "train loss:0.007781914260632805\n",
      "train loss:0.02287520257761182\n",
      "train loss:0.016452707702453166\n",
      "train loss:0.0185408245519532\n",
      "train loss:0.023478298768067302\n",
      "train loss:0.0044757623505754665\n",
      "train loss:0.02930851676416983\n",
      "train loss:0.022142865620223558\n",
      "train loss:0.003520691065724639\n",
      "train loss:0.012326310934372196\n",
      "train loss:0.08190470501815966\n",
      "train loss:0.02512654320313536\n",
      "train loss:0.009448927014618415\n",
      "train loss:0.04633816889214955\n",
      "train loss:0.04829030430939607\n",
      "train loss:0.038161028516027186\n",
      "train loss:0.07485845099877514\n",
      "train loss:0.007289484659260626\n",
      "train loss:0.03426696821322653\n",
      "train loss:0.03661002122290406\n",
      "train loss:0.044729306901883745\n",
      "train loss:0.050585572747729055\n",
      "train loss:0.03327457839980577\n",
      "train loss:0.02909658830180858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.018402486698163054\n",
      "train loss:0.03207155612937723\n",
      "train loss:0.018685670467837975\n",
      "train loss:0.005733652507104811\n",
      "train loss:0.033160185820507906\n",
      "train loss:0.011247519822862808\n",
      "train loss:0.012580312301512884\n",
      "train loss:0.067161944425205\n",
      "train loss:0.005109591993709504\n",
      "train loss:0.021839005575991558\n",
      "train loss:0.019474391550027136\n",
      "train loss:0.06974767771782191\n",
      "train loss:0.09004661503631078\n",
      "train loss:0.022273852980852715\n",
      "train loss:0.02069605736290111\n",
      "train loss:0.03871902703114475\n",
      "train loss:0.06334909036908841\n",
      "train loss:0.16983273363870385\n",
      "train loss:0.024827102130730708\n",
      "train loss:0.04139083586911429\n",
      "train loss:0.012514211011739827\n",
      "train loss:0.025434012811040123\n",
      "train loss:0.00504507504035255\n",
      "train loss:0.0242885445459904\n",
      "train loss:0.006015603981429163\n",
      "train loss:0.021227076088601478\n",
      "train loss:0.018655708131934245\n",
      "train loss:0.10872666410230282\n",
      "train loss:0.009791312780719182\n",
      "train loss:0.03916663105328419\n",
      "train loss:0.018512350561104892\n",
      "train loss:0.022582941095218155\n",
      "train loss:0.11893198315471466\n",
      "train loss:0.013836475922124464\n",
      "train loss:0.01697860369294661\n",
      "train loss:0.015244586237236535\n",
      "train loss:0.04783756265667769\n",
      "train loss:0.028425661586086188\n",
      "train loss:0.006349953839385072\n",
      "train loss:0.016621071654234706\n",
      "train loss:0.009972403290035575\n",
      "train loss:0.007545707472074238\n",
      "train loss:0.014404790189302834\n",
      "train loss:0.02301333501323\n",
      "train loss:0.014622422666229819\n",
      "train loss:0.018373994875459633\n",
      "train loss:0.009819377803719324\n",
      "train loss:0.01051218934557954\n",
      "train loss:0.037880990975411255\n",
      "train loss:0.022917139698519242\n",
      "train loss:0.011179166144020663\n",
      "train loss:0.02083957352026645\n",
      "train loss:0.03856080282357703\n",
      "train loss:0.01960718687727008\n",
      "train loss:0.015773347798486236\n",
      "train loss:0.07215183380309054\n",
      "train loss:0.0023145697553763993\n",
      "train loss:0.00851181901892079\n",
      "train loss:0.01157459961234414\n",
      "train loss:0.020279692007700238\n",
      "train loss:0.0695374995173252\n",
      "train loss:0.01322584553762875\n",
      "train loss:0.08420669163399795\n",
      "train loss:0.004807067983576312\n",
      "train loss:0.05604068294185484\n",
      "train loss:0.019170551470639965\n",
      "train loss:0.0092876820238614\n",
      "train loss:0.019542115154850104\n",
      "train loss:0.012790861736280494\n",
      "train loss:0.03659114278638671\n",
      "train loss:0.014957847465347061\n",
      "train loss:0.003500274691679508\n",
      "train loss:0.008373105136330196\n",
      "train loss:0.02353820131679061\n",
      "train loss:0.010551797080346705\n",
      "train loss:0.03275697305335825\n",
      "train loss:0.0507628776554889\n",
      "train loss:0.0174701126217252\n",
      "train loss:0.02772089588111811\n",
      "train loss:0.005313399380478244\n",
      "train loss:0.019289925569095187\n",
      "train loss:0.009772348323008625\n",
      "train loss:0.005880773553970216\n",
      "train loss:0.03413034981335236\n",
      "train loss:0.0244894343232791\n",
      "train loss:0.004668186164823131\n",
      "train loss:0.007516579759990018\n",
      "train loss:0.004966515120902621\n",
      "train loss:0.023225216332601897\n",
      "train loss:0.05275834323434607\n",
      "train loss:0.008184874960928137\n",
      "train loss:0.007505013666041374\n",
      "train loss:0.023618114459426368\n",
      "train loss:0.006635847461284337\n",
      "train loss:0.0058239882320859915\n",
      "train loss:0.04521170935997299\n",
      "train loss:0.010419477773065466\n",
      "train loss:0.011043702546663972\n",
      "train loss:0.008055311340478257\n",
      "train loss:0.005633645671802507\n",
      "train loss:0.04435812701106686\n",
      "train loss:0.07883268357839392\n",
      "train loss:0.01733054027225027\n",
      "train loss:0.007918604538674691\n",
      "train loss:0.037690204636627325\n",
      "train loss:0.0076918406937035765\n",
      "train loss:0.004540556419821561\n",
      "train loss:0.006069560377099849\n",
      "train loss:0.019306278755976427\n",
      "train loss:0.00845551719168085\n",
      "train loss:0.007627735907227136\n",
      "train loss:0.019197133221547362\n",
      "train loss:0.05138286464219988\n",
      "train loss:0.011415043515079127\n",
      "train loss:0.04173265115429404\n",
      "train loss:0.024960735956257127\n",
      "train loss:0.01876638891756548\n",
      "train loss:0.062457344766257326\n",
      "train loss:0.012675152943455874\n",
      "train loss:0.005278294776340733\n",
      "train loss:0.003744329538389714\n",
      "train loss:0.06321521848940045\n",
      "train loss:0.019261882311943396\n",
      "train loss:0.003080233832673787\n",
      "train loss:0.009128506899269551\n",
      "train loss:0.023438890897540608\n",
      "train loss:0.006744496420627909\n",
      "train loss:0.1155197452720123\n",
      "train loss:0.021004515143423365\n",
      "train loss:0.018126066409535117\n",
      "train loss:0.022388316161254505\n",
      "train loss:0.015255659710703482\n",
      "train loss:0.014759462457512387\n",
      "train loss:0.02061447231755947\n",
      "train loss:0.008926189334056374\n",
      "train loss:0.04293785376685753\n",
      "train loss:0.024700774709413554\n",
      "train loss:0.005525501950830891\n",
      "train loss:0.060434089661716664\n",
      "train loss:0.02039634054976045\n",
      "train loss:0.018271199965440653\n",
      "train loss:0.09280732021567459\n",
      "train loss:0.044164317799329576\n",
      "train loss:0.007494909636953735\n",
      "train loss:0.04964719878472982\n",
      "train loss:0.014634984700195933\n",
      "train loss:0.023041624232348096\n",
      "train loss:0.01440368015750781\n",
      "train loss:0.0035801150265598676\n",
      "train loss:0.01242958771209709\n",
      "train loss:0.007409992888894264\n",
      "train loss:0.014588260364304622\n",
      "train loss:0.04176474036775069\n",
      "train loss:0.02110420757451359\n",
      "train loss:0.028540881879505257\n",
      "train loss:0.009340464431471162\n",
      "train loss:0.019406470665691806\n",
      "train loss:0.004266686080403807\n",
      "train loss:0.008604754266771243\n",
      "train loss:0.016481388413607162\n",
      "train loss:0.010087944202424341\n",
      "train loss:0.011760489529275503\n",
      "train loss:0.017919011820485952\n",
      "train loss:0.013328252059946972\n",
      "train loss:0.006848576840353727\n",
      "train loss:0.004540252774790915\n",
      "train loss:0.010596107441350049\n",
      "train loss:0.008637309970357103\n",
      "train loss:0.013357668414710084\n",
      "train loss:0.01232871013336494\n",
      "train loss:0.024629969944207138\n",
      "train loss:0.028916850573877603\n",
      "train loss:0.017470092968777207\n",
      "train loss:0.01124592427746826\n",
      "train loss:0.03425465261590516\n",
      "train loss:0.01650997245502893\n",
      "train loss:0.005488839013635437\n",
      "train loss:0.053695865677442216\n",
      "train loss:0.037260965244695\n",
      "train loss:0.019046232452507066\n",
      "train loss:0.022623690082606066\n",
      "train loss:0.013164374744586175\n",
      "train loss:0.004524486384010594\n",
      "train loss:0.011903807504559471\n",
      "train loss:0.010802630999324901\n",
      "train loss:0.017582720105741693\n",
      "train loss:0.004013269342990437\n",
      "train loss:0.010449626546668738\n",
      "train loss:0.004551127987668448\n",
      "train loss:0.01505491101597509\n",
      "train loss:0.06826281609888654\n",
      "train loss:0.03987206170052226\n",
      "train loss:0.01096553073368682\n",
      "train loss:0.020982732486692093\n",
      "train loss:0.008446395691968735\n",
      "train loss:0.005156368538820317\n",
      "train loss:0.04729862959492863\n",
      "train loss:0.003306061751282813\n",
      "train loss:0.011353830237674736\n",
      "train loss:0.019894437035345082\n",
      "train loss:0.013490965202952983\n",
      "train loss:0.03519852343152907\n",
      "train loss:0.05222420823608096\n",
      "train loss:0.04856519207816519\n",
      "train loss:0.008986303616109675\n",
      "train loss:0.01622326584375022\n",
      "train loss:0.01615752944868515\n",
      "train loss:0.009468102406012428\n",
      "train loss:0.054427803972513546\n",
      "train loss:0.010378012404645063\n",
      "train loss:0.018068324068555405\n",
      "train loss:0.011092919714969156\n",
      "train loss:0.027269643578915308\n",
      "train loss:0.019839874403347384\n",
      "train loss:0.010159615014365533\n",
      "train loss:0.0014310879418959882\n",
      "train loss:0.010992486008508053\n",
      "train loss:0.025255929067851693\n",
      "train loss:0.003525735511768842\n",
      "train loss:0.019170863416323538\n",
      "train loss:0.0027345879374349015\n",
      "train loss:0.005554717307780253\n",
      "train loss:0.00213502053382554\n",
      "train loss:0.012790108088554195\n",
      "train loss:0.014248223967418538\n",
      "train loss:0.016231121065537736\n",
      "train loss:0.0022996522511368705\n",
      "train loss:0.005421710651608993\n",
      "train loss:0.009748274661812547\n",
      "train loss:0.005611677119376641\n",
      "train loss:0.00728173884847938\n",
      "train loss:0.0066245167116811025\n",
      "train loss:0.010242861751109595\n",
      "train loss:0.01658664688180073\n",
      "train loss:0.05700745591530554\n",
      "train loss:0.016336031836690083\n",
      "train loss:0.01456885574190218\n",
      "train loss:0.009719432059485979\n",
      "train loss:0.020994481709120185\n",
      "train loss:0.06361567682439719\n",
      "train loss:0.022169450134525058\n",
      "train loss:0.009165009067376889\n",
      "train loss:0.04402270470819175\n",
      "train loss:0.07497886939950965\n",
      "train loss:0.0089570471853466\n",
      "train loss:0.010582316795977853\n",
      "train loss:0.03473537377105285\n",
      "train loss:0.0027441993821541253\n",
      "train loss:0.03415645247358858\n",
      "train loss:0.011514386021453944\n",
      "train loss:0.03284349951312528\n",
      "train loss:0.007897262574811614\n",
      "train loss:0.021734508546076333\n",
      "train loss:0.026849195501722548\n",
      "train loss:0.031588357542359474\n",
      "train loss:0.006288655763149215\n",
      "train loss:0.007657835479608748\n",
      "train loss:0.005922407246107109\n",
      "train loss:0.03811925290611476\n",
      "train loss:0.007507841406278937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010290252178547335\n",
      "train loss:0.006470134410046637\n",
      "train loss:0.010114994229859436\n",
      "train loss:0.006384157275563215\n",
      "train loss:0.01886163241793398\n",
      "train loss:0.005735943748917136\n",
      "train loss:0.022022087163374168\n",
      "train loss:0.03555974920575478\n",
      "train loss:0.05350303683339157\n",
      "train loss:0.0052829838881730375\n",
      "train loss:0.004289488305671151\n",
      "train loss:0.006687247153205481\n",
      "train loss:0.0036930642730364977\n",
      "train loss:0.03063323763685732\n",
      "train loss:0.010526363167932387\n",
      "train loss:0.0030321539345989374\n",
      "train loss:0.012862716153765143\n",
      "train loss:0.004378753634304335\n",
      "train loss:0.05122454976110232\n",
      "train loss:0.007186344242819954\n",
      "train loss:0.03774906333237514\n",
      "train loss:0.003765280189380864\n",
      "train loss:0.01584641153099554\n",
      "train loss:0.006401196505656816\n",
      "train loss:0.0772928441112814\n",
      "train loss:0.008131655028735143\n",
      "train loss:0.012668283957125015\n",
      "train loss:0.0013790364535519691\n",
      "train loss:0.0119520872247629\n",
      "train loss:0.021741899622359534\n",
      "train loss:0.012438295293612043\n",
      "train loss:0.012260954429829284\n",
      "train loss:0.021013484534333562\n",
      "train loss:0.016722723015219744\n",
      "train loss:0.00904754841745923\n",
      "train loss:0.0031672671175944416\n",
      "train loss:0.006520685496697515\n",
      "train loss:0.0047256925302582445\n",
      "train loss:0.006952028814910901\n",
      "train loss:0.004802699714981542\n",
      "train loss:0.0436265528373076\n",
      "train loss:0.007259269533355348\n",
      "train loss:0.008811843281037816\n",
      "train loss:0.02122316392389332\n",
      "train loss:0.004253981827369466\n",
      "train loss:0.007971704998372638\n",
      "train loss:0.015453144560961318\n",
      "train loss:0.012447389527633284\n",
      "train loss:0.009219636414027555\n",
      "train loss:0.029126557828162553\n",
      "train loss:0.04085511749282869\n",
      "train loss:0.021155097863144515\n",
      "train loss:0.022838026808080593\n",
      "train loss:0.012504391615170923\n",
      "train loss:0.008359318886960227\n",
      "train loss:0.03794929825713647\n",
      "train loss:0.06906253947628435\n",
      "train loss:0.01303789913156772\n",
      "train loss:0.04112055988439655\n",
      "train loss:0.023584769027588836\n",
      "train loss:0.010489420947981387\n",
      "train loss:0.04625973980924392\n",
      "train loss:0.002618569761872082\n",
      "train loss:0.04723021729873086\n",
      "train loss:0.02269259672710695\n",
      "train loss:0.009981646842563191\n",
      "train loss:0.04556311691034669\n",
      "train loss:0.050740537570950345\n",
      "train loss:0.007085298931991442\n",
      "train loss:0.009786694304581038\n",
      "train loss:0.01753016861659608\n",
      "train loss:0.005332799470213848\n",
      "train loss:0.008821550211823563\n",
      "train loss:0.004573790908796838\n",
      "train loss:0.05303318696325319\n",
      "train loss:0.040233419939208294\n",
      "train loss:0.027169954820794394\n",
      "train loss:0.013672844619408478\n",
      "train loss:0.015819104574719644\n",
      "train loss:0.04497811420527983\n",
      "train loss:0.03174861287670354\n",
      "train loss:0.030563457561946058\n",
      "train loss:0.008525483965578541\n",
      "train loss:0.00884446736459547\n",
      "train loss:0.059894135326257876\n",
      "train loss:0.003979027021289036\n",
      "train loss:0.006046912710937943\n",
      "train loss:0.004043403678594099\n",
      "train loss:0.01163888024260122\n",
      "train loss:0.011966527269246862\n",
      "train loss:0.0055209950262219065\n",
      "train loss:0.028265296249174288\n",
      "train loss:0.1224653324052015\n",
      "train loss:0.006110042372955805\n",
      "train loss:0.00968678585937115\n",
      "train loss:0.016768142813758203\n",
      "train loss:0.00429170378487447\n",
      "train loss:0.017944630046264502\n",
      "train loss:0.03224455673900614\n",
      "train loss:0.006684946356811523\n",
      "train loss:0.005969358521379382\n",
      "train loss:0.0277194846413631\n",
      "train loss:0.0075742633135425196\n",
      "train loss:0.0025547234715357515\n",
      "train loss:0.01081171673282282\n",
      "train loss:0.01167931431628483\n",
      "train loss:0.055972344844297195\n",
      "train loss:0.0014869604088633376\n",
      "train loss:0.05156971697199296\n",
      "train loss:0.01800662777888877\n",
      "train loss:0.006657343064852083\n",
      "train loss:0.010457940485363068\n",
      "train loss:0.0008123059145598245\n",
      "train loss:0.014373059092734215\n",
      "train loss:0.02976000792754723\n",
      "train loss:0.03440044858052336\n",
      "train loss:0.012263184848771196\n",
      "train loss:0.01906485234590007\n",
      "train loss:0.012376554483410494\n",
      "train loss:0.06131152293527996\n",
      "train loss:0.03081304584206313\n",
      "train loss:0.021276761043208334\n",
      "train loss:0.00215222089970235\n",
      "train loss:0.009349262551601794\n",
      "train loss:0.001276063667146953\n",
      "train loss:0.05557064338742464\n",
      "train loss:0.03844308882081338\n",
      "train loss:0.0436217962118076\n",
      "train loss:0.003156706441262534\n",
      "train loss:0.007773621997483006\n",
      "train loss:0.01253545745849405\n",
      "train loss:0.005107967778482876\n",
      "train loss:0.005616574463177457\n",
      "train loss:0.002146183094917698\n",
      "train loss:0.013048022456283387\n",
      "train loss:0.010266729542217367\n",
      "train loss:0.04933030827924588\n",
      "train loss:0.011291449232119348\n",
      "train loss:0.0011060566561538483\n",
      "train loss:0.01242772675642909\n",
      "train loss:0.026078459172510303\n",
      "train loss:0.016886547671548985\n",
      "train loss:0.032403118478255555\n",
      "train loss:0.0186502913612438\n",
      "train loss:0.004214501864020415\n",
      "train loss:0.0020517511242444204\n",
      "train loss:0.009105569751326658\n",
      "train loss:0.008919479710474975\n",
      "train loss:0.006237997363014059\n",
      "train loss:0.05601727470039642\n",
      "train loss:0.007492616172528273\n",
      "train loss:0.017929805126398312\n",
      "train loss:0.02073526775946981\n",
      "train loss:0.002566543160183395\n",
      "train loss:0.02221762416269931\n",
      "train loss:0.013824882909705143\n",
      "train loss:0.0294886060423057\n",
      "train loss:0.040262979160612514\n",
      "train loss:0.012409628050031067\n",
      "train loss:0.01547543666346924\n",
      "train loss:0.003724343353840504\n",
      "train loss:0.021097053703936927\n",
      "train loss:0.009276042791512899\n",
      "train loss:0.03611213460698522\n",
      "train loss:0.014156750667802191\n",
      "train loss:0.011162893692493759\n",
      "train loss:0.015837403178112715\n",
      "train loss:0.0032516497579408985\n",
      "train loss:0.002066657514884123\n",
      "train loss:0.002969329257155805\n",
      "train loss:0.0030307561314817186\n",
      "train loss:0.033265349494237144\n",
      "train loss:0.007450814580301509\n",
      "train loss:0.019323654034238878\n",
      "train loss:0.009351800551497935\n",
      "train loss:0.010647971559018083\n",
      "train loss:0.008459760104926231\n",
      "train loss:0.006856498569663967\n",
      "train loss:0.026975786412090322\n",
      "train loss:0.022408362728570906\n",
      "train loss:0.0353945736819445\n",
      "train loss:0.006898218675706348\n",
      "train loss:0.014920689607300988\n",
      "train loss:0.016672524856935565\n",
      "train loss:0.0050638847725429596\n",
      "train loss:0.005256643903248053\n",
      "train loss:0.006570262516740921\n",
      "train loss:0.008846580456144582\n",
      "=== epoch:7, train acc:0.989, test acc:0.985 ===\n",
      "train loss:0.00480834026055244\n",
      "train loss:0.009464972017135764\n",
      "train loss:0.01664483659959419\n",
      "train loss:0.04917307533836924\n",
      "train loss:0.011208699393848054\n",
      "train loss:0.01840089239588323\n",
      "train loss:0.009801672605804784\n",
      "train loss:0.01858017869295454\n",
      "train loss:0.008671208315017696\n",
      "train loss:0.015825289250484334\n",
      "train loss:0.006831309536370254\n",
      "train loss:0.01694258964616072\n",
      "train loss:0.0369092192644056\n",
      "train loss:0.03413700856476391\n",
      "train loss:0.009585131150892838\n",
      "train loss:0.024779238462065457\n",
      "train loss:0.01554851513105337\n",
      "train loss:0.021450682575673792\n",
      "train loss:0.04276805312100969\n",
      "train loss:0.005702584504258463\n",
      "train loss:0.02168429218309413\n",
      "train loss:0.04432420799339383\n",
      "train loss:0.022385950824283365\n",
      "train loss:0.009388613719637747\n",
      "train loss:0.002803170686210386\n",
      "train loss:0.05009626441985442\n",
      "train loss:0.03767132908470292\n",
      "train loss:0.03608096202645282\n",
      "train loss:0.011923864748067439\n",
      "train loss:0.008392718445997722\n",
      "train loss:0.03381540974053972\n",
      "train loss:0.05457366382638343\n",
      "train loss:0.014468378544043254\n",
      "train loss:0.002750837509641206\n",
      "train loss:0.00415022010370591\n",
      "train loss:0.03686626032935083\n",
      "train loss:0.042275013131528524\n",
      "train loss:0.10070722679841537\n",
      "train loss:0.008640165160958516\n",
      "train loss:0.018776900517793682\n",
      "train loss:0.060292089730020704\n",
      "train loss:0.006602507887531464\n",
      "train loss:0.024843626884625877\n",
      "train loss:0.015949170527616477\n",
      "train loss:0.018182759714540395\n",
      "train loss:0.03998786336865863\n",
      "train loss:0.0047164900275204185\n",
      "train loss:0.020911395322976825\n",
      "train loss:0.011234396407330524\n",
      "train loss:0.02480449233581978\n",
      "train loss:0.05982050313067224\n",
      "train loss:0.009999885006198046\n",
      "train loss:0.012013747848363353\n",
      "train loss:0.012887652012698168\n",
      "train loss:0.0034482899026872568\n",
      "train loss:0.011460039691994281\n",
      "train loss:0.012759994412191812\n",
      "train loss:0.03377220713775567\n",
      "train loss:0.0071668194323834\n",
      "train loss:0.019145749253731578\n",
      "train loss:0.0180347669373918\n",
      "train loss:0.018767496002282048\n",
      "train loss:0.06760894375683307\n",
      "train loss:0.005830329998662086\n",
      "train loss:0.011701183875183652\n",
      "train loss:0.0030633715047396555\n",
      "train loss:0.04511089040237248\n",
      "train loss:0.030830165641963978\n",
      "train loss:0.0030390199635442223\n",
      "train loss:0.036423923141344836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.016420573753789407\n",
      "train loss:0.04587017759622752\n",
      "train loss:0.025907699265470447\n",
      "train loss:0.01824308672938227\n",
      "train loss:0.019968495997982585\n",
      "train loss:0.00955695240900857\n",
      "train loss:0.030680384488521985\n",
      "train loss:0.02089902387325201\n",
      "train loss:0.03799864843037149\n",
      "train loss:0.009395710485731299\n",
      "train loss:0.0322821212311819\n",
      "train loss:0.003904749697489776\n",
      "train loss:0.0670667767341076\n",
      "train loss:0.013021021819336835\n",
      "train loss:0.04162541071909362\n",
      "train loss:0.014326859222497278\n",
      "train loss:0.06382921333565922\n",
      "train loss:0.05158635411539098\n",
      "train loss:0.037752472072021176\n",
      "train loss:0.04140578868438441\n",
      "train loss:0.010514030864501549\n",
      "train loss:0.004913600077566443\n",
      "train loss:0.011103084298596173\n",
      "train loss:0.003260056417982579\n",
      "train loss:0.0173112945639159\n",
      "train loss:0.017918034301855953\n",
      "train loss:0.004874705286281807\n",
      "train loss:0.0035227822232258045\n",
      "train loss:0.006774316901823951\n",
      "train loss:0.01743582153950585\n",
      "train loss:0.007935894797263098\n",
      "train loss:0.0041041992310010345\n",
      "train loss:0.02652706609933913\n",
      "train loss:0.0017780937422300952\n",
      "train loss:0.037795615763230754\n",
      "train loss:0.0192822799533012\n",
      "train loss:0.009026589923239367\n",
      "train loss:0.004545107424858114\n",
      "train loss:0.04754012028855398\n",
      "train loss:0.016681437549134856\n",
      "train loss:0.006462381239477784\n",
      "train loss:0.04053770186049722\n",
      "train loss:0.006630203935268872\n",
      "train loss:0.02655142855953936\n",
      "train loss:0.011745029793359394\n",
      "train loss:0.01995637469918074\n",
      "train loss:0.009092780382919252\n",
      "train loss:0.006225240820703966\n",
      "train loss:0.0066540159262665315\n",
      "train loss:0.006566470833347344\n",
      "train loss:0.007362114486280713\n",
      "train loss:0.03588395111564906\n",
      "train loss:0.018554716994557244\n",
      "train loss:0.03190991240616741\n",
      "train loss:0.03395915064764963\n",
      "train loss:0.008435293882103791\n",
      "train loss:0.04623067551941237\n",
      "train loss:0.007609117069158902\n",
      "train loss:0.024158977774711057\n",
      "train loss:0.06908912785266101\n",
      "train loss:0.036044403912550774\n",
      "train loss:0.009764611752301908\n",
      "train loss:0.01614714509983832\n",
      "train loss:0.01310006106448226\n",
      "train loss:0.007749344431192871\n",
      "train loss:0.020661458984331506\n",
      "train loss:0.06455861355667447\n",
      "train loss:0.03470679926370049\n",
      "train loss:0.05202108079970626\n",
      "train loss:0.024505358649098932\n",
      "train loss:0.025135464874423866\n",
      "train loss:0.011316705000162033\n",
      "train loss:0.019850509500641197\n",
      "train loss:0.04596556910463576\n",
      "train loss:0.0024356160351147794\n",
      "train loss:0.09159548747658626\n",
      "train loss:0.00783685792313156\n",
      "train loss:0.049825197520313134\n",
      "train loss:0.023157079168268688\n",
      "train loss:0.004825754684636984\n",
      "train loss:0.014531439648242848\n",
      "train loss:0.006017107130569258\n",
      "train loss:0.0024831777819035645\n",
      "train loss:0.02017155413583256\n",
      "train loss:0.017106478013710836\n",
      "train loss:0.024999384975060823\n",
      "train loss:0.011553913015315347\n",
      "train loss:0.024895981853715533\n",
      "train loss:0.01902625637915441\n",
      "train loss:0.04584674632178408\n",
      "train loss:0.0077789661033540545\n",
      "train loss:0.020564350896825165\n",
      "train loss:0.005669607879232589\n",
      "train loss:0.014758184362802008\n",
      "train loss:0.015760401411444636\n",
      "train loss:0.01394608858234667\n",
      "train loss:0.00720858113690379\n",
      "train loss:0.003069009772988793\n",
      "train loss:0.0017296972879769779\n",
      "train loss:0.0019454128867841972\n",
      "train loss:0.00446598896063751\n",
      "train loss:0.006587792064531465\n",
      "train loss:0.027860158314742624\n",
      "train loss:0.056623470988754636\n",
      "train loss:0.03314776343023155\n",
      "train loss:0.02676599834651797\n",
      "train loss:0.0474098103266037\n",
      "train loss:0.017587069892495737\n",
      "train loss:0.05710022031798223\n",
      "train loss:0.019743854477540655\n",
      "train loss:0.031755369264173355\n",
      "train loss:0.0030994938309651865\n",
      "train loss:0.013613181111278759\n",
      "train loss:0.030297000683451994\n",
      "train loss:0.022403253751202546\n",
      "train loss:0.011985067438396911\n",
      "train loss:0.006495366126737215\n",
      "train loss:0.0034082368893874537\n",
      "train loss:0.02680082046029916\n",
      "train loss:0.03864834436896916\n",
      "train loss:0.009682638704128353\n",
      "train loss:0.0053810551564794865\n",
      "train loss:0.0344740589031412\n",
      "train loss:0.06822102528833883\n",
      "train loss:0.02539574938757847\n",
      "train loss:0.04128522537555832\n",
      "train loss:0.08363663285450168\n",
      "train loss:0.011216036083549472\n",
      "train loss:0.020181870105625124\n",
      "train loss:0.012926894482894066\n",
      "train loss:0.02972238179779626\n",
      "train loss:0.03106392333932519\n",
      "train loss:0.007910994147224088\n",
      "train loss:0.005602491491029434\n",
      "train loss:0.031618152752496353\n",
      "train loss:0.013836645364296527\n",
      "train loss:0.01195290637849384\n",
      "train loss:0.04671751535955854\n",
      "train loss:0.03951579541145047\n",
      "train loss:0.013107216501923384\n",
      "train loss:0.0076181841183197655\n",
      "train loss:0.010855453409516498\n",
      "train loss:0.009477434139669687\n",
      "train loss:0.01095701782789361\n",
      "train loss:0.009741110104169316\n",
      "train loss:0.01713745765782738\n",
      "train loss:0.04178126357494444\n",
      "train loss:0.0063178498677102625\n",
      "train loss:0.03876528346618379\n",
      "train loss:0.00817428559457278\n",
      "train loss:0.007255890619664332\n",
      "train loss:0.00357901280885781\n",
      "train loss:0.006288348206104411\n",
      "train loss:0.0065632501910349896\n",
      "train loss:0.009197196923644735\n",
      "train loss:0.012089332022832371\n",
      "train loss:0.00932974008616591\n",
      "train loss:0.0010826926012794536\n",
      "train loss:0.005459485671698297\n",
      "train loss:0.025875022767656092\n",
      "train loss:0.0073068678688813305\n",
      "train loss:0.0041241210499587\n",
      "train loss:0.00724731686925372\n",
      "train loss:0.03852145976741648\n",
      "train loss:0.008779019251104721\n",
      "train loss:0.009760748476079828\n",
      "train loss:0.0022054965017037262\n",
      "train loss:0.00788898671844305\n",
      "train loss:0.011198948281695225\n",
      "train loss:0.046632254755673896\n",
      "train loss:0.0024943278253796\n",
      "train loss:0.03881488625341411\n",
      "train loss:0.013076897176946678\n",
      "train loss:0.02006537556646316\n",
      "train loss:0.011426035918948578\n",
      "train loss:0.00504496792168947\n",
      "train loss:0.05641254997744456\n",
      "train loss:0.009014784082753054\n",
      "train loss:0.004347830532097293\n",
      "train loss:0.03746929289537481\n",
      "train loss:0.0059310109679994606\n",
      "train loss:0.003809657402978792\n",
      "train loss:0.027734614680609327\n",
      "train loss:0.011068050738194725\n",
      "train loss:0.07895879675850569\n",
      "train loss:0.012238888683267234\n",
      "train loss:0.09662299593750051\n",
      "train loss:0.009888955654650968\n",
      "train loss:0.010141111384709498\n",
      "train loss:0.0396310238168609\n",
      "train loss:0.00525290399263749\n",
      "train loss:0.03867263900568601\n",
      "train loss:0.02487933246119732\n",
      "train loss:0.002917538115837154\n",
      "train loss:0.0036685874188884878\n",
      "train loss:0.008136242150982733\n",
      "train loss:0.00997475585005942\n",
      "train loss:0.0062122178937183805\n",
      "train loss:0.00864477891952918\n",
      "train loss:0.0030462744152075154\n",
      "train loss:0.0381844309986787\n",
      "train loss:0.004524062221063311\n",
      "train loss:0.02210766612066891\n",
      "train loss:0.021902775620865594\n",
      "train loss:0.014377474669511794\n",
      "train loss:0.017891049803873006\n",
      "train loss:0.0038530952597166175\n",
      "train loss:0.004395552405728361\n",
      "train loss:0.022228915654753167\n",
      "train loss:0.0055650214870890564\n",
      "train loss:0.02260384484729492\n",
      "train loss:0.023970140012471063\n",
      "train loss:0.012318734381117944\n",
      "train loss:0.004060492555274757\n",
      "train loss:0.004419656305567772\n",
      "train loss:0.010734612225446744\n",
      "train loss:0.0042954823518904115\n",
      "train loss:0.004129212893247439\n",
      "train loss:0.038860964732900065\n",
      "train loss:0.030013512082299663\n",
      "train loss:0.00948185175135606\n",
      "train loss:0.043933115858723906\n",
      "train loss:0.037980871458718125\n",
      "train loss:0.007420683621534257\n",
      "train loss:0.002418606885343894\n",
      "train loss:0.007255266728766006\n",
      "train loss:0.006546423793421154\n",
      "train loss:0.003842588931818799\n",
      "train loss:0.02566837402779792\n",
      "train loss:0.005972605636528006\n",
      "train loss:0.015757412560517808\n",
      "train loss:0.006826761056940503\n",
      "train loss:0.010152141765227772\n",
      "train loss:0.01727670275139048\n",
      "train loss:0.043249847717204776\n",
      "train loss:0.027519719739685145\n",
      "train loss:0.026767226644619543\n",
      "train loss:0.005606889087682948\n",
      "train loss:0.02139149770859602\n",
      "train loss:0.07080330243349672\n",
      "train loss:0.019298636980189982\n",
      "train loss:0.01573196353344303\n",
      "train loss:0.003127239202779472\n",
      "train loss:0.015177927928766039\n",
      "train loss:0.00924185469415549\n",
      "train loss:0.03622985586900804\n",
      "train loss:0.007107323864049843\n",
      "train loss:0.060531008672080375\n",
      "train loss:0.01014790091120668\n",
      "train loss:0.004546822662477003\n",
      "train loss:0.007976859003338787\n",
      "train loss:0.02331242413731445\n",
      "train loss:0.025986260007823246\n",
      "train loss:0.003938980657497945\n",
      "train loss:0.012875072888428273\n",
      "train loss:0.012560237408472098\n",
      "train loss:0.011766809867929376\n",
      "train loss:0.013124434035222536\n",
      "train loss:0.02437170066996205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010113648202025744\n",
      "train loss:0.00976715462132248\n",
      "train loss:0.012693745542631132\n",
      "train loss:0.00981589005474519\n",
      "train loss:0.007231651269237662\n",
      "train loss:0.011539182050286994\n",
      "train loss:0.06580694628706875\n",
      "train loss:0.028396374478040682\n",
      "train loss:0.060868047626588366\n",
      "train loss:0.008178243510289751\n",
      "train loss:0.05681567053666907\n",
      "train loss:0.017416029935104924\n",
      "train loss:0.024867592727523702\n",
      "train loss:0.015903542099173815\n",
      "train loss:0.03489466147374169\n",
      "train loss:0.005725333537799131\n",
      "train loss:0.031158076598815844\n",
      "train loss:0.04862486725053519\n",
      "train loss:0.004526175531068263\n",
      "train loss:0.014390812564869526\n",
      "train loss:0.005391096532019395\n",
      "train loss:0.004640991259366679\n",
      "train loss:0.014605881676761339\n",
      "train loss:0.015863792473336673\n",
      "train loss:0.05863567712441318\n",
      "train loss:0.014176730605523016\n",
      "train loss:0.01075435140327033\n",
      "train loss:0.0034112695633391876\n",
      "train loss:0.024670343034362954\n",
      "train loss:0.008797805268401328\n",
      "train loss:0.004102971513899913\n",
      "train loss:0.021136741670532477\n",
      "train loss:0.020974387519654202\n",
      "train loss:0.002741611146946989\n",
      "train loss:0.03660056476108023\n",
      "train loss:0.003573069188474118\n",
      "train loss:0.00531765368423774\n",
      "train loss:0.024094646239342783\n",
      "train loss:0.008031569807730097\n",
      "train loss:0.004333698534500221\n",
      "train loss:0.004333313277672934\n",
      "train loss:0.03466439687738852\n",
      "train loss:0.008601002536624705\n",
      "train loss:0.009226068143138736\n",
      "train loss:0.03306068399063866\n",
      "train loss:0.006367156441080487\n",
      "train loss:0.023367515861338103\n",
      "train loss:0.011101901414256132\n",
      "train loss:0.0065209023048268585\n",
      "train loss:0.02600641386595748\n",
      "train loss:0.0019132776445499162\n",
      "train loss:0.03391870030144018\n",
      "train loss:0.0019484904247583773\n",
      "train loss:0.005280307511988509\n",
      "train loss:0.005860703006063733\n",
      "train loss:0.013097725777229386\n",
      "train loss:0.015659882234509613\n",
      "train loss:0.01731676521672552\n",
      "train loss:0.018713116550826355\n",
      "train loss:0.019436079667877363\n",
      "train loss:0.004367394907205443\n",
      "train loss:0.0039515144719781785\n",
      "train loss:0.009396450144281424\n",
      "train loss:0.05283618812175131\n",
      "train loss:0.011562860157812258\n",
      "train loss:0.012709420619969478\n",
      "train loss:0.019174871971918736\n",
      "train loss:0.007674506323228041\n",
      "train loss:0.011395478276711083\n",
      "train loss:0.039158212173877285\n",
      "train loss:0.014840482755646957\n",
      "train loss:0.008190099183029632\n",
      "train loss:0.02327981121086543\n",
      "train loss:0.04881292629980165\n",
      "train loss:0.009713930429042627\n",
      "train loss:0.0035312624635294152\n",
      "train loss:0.011053416803071491\n",
      "train loss:0.0035107699232942713\n",
      "train loss:0.0544288423897273\n",
      "train loss:0.009669553903405525\n",
      "train loss:0.034182972529738204\n",
      "train loss:0.03837234671792175\n",
      "train loss:0.02056343216972499\n",
      "train loss:0.010167830271077483\n",
      "train loss:0.008021497520876459\n",
      "train loss:0.007973822009228424\n",
      "train loss:0.009337311634749445\n",
      "train loss:0.004237975668273519\n",
      "train loss:0.011450791234121292\n",
      "train loss:0.010151181966240064\n",
      "train loss:0.027520506472604938\n",
      "train loss:0.003144879540292303\n",
      "train loss:0.008551865779962748\n",
      "train loss:0.012051084013381761\n",
      "train loss:0.011906009618595014\n",
      "train loss:0.004728287624678714\n",
      "train loss:0.0036426541524848992\n",
      "train loss:0.003661083109025631\n",
      "train loss:0.0068223501620152515\n",
      "train loss:0.005636819349772151\n",
      "train loss:0.008824085064554898\n",
      "train loss:0.0038971224132866066\n",
      "train loss:0.004575518139284386\n",
      "train loss:0.015235704993331468\n",
      "train loss:0.009250768479175877\n",
      "train loss:0.003638009763592071\n",
      "train loss:0.00966108770939826\n",
      "train loss:0.0015644610442967085\n",
      "train loss:0.01651948885870283\n",
      "train loss:0.008298280358557272\n",
      "train loss:0.006241836167214232\n",
      "train loss:0.05351692736761476\n",
      "train loss:0.00812959995636442\n",
      "train loss:0.04202828294798896\n",
      "train loss:0.015439994265752082\n",
      "train loss:0.01936421843253573\n",
      "train loss:0.01764825594588329\n",
      "train loss:0.010975904606925331\n",
      "train loss:0.005374510972577302\n",
      "train loss:0.002873560622674207\n",
      "train loss:0.018759094624643192\n",
      "train loss:0.008539517606299358\n",
      "train loss:0.015663295245050172\n",
      "train loss:0.0012748007032662245\n",
      "train loss:0.004486061922225782\n",
      "train loss:0.018431783470209857\n",
      "train loss:0.07863113094541979\n",
      "train loss:0.010175261272153808\n",
      "train loss:0.003577838365495917\n",
      "train loss:0.011093597989267977\n",
      "train loss:0.024152377636863346\n",
      "train loss:0.022402113188417984\n",
      "train loss:0.003736864738804573\n",
      "train loss:0.02219184076342494\n",
      "train loss:0.014439616961570789\n",
      "train loss:0.0024007439150695443\n",
      "train loss:0.008632425866239095\n",
      "train loss:0.0025472172172025316\n",
      "train loss:0.008856920419507381\n",
      "train loss:0.011550265579600136\n",
      "train loss:0.011135331095927863\n",
      "train loss:0.061280009730533894\n",
      "train loss:0.036948026334874005\n",
      "train loss:0.008948899993273701\n",
      "train loss:0.003186646615803891\n",
      "train loss:0.001574204721500039\n",
      "train loss:0.0023519460818390526\n",
      "train loss:0.06493204117180701\n",
      "train loss:0.022919541311083022\n",
      "train loss:0.00730181601195489\n",
      "train loss:0.014150455367190022\n",
      "train loss:0.010162782780029536\n",
      "train loss:0.0031741408100548073\n",
      "train loss:0.02533664126743066\n",
      "train loss:0.006960799567704881\n",
      "train loss:0.021821779263350966\n",
      "train loss:0.0023225946049431397\n",
      "train loss:0.021760129318373133\n",
      "train loss:0.02150988097397301\n",
      "train loss:0.011288594868710757\n",
      "train loss:0.08269142217833618\n",
      "train loss:0.002417053027782107\n",
      "train loss:0.013725619694729968\n",
      "train loss:0.023819783737267376\n",
      "train loss:0.01596580361928386\n",
      "train loss:0.021677116608722707\n",
      "train loss:0.005178320822358192\n",
      "train loss:0.008055098319382097\n",
      "train loss:0.009478971280210375\n",
      "train loss:0.0024102940137094614\n",
      "train loss:0.0023155598018939996\n",
      "train loss:0.010493738734397167\n",
      "train loss:0.01166030173380695\n",
      "train loss:0.018917178860249916\n",
      "train loss:0.00844829803414001\n",
      "train loss:0.028975847471906735\n",
      "train loss:0.022662171145811292\n",
      "train loss:0.007603398203797404\n",
      "train loss:0.004371125701568116\n",
      "train loss:0.032824776636111073\n",
      "train loss:0.004539232810604301\n",
      "train loss:0.013087359430355059\n",
      "train loss:0.004888304872213457\n",
      "train loss:0.008895792138868375\n",
      "train loss:0.020583570000932555\n",
      "train loss:0.004245970839152443\n",
      "train loss:0.020301384194560904\n",
      "train loss:0.007085734411462673\n",
      "train loss:0.004500426290835461\n",
      "train loss:0.010328603847453502\n",
      "train loss:0.006887151507861248\n",
      "train loss:0.023674764724166124\n",
      "train loss:0.017170223905707112\n",
      "train loss:0.00558515985127161\n",
      "train loss:0.031030825256046782\n",
      "train loss:0.034323864773850694\n",
      "train loss:0.05315556683429887\n",
      "train loss:0.03440316930634258\n",
      "train loss:0.009959948919440596\n",
      "train loss:0.014630397328490658\n",
      "train loss:0.009344650587291024\n",
      "train loss:0.046824942319861285\n",
      "train loss:0.008317538360567249\n",
      "train loss:0.011889100940724122\n",
      "train loss:0.002256966981863265\n",
      "train loss:0.002674315377930111\n",
      "train loss:0.011310632538130232\n",
      "train loss:0.002412297395246276\n",
      "train loss:0.01551484107379368\n",
      "train loss:0.0032814945777359726\n",
      "train loss:0.004218209574007052\n",
      "train loss:0.028685901507820542\n",
      "train loss:0.007248225163048774\n",
      "train loss:0.00825744745607589\n",
      "train loss:0.03075084111123837\n",
      "train loss:0.023725447140306465\n",
      "train loss:0.006372198695083323\n",
      "train loss:0.010673341177461366\n",
      "train loss:0.006071915785793375\n",
      "train loss:0.0017563713121702348\n",
      "train loss:0.0368235968599992\n",
      "train loss:0.01790615716155239\n",
      "train loss:0.003948965305528243\n",
      "train loss:0.01146879988404585\n",
      "train loss:0.008576559884904784\n",
      "train loss:0.010293968370275368\n",
      "train loss:0.07418307141738655\n",
      "train loss:0.010873328727244327\n",
      "train loss:0.034242464105969685\n",
      "train loss:0.016653595560332052\n",
      "train loss:0.024275167593839013\n",
      "train loss:0.023510820662437513\n",
      "train loss:0.014585390511357281\n",
      "train loss:0.012985220507915484\n",
      "train loss:0.017717052121490977\n",
      "train loss:0.013888257547178458\n",
      "train loss:0.011334638663755945\n",
      "train loss:0.015843096481690574\n",
      "train loss:0.002986333120627151\n",
      "train loss:0.013309269609702034\n",
      "train loss:0.03904690497080421\n",
      "train loss:0.007887822926816506\n",
      "train loss:0.0081841629604579\n",
      "train loss:0.007187665784888336\n",
      "train loss:0.016197573172299362\n",
      "train loss:0.01996641519675137\n",
      "train loss:0.057049044137820075\n",
      "train loss:0.003680753263317692\n",
      "train loss:0.014717104735626643\n",
      "train loss:0.019577421696180996\n",
      "train loss:0.012981409569324663\n",
      "train loss:0.007041027149823925\n",
      "train loss:0.026111002187048468\n",
      "train loss:0.018837565764223064\n",
      "train loss:0.0036287126315639917\n",
      "train loss:0.018032523579775927\n",
      "train loss:0.018542191495508367\n",
      "train loss:0.012609626030866662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010661659718265276\n",
      "train loss:0.04372257102055211\n",
      "train loss:0.006773170547700167\n",
      "train loss:0.012474979320776665\n",
      "train loss:0.010294622020274691\n",
      "train loss:0.008700681502146049\n",
      "train loss:0.010006233086847753\n",
      "train loss:0.008768486626981346\n",
      "train loss:0.003948440449792484\n",
      "train loss:0.007425805150486754\n",
      "train loss:0.009172393569989466\n",
      "train loss:0.00447149954747373\n",
      "train loss:0.007756962799302355\n",
      "=== epoch:8, train acc:0.99, test acc:0.986 ===\n",
      "train loss:0.022470008220119717\n",
      "train loss:0.01746510918871458\n",
      "train loss:0.018716028300770685\n",
      "train loss:0.004910646413981184\n",
      "train loss:0.01306646769765947\n",
      "train loss:0.006515135675197981\n",
      "train loss:0.0027014324261400054\n",
      "train loss:0.02416310441048461\n",
      "train loss:0.0018059514457626085\n",
      "train loss:0.0038557432327468873\n",
      "train loss:0.0020926367251472007\n",
      "train loss:0.020805181091221328\n",
      "train loss:0.03369655169321903\n",
      "train loss:0.02300259209942371\n",
      "train loss:0.03751089289922349\n",
      "train loss:0.017765260857083718\n",
      "train loss:0.05603892727826554\n",
      "train loss:0.01699025808037375\n",
      "train loss:0.010091564758048866\n",
      "train loss:0.015333209822647647\n",
      "train loss:0.012825836591440298\n",
      "train loss:0.004094024054954504\n",
      "train loss:0.01298003443302471\n",
      "train loss:0.0016294667542329014\n",
      "train loss:0.005498280980606232\n",
      "train loss:0.01152483801293584\n",
      "train loss:0.012520454437510473\n",
      "train loss:0.02025275474165373\n",
      "train loss:0.007270278160828567\n",
      "train loss:0.008323637239636882\n",
      "train loss:0.004267823421671187\n",
      "train loss:0.014950922086920886\n",
      "train loss:0.0019274823344202169\n",
      "train loss:0.04597787877607885\n",
      "train loss:0.019393119382922007\n",
      "train loss:0.030760164644227886\n",
      "train loss:0.01353906749391529\n",
      "train loss:0.027149583230874887\n",
      "train loss:0.007283924218608981\n",
      "train loss:0.07145762400238526\n",
      "train loss:0.005836896691881547\n",
      "train loss:0.0250048875027029\n",
      "train loss:0.013124891548520898\n",
      "train loss:0.009436793462920338\n",
      "train loss:0.0061341062369265195\n",
      "train loss:0.003192543706321444\n",
      "train loss:0.004465544559919845\n",
      "train loss:0.004710172126217411\n",
      "train loss:0.010590455159827867\n",
      "train loss:0.00969834740660413\n",
      "train loss:0.013645731136371471\n",
      "train loss:0.013538932019210179\n",
      "train loss:0.008578363983827126\n",
      "train loss:0.0032507214384269304\n",
      "train loss:0.005320193871771401\n",
      "train loss:0.03572859336555131\n",
      "train loss:0.026287461431648933\n",
      "train loss:0.023717017012667218\n",
      "train loss:0.02547831284640259\n",
      "train loss:0.00931446106858161\n",
      "train loss:0.0021395725825173193\n",
      "train loss:0.0275816315665902\n",
      "train loss:0.0017327221195601523\n",
      "train loss:0.008804390263378675\n",
      "train loss:0.02688437198415687\n",
      "train loss:0.026934518223759828\n",
      "train loss:0.012285885829105564\n",
      "train loss:0.0038699821903934884\n",
      "train loss:0.008113831047323624\n",
      "train loss:0.01219381546802361\n",
      "train loss:0.015494744463850563\n",
      "train loss:0.004056801851994515\n",
      "train loss:0.0035421217485410877\n",
      "train loss:0.05495698272557501\n",
      "train loss:0.0026892926335995598\n",
      "train loss:0.004669016711572155\n",
      "train loss:0.0045103986409649995\n",
      "train loss:0.005430264836750083\n",
      "train loss:0.04765550471487971\n",
      "train loss:0.004226687743666799\n",
      "train loss:0.003134539413640147\n",
      "train loss:0.008072625173488605\n",
      "train loss:0.013065409952794215\n",
      "train loss:0.0010433606837060854\n",
      "train loss:0.007542048215882768\n",
      "train loss:0.010852867137643924\n",
      "train loss:0.014451439504947348\n",
      "train loss:0.007108776158331582\n",
      "train loss:0.003325227924573691\n",
      "train loss:0.02624371715002927\n",
      "train loss:0.006318173609090523\n",
      "train loss:0.0019623635134761687\n",
      "train loss:0.03282823013577334\n",
      "train loss:0.005613321915367901\n",
      "train loss:0.005989312637121149\n",
      "train loss:0.01434569438471841\n",
      "train loss:0.02195474804212821\n",
      "train loss:0.02410521254176893\n",
      "train loss:0.011123618139273005\n",
      "train loss:0.030318229334596568\n",
      "train loss:0.006048364780636243\n",
      "train loss:0.02657944947810943\n",
      "train loss:0.0011882904878966582\n",
      "train loss:0.004687531083269389\n",
      "train loss:0.008279859889094576\n",
      "train loss:0.008241525145077729\n",
      "train loss:0.007367967418520887\n",
      "train loss:0.008594599076170294\n",
      "train loss:0.020248782451435327\n",
      "train loss:0.008691152513801655\n",
      "train loss:0.002796009501339568\n",
      "train loss:0.013415177395398438\n",
      "train loss:0.006151069457068278\n",
      "train loss:0.15577352197714592\n",
      "train loss:0.015278818488032206\n",
      "train loss:0.017581431190798878\n",
      "train loss:0.01083978353173596\n",
      "train loss:0.003990291460875742\n",
      "train loss:0.029314620865988156\n",
      "train loss:0.019713888011630515\n",
      "train loss:0.04833039916325878\n",
      "train loss:0.02525157362376256\n",
      "train loss:0.00535011397548099\n",
      "train loss:0.01501478794470928\n",
      "train loss:0.011106966994900856\n",
      "train loss:0.0035621616631917007\n",
      "train loss:0.008358046393218306\n",
      "train loss:0.005175959272863626\n",
      "train loss:0.00857919875079665\n",
      "train loss:0.00840117938692482\n",
      "train loss:0.015604184587328138\n",
      "train loss:0.009252419511614441\n",
      "train loss:0.002191188006217358\n",
      "train loss:0.00496490955579238\n",
      "train loss:0.04690753855975305\n",
      "train loss:0.019936248864586906\n",
      "train loss:0.0116114391738722\n",
      "train loss:0.004129976705070336\n",
      "train loss:0.017131575136215643\n",
      "train loss:0.02845530423939422\n",
      "train loss:0.0008679193597437386\n",
      "train loss:0.02544814390299627\n",
      "train loss:0.0037607179271126447\n",
      "train loss:0.009779561900979464\n",
      "train loss:0.030737568902346385\n",
      "train loss:0.00369700673934231\n",
      "train loss:0.006614445922542269\n",
      "train loss:0.0028196296300293778\n",
      "train loss:0.012302354552744114\n",
      "train loss:0.005167112136596092\n",
      "train loss:0.011486861544127007\n",
      "train loss:0.002911590501965721\n",
      "train loss:0.006849619688276342\n",
      "train loss:0.002292018817188454\n",
      "train loss:0.0023240543385137195\n",
      "train loss:0.010932840966438621\n",
      "train loss:0.003424115426878263\n",
      "train loss:0.016045564248187025\n",
      "train loss:0.0101284525067427\n",
      "train loss:0.015035987734873855\n",
      "train loss:0.014018350105620461\n",
      "train loss:0.0024543831960287454\n",
      "train loss:0.10868530913961631\n",
      "train loss:0.005520746494231964\n",
      "train loss:0.0051236897707891945\n",
      "train loss:0.01422453172994317\n",
      "train loss:0.015938043319450677\n",
      "train loss:0.015257026422801169\n",
      "train loss:0.0266232529422785\n",
      "train loss:0.016547789788903988\n",
      "train loss:0.004696181430093118\n",
      "train loss:0.0035067108546689824\n",
      "train loss:0.025474224569020914\n",
      "train loss:0.014290883555055964\n",
      "train loss:0.08976857677315996\n",
      "train loss:0.014312659071889477\n",
      "train loss:0.015619941923894489\n",
      "train loss:0.0060207201218357535\n",
      "train loss:0.024631784958509578\n",
      "train loss:0.021981999284448713\n",
      "train loss:0.0031088228864405553\n",
      "train loss:0.02805277460332029\n",
      "train loss:0.00699169557319622\n",
      "train loss:0.02361769746665944\n",
      "train loss:0.0084200326314713\n",
      "train loss:0.08157063496076594\n",
      "train loss:0.015644871518898852\n",
      "train loss:0.026469636027198172\n",
      "train loss:0.019526650166137638\n",
      "train loss:0.004172296977644441\n",
      "train loss:0.0016497462279162938\n",
      "train loss:0.005484186488815186\n",
      "train loss:0.009363301969731445\n",
      "train loss:0.009227035279449097\n",
      "train loss:0.0194586995135536\n",
      "train loss:0.08566435934762455\n",
      "train loss:0.008566942786117259\n",
      "train loss:0.05124982447894084\n",
      "train loss:0.006281931420968152\n",
      "train loss:0.0073397507394284385\n",
      "train loss:0.013026125882735731\n",
      "train loss:0.0017790998955057164\n",
      "train loss:0.050461120968920914\n",
      "train loss:0.006795040486015543\n",
      "train loss:0.012158077492487897\n",
      "train loss:0.011028714593226553\n",
      "train loss:0.013929410846434835\n",
      "train loss:0.008096578011102359\n",
      "train loss:0.017851255833002146\n",
      "train loss:0.01458428736016571\n",
      "train loss:0.03176703318872294\n",
      "train loss:0.008181532708393108\n",
      "train loss:0.012462332715010547\n",
      "train loss:0.012727809921882433\n",
      "train loss:0.02277779652412881\n",
      "train loss:0.008670127115890072\n",
      "train loss:0.01164112246515706\n",
      "train loss:0.0014595946050726541\n",
      "train loss:0.016804764752150647\n",
      "train loss:0.08734368368327482\n",
      "train loss:0.003651473144595118\n",
      "train loss:0.005076552111782777\n",
      "train loss:0.005543529138816842\n",
      "train loss:0.01801743666495072\n",
      "train loss:0.03392289958449765\n",
      "train loss:0.0062736261636825745\n",
      "train loss:0.007357371771951133\n",
      "train loss:0.005886956667503221\n",
      "train loss:0.008114991376537201\n",
      "train loss:0.06291138017606987\n",
      "train loss:0.014858647770766113\n",
      "train loss:0.024105345574956926\n",
      "train loss:0.005206966994955543\n",
      "train loss:0.010280232180322297\n",
      "train loss:0.010571518420088584\n",
      "train loss:0.0013977605693698328\n",
      "train loss:0.012187044625826513\n",
      "train loss:0.0042845149369903305\n",
      "train loss:0.01497018085540785\n",
      "train loss:0.004683392177896017\n",
      "train loss:0.03311469587231607\n",
      "train loss:0.0097011492627853\n",
      "train loss:0.006448854474522034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01295783299535254\n",
      "train loss:0.02182270276878586\n",
      "train loss:0.006152628046275458\n",
      "train loss:0.017790942644841528\n",
      "train loss:0.007723360689975122\n",
      "train loss:0.008367976152984463\n",
      "train loss:0.0076324885840002524\n",
      "train loss:0.06452782036462583\n",
      "train loss:0.006705373080339528\n",
      "train loss:0.0024045220526029564\n",
      "train loss:0.03083586051543316\n",
      "train loss:0.004187144894868965\n",
      "train loss:0.04019586568914191\n",
      "train loss:0.04036249787082771\n",
      "train loss:0.0013049073560577045\n",
      "train loss:0.026264934846696314\n",
      "train loss:0.007400986726721028\n",
      "train loss:0.028026447831667002\n",
      "train loss:0.06444307086507828\n",
      "train loss:0.026120941448470027\n",
      "train loss:0.0030101112038844356\n",
      "train loss:0.019261701491913332\n",
      "train loss:0.004870430520179536\n",
      "train loss:0.02539398265463229\n",
      "train loss:0.04157205025926901\n",
      "train loss:0.017235522142173644\n",
      "train loss:0.005837469051023685\n",
      "train loss:0.01326303863361953\n",
      "train loss:0.004461677514607336\n",
      "train loss:0.01119417873615538\n",
      "train loss:0.0012245361874901786\n",
      "train loss:0.015576418790805973\n",
      "train loss:0.0069914355061877565\n",
      "train loss:0.014861719348334822\n",
      "train loss:0.04116677046709645\n",
      "train loss:0.08043143835347896\n",
      "train loss:0.004021239344127181\n",
      "train loss:0.03847473784994189\n",
      "train loss:0.10374810060264855\n",
      "train loss:0.005462116260875838\n",
      "train loss:0.01116268564005445\n",
      "train loss:0.007719241503496983\n",
      "train loss:0.014285354503673433\n",
      "train loss:0.016551096409843504\n",
      "train loss:0.00372125546768011\n",
      "train loss:0.007507535452619699\n",
      "train loss:0.017954659031409217\n",
      "train loss:0.009001031832902663\n",
      "train loss:0.0065279876251199635\n",
      "train loss:0.006378208500923366\n",
      "train loss:0.012717409962451898\n",
      "train loss:0.03356186790363932\n",
      "train loss:0.011351693569702684\n",
      "train loss:0.008743241629365283\n",
      "train loss:0.00489575211636651\n",
      "train loss:0.012104754421466612\n",
      "train loss:0.010144260094108768\n",
      "train loss:0.0016920302878373774\n",
      "train loss:0.01982354392522256\n",
      "train loss:0.0024977875724928517\n",
      "train loss:0.002783550841324439\n",
      "train loss:0.006790805147845684\n",
      "train loss:0.004944459543300539\n",
      "train loss:0.01614102203898219\n",
      "train loss:0.007907632217693288\n",
      "train loss:0.008329383540624367\n",
      "train loss:0.0031082828833650868\n",
      "train loss:0.015466144800869054\n",
      "train loss:0.022203624703201096\n",
      "train loss:0.03937568996856426\n",
      "train loss:0.00940221136804445\n",
      "train loss:0.017033324112820006\n",
      "train loss:0.015374305687231892\n",
      "train loss:0.004877348972482437\n",
      "train loss:0.04817814671143067\n",
      "train loss:0.010411650164947779\n",
      "train loss:0.001480226169792034\n",
      "train loss:0.02684426373678165\n",
      "train loss:0.025287098069651882\n",
      "train loss:0.009933666496243873\n",
      "train loss:0.007758158312170297\n",
      "train loss:0.0034056207818876968\n",
      "train loss:0.0020472903506303175\n",
      "train loss:0.014548093567595614\n",
      "train loss:0.008513086309060563\n",
      "train loss:0.03188035229945732\n",
      "train loss:0.02081153020927331\n",
      "train loss:0.0019924162876127052\n",
      "train loss:0.0027671276535808924\n",
      "train loss:0.002608176611457631\n",
      "train loss:0.00166731335802101\n",
      "train loss:0.06103314273504511\n",
      "train loss:0.08138418630915183\n",
      "train loss:0.0030793672810184567\n",
      "train loss:0.0060135075587975486\n",
      "train loss:0.002385649452249143\n",
      "train loss:0.012591917188441486\n",
      "train loss:0.02389998781555363\n",
      "train loss:0.0065037683706811724\n",
      "train loss:0.0033353781043909164\n",
      "train loss:0.007528561827488436\n",
      "train loss:0.008080514835206196\n",
      "train loss:0.03484648694562657\n",
      "train loss:0.014376444705894982\n",
      "train loss:0.003303395967698278\n",
      "train loss:0.0024371866243074335\n",
      "train loss:0.012400090886864699\n",
      "train loss:0.025461279534489685\n",
      "train loss:0.004804562579762702\n",
      "train loss:0.0016427125954545788\n",
      "train loss:0.0178264116687511\n",
      "train loss:0.004310039094874888\n",
      "train loss:0.015276578007383246\n",
      "train loss:0.003908142822321302\n",
      "train loss:0.013912348227662014\n",
      "train loss:0.00854050101957428\n",
      "train loss:0.004508029348601754\n",
      "train loss:0.005520723732704449\n",
      "train loss:0.011881895903846244\n",
      "train loss:0.009986211482264773\n",
      "train loss:0.022229713565328487\n",
      "train loss:0.002146619147829447\n",
      "train loss:0.012436687132372353\n",
      "train loss:0.009504550671834712\n",
      "train loss:0.0010978493567756476\n",
      "train loss:0.003540668864815595\n",
      "train loss:0.009958118678215992\n",
      "train loss:0.0073701876180202784\n",
      "train loss:0.006935588662811065\n",
      "train loss:0.005179583151823586\n",
      "train loss:0.00934531794697826\n",
      "train loss:0.014986677456209567\n",
      "train loss:0.03225249420298244\n",
      "train loss:0.009663108453811487\n",
      "train loss:0.012828693485058485\n",
      "train loss:0.0022595006100520963\n",
      "train loss:0.003953176370299737\n",
      "train loss:0.018312454722080564\n",
      "train loss:0.007192932655713208\n",
      "train loss:0.001868449254798179\n",
      "train loss:0.0066653623471384545\n",
      "train loss:0.002638052317900769\n",
      "train loss:0.018033799235890928\n",
      "train loss:0.0020731755794903975\n",
      "train loss:0.0337852615429379\n",
      "train loss:0.005012494019460764\n",
      "train loss:0.006691587412057104\n",
      "train loss:0.0008768309246577256\n",
      "train loss:0.010493993536100135\n",
      "train loss:0.006893350336038554\n",
      "train loss:0.008356789289648127\n",
      "train loss:0.00446318807306508\n",
      "train loss:0.007946090027082523\n",
      "train loss:0.018908052967843605\n",
      "train loss:0.009714367118200128\n",
      "train loss:0.041870337939769534\n",
      "train loss:0.0028224557465291004\n",
      "train loss:0.016238400509158882\n",
      "train loss:0.015577532796705268\n",
      "train loss:0.01939903371198636\n",
      "train loss:0.025879891642684814\n",
      "train loss:0.005380174060484156\n",
      "train loss:0.005798439529899426\n",
      "train loss:0.0004940891771006732\n",
      "train loss:0.003049061633461012\n",
      "train loss:0.012841583018543346\n",
      "train loss:0.0055959002131585325\n",
      "train loss:0.0013254559829172766\n",
      "train loss:0.0025747209011875364\n",
      "train loss:0.007583014098473784\n",
      "train loss:0.005079829070149323\n",
      "train loss:0.012684809580998853\n",
      "train loss:0.0022285117431716955\n",
      "train loss:0.02391668660697793\n",
      "train loss:0.008025720648877917\n",
      "train loss:0.021718231711611757\n",
      "train loss:0.0016576674618480425\n",
      "train loss:0.05470342651634328\n",
      "train loss:0.0038068565072725403\n",
      "train loss:0.011499675759544066\n",
      "train loss:0.017044275158540245\n",
      "train loss:0.013269372050877708\n",
      "train loss:0.06462815939372211\n",
      "train loss:0.00155801489126177\n",
      "train loss:0.003252359337170558\n",
      "train loss:0.0068204625853391975\n",
      "train loss:0.001881080178010989\n",
      "train loss:0.005594322536888092\n",
      "train loss:0.005813480402574729\n",
      "train loss:0.006431389120903114\n",
      "train loss:0.004060564408676115\n",
      "train loss:0.0017768972256029833\n",
      "train loss:0.00549994116271925\n",
      "train loss:0.004094378047957539\n",
      "train loss:0.011436741065582618\n",
      "train loss:0.012299857383582635\n",
      "train loss:0.017524773905244914\n",
      "train loss:0.003787971160173586\n",
      "train loss:0.009997014970786443\n",
      "train loss:0.03525168079232596\n",
      "train loss:0.014135670425216476\n",
      "train loss:0.042971158153903184\n",
      "train loss:0.007459316478722487\n",
      "train loss:0.007543490217563748\n",
      "train loss:0.015524640059868079\n",
      "train loss:0.014491291562462073\n",
      "train loss:0.022346925901845102\n",
      "train loss:0.004049917627981892\n",
      "train loss:0.00797226161659157\n",
      "train loss:0.009395865543942405\n",
      "train loss:0.0067822371166913805\n",
      "train loss:0.016973647236294822\n",
      "train loss:0.008818741278503009\n",
      "train loss:0.014901894319270392\n",
      "train loss:0.016701726167159047\n",
      "train loss:0.0070915695219754315\n",
      "train loss:0.01278533905346095\n",
      "train loss:0.018947110030698978\n",
      "train loss:0.012738392013989545\n",
      "train loss:0.009351534955426715\n",
      "train loss:0.005335755608585089\n",
      "train loss:0.005464552042827551\n",
      "train loss:0.0028747057854215585\n",
      "train loss:0.006490104874568632\n",
      "train loss:0.0360799840409965\n",
      "train loss:0.013086803049135827\n",
      "train loss:0.021060511434134246\n",
      "train loss:0.0041758309852339475\n",
      "train loss:0.0018979426629468481\n",
      "train loss:0.019571776554871335\n",
      "train loss:0.007231839305385521\n",
      "train loss:0.019237556542142927\n",
      "train loss:0.02282773020385257\n",
      "train loss:0.014370445363498921\n",
      "train loss:0.018120451393804533\n",
      "train loss:0.011861908855917232\n",
      "train loss:0.011055019274835518\n",
      "train loss:0.04680432052788872\n",
      "train loss:0.009850095853725831\n",
      "train loss:0.009933237127145899\n",
      "train loss:0.0051631507986627\n",
      "train loss:0.013704044454290472\n",
      "train loss:0.006912953657744006\n",
      "train loss:0.023468713560682797\n",
      "train loss:0.00520800851024211\n",
      "train loss:0.008922474953667959\n",
      "train loss:0.024223141398296236\n",
      "train loss:0.01346283868380184\n",
      "train loss:0.005518649144033745\n",
      "train loss:0.02193963251489921\n",
      "train loss:0.005916058304649136\n",
      "train loss:0.012020444984070873\n",
      "train loss:0.0044512904193464275\n",
      "train loss:0.008233477287329084\n",
      "train loss:0.014519399104322832\n",
      "train loss:0.006530529347893128\n",
      "train loss:0.027625653613341763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004024586781451193\n",
      "train loss:0.0092994168516775\n",
      "train loss:0.014672428318073985\n",
      "train loss:0.030438760849302665\n",
      "train loss:0.00800255884697589\n",
      "train loss:0.07187169006769135\n",
      "train loss:0.0306599620800421\n",
      "train loss:0.001843722745903347\n",
      "train loss:0.011358970970229185\n",
      "train loss:0.029293854349588866\n",
      "train loss:0.026912139343815703\n",
      "train loss:0.014319793357790484\n",
      "train loss:0.00945566772177669\n",
      "train loss:0.011940776170785873\n",
      "train loss:0.002053492549998477\n",
      "train loss:0.0036155765046768135\n",
      "train loss:0.03590898820166511\n",
      "train loss:0.04957714605729833\n",
      "train loss:0.0053092538418599575\n",
      "train loss:0.016413687054518046\n",
      "train loss:0.004056026319208569\n",
      "train loss:0.004147121739105719\n",
      "train loss:0.017930134622452555\n",
      "train loss:0.01506955207174255\n",
      "train loss:0.06718724291178191\n",
      "train loss:0.012089540049575182\n",
      "train loss:0.010260683605337773\n",
      "train loss:0.006631606394748025\n",
      "train loss:0.002078841604694009\n",
      "train loss:0.0024881801764941643\n",
      "train loss:0.00544647116374204\n",
      "train loss:0.02239717092650586\n",
      "train loss:0.014701654686923466\n",
      "train loss:0.011987300518928245\n",
      "train loss:0.03545747209687888\n",
      "train loss:0.035602024352345836\n",
      "train loss:0.01678811211762785\n",
      "train loss:0.004640197793756797\n",
      "train loss:0.008417603592304021\n",
      "train loss:0.014336755020536489\n",
      "train loss:0.003181578969741426\n",
      "train loss:0.007081158344640484\n",
      "train loss:0.010636657194361618\n",
      "train loss:0.0014057901970414219\n",
      "train loss:0.011576011193630456\n",
      "train loss:0.0691311543941998\n",
      "train loss:0.025110598813960577\n",
      "train loss:0.007763738712324737\n",
      "train loss:0.00974509388713274\n",
      "train loss:0.04679954322569015\n",
      "train loss:0.006540561123030688\n",
      "train loss:0.08790427473310215\n",
      "train loss:0.0007108366512717948\n",
      "train loss:0.010704114158230629\n",
      "train loss:0.009887988778033036\n",
      "train loss:0.006570824099957851\n",
      "train loss:0.010101639959235503\n",
      "train loss:0.013462661665456725\n",
      "train loss:0.0076825355347200615\n",
      "train loss:0.0023661730494094137\n",
      "train loss:0.010625660352837938\n",
      "train loss:0.08401513101877434\n",
      "train loss:0.004952429691984916\n",
      "train loss:0.01603793085962344\n",
      "train loss:0.015672563683602158\n",
      "train loss:0.011701669921741691\n",
      "train loss:0.01878867773085867\n",
      "train loss:0.007767878185215884\n",
      "train loss:0.004745046684665808\n",
      "train loss:0.007950359911007218\n",
      "train loss:0.0036990946060520813\n",
      "train loss:0.010105422538328801\n",
      "train loss:0.007783716308987078\n",
      "train loss:0.007456892385160211\n",
      "train loss:0.004218777290619085\n",
      "train loss:0.006148886128388279\n",
      "train loss:0.003018170888331857\n",
      "train loss:0.06341655150586625\n",
      "train loss:0.007168067455206727\n",
      "train loss:0.011246016761392402\n",
      "train loss:0.0046015582486276276\n",
      "train loss:0.010752621519494599\n",
      "train loss:0.002634092024423785\n",
      "train loss:0.003640781284890182\n",
      "train loss:0.008195929109815385\n",
      "train loss:0.0016095496989640178\n",
      "train loss:0.020057140585578778\n",
      "train loss:0.0010066259107910868\n",
      "train loss:0.007790548253803079\n",
      "train loss:0.003274233852090477\n",
      "train loss:0.00423441379077735\n",
      "train loss:0.015017472279444206\n",
      "train loss:0.012460507441183676\n",
      "train loss:0.019212347559269066\n",
      "train loss:0.010314647281098354\n",
      "train loss:0.004007661430699405\n",
      "train loss:0.004710209281541014\n",
      "train loss:0.007883151463546755\n",
      "train loss:0.010689176547017322\n",
      "train loss:0.004449463785298843\n",
      "=== epoch:9, train acc:0.995, test acc:0.988 ===\n",
      "train loss:0.0008903274584290652\n",
      "train loss:0.005034813411140711\n",
      "train loss:0.003651904171074387\n",
      "train loss:0.006531872681457771\n",
      "train loss:0.004372184436963313\n",
      "train loss:0.007387008577738092\n",
      "train loss:0.0045839010293451275\n",
      "train loss:0.0026304913780765445\n",
      "train loss:0.0671987251282126\n",
      "train loss:0.004962225443112347\n",
      "train loss:0.0061877417688399675\n",
      "train loss:0.020538755696328716\n",
      "train loss:0.00994906299634811\n",
      "train loss:0.005477757803350358\n",
      "train loss:0.0006206781176486058\n",
      "train loss:0.011046707311184824\n",
      "train loss:0.005222989984230406\n",
      "train loss:0.001244239391340148\n",
      "train loss:0.0641654913117222\n",
      "train loss:0.003427782343783332\n",
      "train loss:0.020035378768247184\n",
      "train loss:0.022448630445812006\n",
      "train loss:0.010833775122105737\n",
      "train loss:0.008299092697940387\n",
      "train loss:0.0027743545460891554\n",
      "train loss:0.003808492316005387\n",
      "train loss:0.005749903802896849\n",
      "train loss:0.020352418488247394\n",
      "train loss:0.003159137140315475\n",
      "train loss:0.005472448015749611\n",
      "train loss:0.03002379296937739\n",
      "train loss:0.003255336283812748\n",
      "train loss:0.03308965861488751\n",
      "train loss:0.0032959088508499046\n",
      "train loss:0.030088769806348666\n",
      "train loss:0.010859781973593672\n",
      "train loss:0.010706337228115209\n",
      "train loss:0.0018568552317802702\n",
      "train loss:0.007888790349456318\n",
      "train loss:0.0025469157409955044\n",
      "train loss:0.049343101702836026\n",
      "train loss:0.006791084700589695\n",
      "train loss:0.0032299814418305923\n",
      "train loss:0.01481077696913939\n",
      "train loss:0.0026705491328223264\n",
      "train loss:0.005490550647477435\n",
      "train loss:0.0014911086455724146\n",
      "train loss:0.005329562045149609\n",
      "train loss:0.006277710130998936\n",
      "train loss:0.023310139646223128\n",
      "train loss:0.024898718097623188\n",
      "train loss:0.03250252700035776\n",
      "train loss:0.002142022323806136\n",
      "train loss:0.0023042969794649704\n",
      "train loss:0.002635559608488705\n",
      "train loss:0.01922424493272505\n",
      "train loss:0.010830443136408508\n",
      "train loss:0.0032303286106227956\n",
      "train loss:0.010125528282554785\n",
      "train loss:0.008447975962591683\n",
      "train loss:0.039370624986717555\n",
      "train loss:0.007209305043022977\n",
      "train loss:0.01743575599436456\n",
      "train loss:0.011134475243477236\n",
      "train loss:0.001051350388975767\n",
      "train loss:0.010726544228437995\n",
      "train loss:0.01285649911884922\n",
      "train loss:0.008440435009615842\n",
      "train loss:0.003029688904973866\n",
      "train loss:0.0098625734390655\n",
      "train loss:0.00705962349290286\n",
      "train loss:0.009341211520657235\n",
      "train loss:0.005214235870854587\n",
      "train loss:0.03381999077538856\n",
      "train loss:0.019022165071048435\n",
      "train loss:0.003622000850851152\n",
      "train loss:0.008017118678807217\n",
      "train loss:0.006288282421855965\n",
      "train loss:0.015440234413857485\n",
      "train loss:0.013623030484119152\n",
      "train loss:0.010852425170147504\n",
      "train loss:0.014623662970045904\n",
      "train loss:0.002832609754002952\n",
      "train loss:0.009294387650003925\n",
      "train loss:0.0021159824103582268\n",
      "train loss:0.025843805394832574\n",
      "train loss:0.02342390135118644\n",
      "train loss:0.00846222316024448\n",
      "train loss:0.007699849712105797\n",
      "train loss:0.0038046578547958937\n",
      "train loss:0.01479406503676125\n",
      "train loss:0.0024987587960062425\n",
      "train loss:0.004416611340012573\n",
      "train loss:0.003513386168077866\n",
      "train loss:0.0015936129387146526\n",
      "train loss:0.005498933005561076\n",
      "train loss:0.004321163728307233\n",
      "train loss:0.010845129372176987\n",
      "train loss:0.014042143666288275\n",
      "train loss:0.011549809415243488\n",
      "train loss:0.03059797620302325\n",
      "train loss:0.004408281386050845\n",
      "train loss:0.01252328223273192\n",
      "train loss:0.001749287502533951\n",
      "train loss:0.0030690605827985258\n",
      "train loss:0.007791725511714346\n",
      "train loss:0.0016695166222954485\n",
      "train loss:0.017474200206422374\n",
      "train loss:0.015730562002857697\n",
      "train loss:0.009133022272326135\n",
      "train loss:0.011418700760343372\n",
      "train loss:0.01559063652673663\n",
      "train loss:0.007783706615636035\n",
      "train loss:0.015206684904915948\n",
      "train loss:0.002923951535094074\n",
      "train loss:0.044599497036074215\n",
      "train loss:0.0015371704467386197\n",
      "train loss:0.012241720623385861\n",
      "train loss:0.010098826334897561\n",
      "train loss:0.022821114829708278\n",
      "train loss:0.007793424611147187\n",
      "train loss:0.013317195865179163\n",
      "train loss:0.01648619717800532\n",
      "train loss:0.0076624058496395754\n",
      "train loss:0.012102808557305594\n",
      "train loss:0.004195954335398706\n",
      "train loss:0.02508009941122586\n",
      "train loss:0.0064941758477294175\n",
      "train loss:0.006830636059980057\n",
      "train loss:0.012873467246225526\n",
      "train loss:0.018210889102044835\n",
      "train loss:0.0053925609009057626\n",
      "train loss:0.013010999999771846\n",
      "train loss:0.004290271299127159\n",
      "train loss:0.026849032456616465\n",
      "train loss:0.009850980105826322\n",
      "train loss:0.08811071505337244\n",
      "train loss:0.005812935339612253\n",
      "train loss:0.015066605429004454\n",
      "train loss:0.001877230631405691\n",
      "train loss:0.018470874639283173\n",
      "train loss:0.0028114286572615676\n",
      "train loss:0.00970935379000981\n",
      "train loss:0.0019440994455270006\n",
      "train loss:0.019686055471775977\n",
      "train loss:0.017882818592398625\n",
      "train loss:0.003965713250871007\n",
      "train loss:0.017279008971354492\n",
      "train loss:0.0367697170027652\n",
      "train loss:0.04271648544945475\n",
      "train loss:0.012936572828552019\n",
      "train loss:0.012739885271519402\n",
      "train loss:0.009021506128372664\n",
      "train loss:0.034727423934343526\n",
      "train loss:0.01389892093966395\n",
      "train loss:0.008036148657127727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005801635794712182\n",
      "train loss:0.004951273487879331\n",
      "train loss:0.0017524529225083412\n",
      "train loss:0.012206400250118392\n",
      "train loss:0.03384469327462032\n",
      "train loss:0.02269159362344243\n",
      "train loss:0.014020125562057395\n",
      "train loss:0.017977016652619478\n",
      "train loss:0.009369299101328088\n",
      "train loss:0.0032826066223989665\n",
      "train loss:0.0054795243104440935\n",
      "train loss:0.00667343380020581\n",
      "train loss:0.009398872872105512\n",
      "train loss:0.011934216596247195\n",
      "train loss:0.018072676904755378\n",
      "train loss:0.008880966122056369\n",
      "train loss:0.014015327291924813\n",
      "train loss:0.0025553336363714776\n",
      "train loss:0.004344990908876912\n",
      "train loss:0.011942035777119685\n",
      "train loss:0.0022893230435203265\n",
      "train loss:0.025012392417271365\n",
      "train loss:0.007618495793635679\n",
      "train loss:0.005004834929196082\n",
      "train loss:0.008608432132345363\n",
      "train loss:0.00822268031172678\n",
      "train loss:0.005287750474821221\n",
      "train loss:0.014606205914592281\n",
      "train loss:0.0007720556008776851\n",
      "train loss:0.015444289464883396\n",
      "train loss:0.0028300351655550482\n",
      "train loss:0.006974804382480291\n",
      "train loss:0.010463372311544834\n",
      "train loss:0.0031335503856843635\n",
      "train loss:0.01209192176132244\n",
      "train loss:0.0035459967432277745\n",
      "train loss:0.030865620167950122\n",
      "train loss:0.013114572559602246\n",
      "train loss:0.002555724635328987\n",
      "train loss:0.0023563034839392616\n",
      "train loss:0.012591414237250147\n",
      "train loss:0.01387025062196063\n",
      "train loss:0.0021571696803175306\n",
      "train loss:0.0014489792852180375\n",
      "train loss:0.010103767283708693\n",
      "train loss:0.010213725783943996\n",
      "train loss:0.00959384651087619\n",
      "train loss:0.004029927834056438\n",
      "train loss:0.027449391302032663\n",
      "train loss:0.0024066282219403806\n",
      "train loss:0.0273627831611904\n",
      "train loss:0.013180421097905445\n",
      "train loss:0.002580665391192212\n",
      "train loss:0.0018050952868000265\n",
      "train loss:0.001894181168778609\n",
      "train loss:0.05008294792617736\n",
      "train loss:0.018587330797374967\n",
      "train loss:0.008990367398488169\n",
      "train loss:0.006841057232909663\n",
      "train loss:0.009482242654293201\n",
      "train loss:0.004653094808910595\n",
      "train loss:0.05415050947365909\n",
      "train loss:0.0036073432500135405\n",
      "train loss:0.006881599796414215\n",
      "train loss:0.021226836586311557\n",
      "train loss:0.0023495439134829264\n",
      "train loss:0.02400347674034219\n",
      "train loss:0.005500651635617599\n",
      "train loss:0.0016507543338217456\n",
      "train loss:0.006996734905168601\n",
      "train loss:0.009452934282481817\n",
      "train loss:0.0045157516186920335\n",
      "train loss:0.0010286134777120984\n",
      "train loss:0.0028126508406219773\n",
      "train loss:0.010698031828665053\n",
      "train loss:0.00815898100303372\n",
      "train loss:0.014674517005613048\n",
      "train loss:0.049640124706808626\n",
      "train loss:0.0020189300727844386\n",
      "train loss:0.0017038840920865891\n",
      "train loss:0.001982828925426224\n",
      "train loss:0.011547044270935709\n",
      "train loss:0.0210774828818308\n",
      "train loss:0.0025388371944026623\n",
      "train loss:0.007815918609478755\n",
      "train loss:0.005732783035506311\n",
      "train loss:0.004396070046403301\n",
      "train loss:0.006402833527522876\n",
      "train loss:0.0013189502435411377\n",
      "train loss:0.015705805892491754\n",
      "train loss:0.0025375160493115918\n",
      "train loss:0.0013534895437291106\n",
      "train loss:0.009498664367690634\n",
      "train loss:0.01336029629970325\n",
      "train loss:0.0016105488567475417\n",
      "train loss:0.014043172963710066\n",
      "train loss:0.0020326900198711297\n",
      "train loss:0.002850988213361223\n",
      "train loss:0.0026977158979792372\n",
      "train loss:0.004286408522938879\n",
      "train loss:0.0032337102204683353\n",
      "train loss:0.004865190019100348\n",
      "train loss:0.009223905407937353\n",
      "train loss:0.005083625818096465\n",
      "train loss:0.003187280141829876\n",
      "train loss:0.0012149139384008696\n",
      "train loss:0.005325796059328092\n",
      "train loss:0.01725409722814036\n",
      "train loss:0.01928611170964672\n",
      "train loss:0.008879545123266447\n",
      "train loss:0.009600053372990218\n",
      "train loss:0.0019039644282420963\n",
      "train loss:0.012182258012408695\n",
      "train loss:0.017745847176998977\n",
      "train loss:0.003668134015749856\n",
      "train loss:0.0014063622031594894\n",
      "train loss:0.00438049391499471\n",
      "train loss:0.0216419396063729\n",
      "train loss:0.009046463689302115\n",
      "train loss:0.015124456868784211\n",
      "train loss:0.011674734301074574\n",
      "train loss:0.006010780867431359\n",
      "train loss:0.003856111515563173\n",
      "train loss:0.0014207328300802455\n",
      "train loss:0.0050276550596250165\n",
      "train loss:0.002324489928986516\n",
      "train loss:0.010793206248754685\n",
      "train loss:0.013745913730132859\n",
      "train loss:0.00284115349508586\n",
      "train loss:0.03175712588883892\n",
      "train loss:0.001853541099043379\n",
      "train loss:0.00022801376381434906\n",
      "train loss:0.003984220749995861\n",
      "train loss:0.015392347625119034\n",
      "train loss:0.012337339006842888\n",
      "train loss:0.002763538615555267\n",
      "train loss:0.009724477882680932\n",
      "train loss:0.023462754502454303\n",
      "train loss:0.03324347044896622\n",
      "train loss:0.006582714971731245\n",
      "train loss:0.005736842161634456\n",
      "train loss:0.007235670203689603\n",
      "train loss:0.0036707291394059227\n",
      "train loss:0.019432640952951115\n",
      "train loss:0.0012459922933226166\n",
      "train loss:0.009228090324445205\n",
      "train loss:0.012876641976487701\n",
      "train loss:0.004693133588988104\n",
      "train loss:0.0035321801863233576\n",
      "train loss:0.022616253996797522\n",
      "train loss:0.014765724914027176\n",
      "train loss:0.021366217292837105\n",
      "train loss:0.02151857026720055\n",
      "train loss:0.0008168967357894004\n",
      "train loss:0.020708965279244748\n",
      "train loss:0.010001663182830663\n",
      "train loss:0.0035108073017092413\n",
      "train loss:0.01668033430688642\n",
      "train loss:0.002026650080267702\n",
      "train loss:0.0013518732949285097\n",
      "train loss:0.011510395088662362\n",
      "train loss:0.01228965985405811\n",
      "train loss:0.003827312485332052\n",
      "train loss:0.011667829551709091\n",
      "train loss:0.013971889458855379\n",
      "train loss:0.002279242642127311\n",
      "train loss:0.003690993663184899\n",
      "train loss:0.011102933102457644\n",
      "train loss:0.006914940634257221\n",
      "train loss:0.002507693619550072\n",
      "train loss:0.005451619199206251\n",
      "train loss:0.021322017382943367\n",
      "train loss:0.007230525591966629\n",
      "train loss:0.0009551889124470976\n",
      "train loss:0.011544025362522864\n",
      "train loss:0.00511864587128744\n",
      "train loss:0.032152001843733694\n",
      "train loss:0.012180765115599351\n",
      "train loss:0.0015300103185387991\n",
      "train loss:0.00909663681287314\n",
      "train loss:0.005710616933394319\n",
      "train loss:0.006814581112894474\n",
      "train loss:0.0034242706511026007\n",
      "train loss:0.010143642860623515\n",
      "train loss:0.007763421271590323\n",
      "train loss:0.028751749149358186\n",
      "train loss:0.04937841581154378\n",
      "train loss:0.0050665415880846\n",
      "train loss:0.023155366144248103\n",
      "train loss:0.02035537999901815\n",
      "train loss:0.0036395162323187595\n",
      "train loss:0.006628512187690538\n",
      "train loss:0.00849996492864472\n",
      "train loss:0.007277492497480387\n",
      "train loss:0.0041947520470168665\n",
      "train loss:0.009939071946993734\n",
      "train loss:0.015548904404987192\n",
      "train loss:0.017606261070637032\n",
      "train loss:0.009677164526071034\n",
      "train loss:0.009555028818441917\n",
      "train loss:0.01678294995967603\n",
      "train loss:0.0083338591450252\n",
      "train loss:0.0024548233798481547\n",
      "train loss:0.04700523683477126\n",
      "train loss:0.00035033920762612037\n",
      "train loss:0.04934511426682409\n",
      "train loss:0.05250404110508236\n",
      "train loss:0.0005688459413496673\n",
      "train loss:0.005383103228885037\n",
      "train loss:0.01790924028316682\n",
      "train loss:0.003576400756432011\n",
      "train loss:0.012166795019820695\n",
      "train loss:0.038354382719798207\n",
      "train loss:0.002097813699958098\n",
      "train loss:0.012324472725967275\n",
      "train loss:0.00424954199840874\n",
      "train loss:0.0532013745775575\n",
      "train loss:0.04851495375631089\n",
      "train loss:0.003532406760271162\n",
      "train loss:0.009948025325567527\n",
      "train loss:0.02928325709789694\n",
      "train loss:0.003949309439926818\n",
      "train loss:0.00427965876488755\n",
      "train loss:0.04061296357572635\n",
      "train loss:0.014262424124782257\n",
      "train loss:0.03120753834844422\n",
      "train loss:0.004028592972694869\n",
      "train loss:0.006723108963983946\n",
      "train loss:0.013352383001800479\n",
      "train loss:0.001651227582478918\n",
      "train loss:0.0020112466028745874\n",
      "train loss:0.005598888561088568\n",
      "train loss:0.014333192894031373\n",
      "train loss:0.0009838392298992383\n",
      "train loss:0.01332632799986716\n",
      "train loss:0.00160155221994383\n",
      "train loss:0.027306868716204472\n",
      "train loss:0.003700909911053832\n",
      "train loss:0.013733066847152335\n",
      "train loss:0.007911230912545014\n",
      "train loss:0.0035055332947443725\n",
      "train loss:0.009668391632590265\n",
      "train loss:0.0009933281066189289\n",
      "train loss:0.02330898646143249\n",
      "train loss:0.005092639360034693\n",
      "train loss:0.012531857888511347\n",
      "train loss:0.009519500737398025\n",
      "train loss:0.002107610888625211\n",
      "train loss:0.017636686095970865\n",
      "train loss:0.0015495589890505124\n",
      "train loss:0.0034405101001956672\n",
      "train loss:0.0028053544285792627\n",
      "train loss:0.0043864139289785655\n",
      "train loss:0.0050492116853954\n",
      "train loss:0.00804925402922999\n",
      "train loss:0.0076717128973280545\n",
      "train loss:0.029533203290784907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005145895899329575\n",
      "train loss:0.007787588190584319\n",
      "train loss:0.008172914954366233\n",
      "train loss:0.001764711239064085\n",
      "train loss:0.006440253525901728\n",
      "train loss:0.005253118400441856\n",
      "train loss:0.017468459767878072\n",
      "train loss:0.0011150369776558983\n",
      "train loss:0.0038859153261243478\n",
      "train loss:0.0030826590021967833\n",
      "train loss:0.006126793048214848\n",
      "train loss:0.014613607365922812\n",
      "train loss:0.002009335761435854\n",
      "train loss:0.005611253348083829\n",
      "train loss:0.009139619578120243\n",
      "train loss:0.01160158033916065\n",
      "train loss:0.0015688142780318722\n",
      "train loss:0.0047495922055285555\n",
      "train loss:0.007948429777412565\n",
      "train loss:0.005708321791762734\n",
      "train loss:0.003845494356283059\n",
      "train loss:0.010250131156442717\n",
      "train loss:0.00342445768123053\n",
      "train loss:0.0047988911255354445\n",
      "train loss:0.0028331033357800574\n",
      "train loss:0.0012667214810394866\n",
      "train loss:0.0053070414657994565\n",
      "train loss:0.0023380250293572402\n",
      "train loss:0.0013051033956746623\n",
      "train loss:0.003765047861565883\n",
      "train loss:0.025890581218694076\n",
      "train loss:0.025151482900925694\n",
      "train loss:0.013769810186679627\n",
      "train loss:0.0025321556308885856\n",
      "train loss:0.002388140453036671\n",
      "train loss:0.010770053823178865\n",
      "train loss:0.03427833564429471\n",
      "train loss:0.0018541690508891092\n",
      "train loss:0.004589373964062258\n",
      "train loss:0.0038094962955322813\n",
      "train loss:0.013835051603284194\n",
      "train loss:0.005071728661816937\n",
      "train loss:0.011548146665719471\n",
      "train loss:0.00237726303060235\n",
      "train loss:0.004969340174301771\n",
      "train loss:0.012499454151257965\n",
      "train loss:0.003497044063297024\n",
      "train loss:0.030992143560127097\n",
      "train loss:0.006741902433722496\n",
      "train loss:0.003867054039905257\n",
      "train loss:0.0010129820953177365\n",
      "train loss:0.0037418703767440583\n",
      "train loss:0.013221387219710324\n",
      "train loss:0.031348459074744525\n",
      "train loss:0.017354314062516373\n",
      "train loss:0.011799412512598967\n",
      "train loss:0.05262788808904266\n",
      "train loss:0.05081256383451314\n",
      "train loss:0.024133752743960565\n",
      "train loss:0.010150425082290191\n",
      "train loss:0.0011807553620324495\n",
      "train loss:0.005082485873795112\n",
      "train loss:0.0016530449180880496\n",
      "train loss:0.003999382085530571\n",
      "train loss:0.00901672887878826\n",
      "train loss:0.027506769666990248\n",
      "train loss:0.0032764079505202184\n",
      "train loss:0.12205475244958666\n",
      "train loss:0.010065007977441715\n",
      "train loss:0.0027361770820738653\n",
      "train loss:0.0065928359262393274\n",
      "train loss:0.0026842109564280477\n",
      "train loss:0.012947602473087894\n",
      "train loss:0.01232289645516779\n",
      "train loss:0.00512999616065597\n",
      "train loss:0.014091799126106069\n",
      "train loss:0.005501259653792183\n",
      "train loss:0.0021847661004119495\n",
      "train loss:0.02751675960749047\n",
      "train loss:0.005748075892728246\n",
      "train loss:0.06653874749097377\n",
      "train loss:0.07349612629018488\n",
      "train loss:0.003838899367467837\n",
      "train loss:0.009442603728904448\n",
      "train loss:0.0030180410494277704\n",
      "train loss:0.0008367209315362852\n",
      "train loss:0.004899780835065281\n",
      "train loss:0.001974957922521513\n",
      "train loss:0.0032223061091421435\n",
      "train loss:0.014924702597504702\n",
      "train loss:0.004276274427633266\n",
      "train loss:0.08072261015624345\n",
      "train loss:0.002247034461263932\n",
      "train loss:0.009341790233615433\n",
      "train loss:0.009036065743281151\n",
      "train loss:0.0024773240281424514\n",
      "train loss:0.004060698136590929\n",
      "train loss:0.007735470099968679\n",
      "train loss:0.010366329526647034\n",
      "train loss:0.005596579861103945\n",
      "train loss:0.0026629329622852456\n",
      "train loss:0.0016903239014603923\n",
      "train loss:0.015549902377995624\n",
      "train loss:0.04438091817077408\n",
      "train loss:0.010484177329867839\n",
      "train loss:0.010061333017159647\n",
      "train loss:0.0040626145348752404\n",
      "train loss:0.006001844925201119\n",
      "train loss:0.029960252268335846\n",
      "train loss:0.007284449704458321\n",
      "train loss:0.01743386041541747\n",
      "train loss:0.003103642540212926\n",
      "train loss:0.01055227477081559\n",
      "train loss:0.016197304457611767\n",
      "train loss:0.002196507052966241\n",
      "train loss:0.01823538878338704\n",
      "train loss:0.013402200668045657\n",
      "train loss:0.009341186643667211\n",
      "train loss:0.008586461488439712\n",
      "train loss:0.00585626273790741\n",
      "train loss:0.017063254494878152\n",
      "train loss:0.011759779372785082\n",
      "train loss:0.01144325138904795\n",
      "train loss:0.002725096678893681\n",
      "train loss:0.0066723718174800115\n",
      "train loss:0.026537191951054227\n",
      "train loss:0.012395425516173748\n",
      "train loss:0.01170143123858812\n",
      "train loss:0.007669447245978813\n",
      "train loss:0.005110542299319339\n",
      "train loss:0.0026466418633251175\n",
      "train loss:0.006961585798783299\n",
      "train loss:0.01324310594947725\n",
      "train loss:0.0004788903240345345\n",
      "train loss:0.010089713976600667\n",
      "train loss:0.023370036858465743\n",
      "train loss:0.006237504924184259\n",
      "train loss:0.010827187619064456\n",
      "train loss:0.008192374992113506\n",
      "train loss:0.00562244080295651\n",
      "train loss:0.0011176062876289033\n",
      "train loss:0.0030185378764872955\n",
      "train loss:0.008986806162481155\n",
      "train loss:0.00516948614323343\n",
      "train loss:0.0017512957871166953\n",
      "train loss:0.007757008788739908\n",
      "train loss:0.018314427731833303\n",
      "train loss:0.01850857992356697\n",
      "train loss:0.00045071717612978524\n",
      "train loss:0.00653267650137898\n",
      "train loss:0.014115966563261924\n",
      "train loss:0.0062007205642197576\n",
      "train loss:0.008485823667224189\n",
      "train loss:0.0019725082493445055\n",
      "train loss:0.00350678890678258\n",
      "train loss:0.009863243342671456\n",
      "train loss:0.009463772817920478\n",
      "train loss:0.034109631705880855\n",
      "train loss:0.0035758003674799545\n",
      "train loss:0.00758915100099783\n",
      "train loss:0.0061131190892359365\n",
      "train loss:0.004038516925715773\n",
      "train loss:0.0054520765616925485\n",
      "train loss:0.004878827497980001\n",
      "train loss:0.0045256913719134905\n",
      "train loss:0.037424852593498203\n",
      "train loss:0.01256212639783336\n",
      "train loss:0.0065312549461415525\n",
      "train loss:0.00808672526092197\n",
      "train loss:0.005121792361972749\n",
      "train loss:0.0006614239870672428\n",
      "train loss:0.003739088170020884\n",
      "train loss:0.050660762738021246\n",
      "train loss:0.026758187648846587\n",
      "train loss:0.023965721309292684\n",
      "train loss:0.008491175204869984\n",
      "train loss:0.008231798152482065\n",
      "train loss:0.014219880662539824\n",
      "train loss:0.0012917851047002237\n",
      "train loss:0.009121542319456312\n",
      "train loss:0.006911302266950319\n",
      "train loss:0.008743428026644899\n",
      "train loss:0.014426537948191265\n",
      "train loss:0.016301300745184176\n",
      "train loss:0.0029838458614139442\n",
      "train loss:0.036179243826848985\n",
      "train loss:0.004237035190550493\n",
      "=== epoch:10, train acc:0.994, test acc:0.985 ===\n",
      "train loss:0.03423502180278805\n",
      "train loss:0.0210557462825006\n",
      "train loss:0.0016328164649422547\n",
      "train loss:0.009180656349083188\n",
      "train loss:0.001690663284619759\n",
      "train loss:0.0025988860038659908\n",
      "train loss:0.015824548339565005\n",
      "train loss:0.0021479943218901234\n",
      "train loss:0.002308810972419594\n",
      "train loss:0.025824925964922953\n",
      "train loss:0.004003994407987245\n",
      "train loss:0.005834805949508553\n",
      "train loss:0.007817462836332037\n",
      "train loss:0.005238879843794029\n",
      "train loss:0.0016280387820400255\n",
      "train loss:0.022190052968243994\n",
      "train loss:0.012825393070295465\n",
      "train loss:0.0009557726344254879\n",
      "train loss:0.009490494047679782\n",
      "train loss:0.04893622129123478\n",
      "train loss:0.003002962079344452\n",
      "train loss:0.004069596287945667\n",
      "train loss:0.004366332589498352\n",
      "train loss:0.0027072161871399252\n",
      "train loss:0.027804624246289003\n",
      "train loss:0.004154187802549025\n",
      "train loss:0.007862831971489797\n",
      "train loss:0.008709472482085902\n",
      "train loss:0.011600546341437517\n",
      "train loss:0.005030736414462874\n",
      "train loss:0.0021862997950276232\n",
      "train loss:0.0005942116601104561\n",
      "train loss:0.1200911705516056\n",
      "train loss:0.03505062031496756\n",
      "train loss:0.010972315813295868\n",
      "train loss:0.00554281805843485\n",
      "train loss:0.004391283956867421\n",
      "train loss:0.026964311420809736\n",
      "train loss:0.019855744476852465\n",
      "train loss:0.0021719565657426915\n",
      "train loss:0.008874408566635253\n",
      "train loss:0.0019248591802548348\n",
      "train loss:0.0021096991674653814\n",
      "train loss:0.001028362567014636\n",
      "train loss:0.013484312564608074\n",
      "train loss:0.011572093971890452\n",
      "train loss:0.004219506228112011\n",
      "train loss:0.01008060619362934\n",
      "train loss:0.002490769696774435\n",
      "train loss:0.011313196881865516\n",
      "train loss:0.00448431684025439\n",
      "train loss:0.01385232094854719\n",
      "train loss:0.012718699656994688\n",
      "train loss:0.005344093313442774\n",
      "train loss:0.015141783217822223\n",
      "train loss:0.0022552323746235507\n",
      "train loss:0.061407113468562986\n",
      "train loss:0.0005654042837525771\n",
      "train loss:0.0036430227311695412\n",
      "train loss:0.005917320589480059\n",
      "train loss:0.010309975020050748\n",
      "train loss:0.0008110360839702921\n",
      "train loss:0.002524809909112864\n",
      "train loss:0.0005122807022325982\n",
      "train loss:0.0029468717024537182\n",
      "train loss:0.003927803232740412\n",
      "train loss:0.0011365557845378748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00680870034476641\n",
      "train loss:0.0032020096653623113\n",
      "train loss:0.0041259148499207055\n",
      "train loss:0.0006743006867250348\n",
      "train loss:0.0012717393657240867\n",
      "train loss:0.00822918673518219\n",
      "train loss:0.011883157811059968\n",
      "train loss:0.006046881749073572\n",
      "train loss:0.004987954768842532\n",
      "train loss:0.004348637492820036\n",
      "train loss:0.0032042785011050434\n",
      "train loss:0.009167297722027033\n",
      "train loss:0.045553984220651274\n",
      "train loss:0.0013483588040357018\n",
      "train loss:0.01064086061973132\n",
      "train loss:0.014735386701988732\n",
      "train loss:0.0021518995651428215\n",
      "train loss:0.02979230923608527\n",
      "train loss:0.04912281701644919\n",
      "train loss:0.005471441428852855\n",
      "train loss:0.022339610198734886\n",
      "train loss:0.03086391013342278\n",
      "train loss:0.005976219272361204\n",
      "train loss:0.004869200970536793\n",
      "train loss:0.008446458173058401\n",
      "train loss:0.012901603349143989\n",
      "train loss:0.0014671096960869815\n",
      "train loss:0.0035662481902018423\n",
      "train loss:0.0468195006647026\n",
      "train loss:0.026013573729220973\n",
      "train loss:0.0012616977109589258\n",
      "train loss:0.021688378751590718\n",
      "train loss:0.012247860058683193\n",
      "train loss:0.0016549159386996374\n",
      "train loss:0.04500175996793165\n",
      "train loss:0.006116146837027916\n",
      "train loss:0.0021270597615719693\n",
      "train loss:0.0288904357946536\n",
      "train loss:0.01047075654592691\n",
      "train loss:0.037449377858058644\n",
      "train loss:0.020103541054850536\n",
      "train loss:0.014088799148852279\n",
      "train loss:0.003801628145935931\n",
      "train loss:0.003912322655212412\n",
      "train loss:0.006866739871568823\n",
      "train loss:0.00789586343495144\n",
      "train loss:0.006618653886904658\n",
      "train loss:0.01677254220110397\n",
      "train loss:0.026204343638237607\n",
      "train loss:0.026033017098689576\n",
      "train loss:0.008569465827318977\n",
      "train loss:0.01309763205536927\n",
      "train loss:0.019993004062878114\n",
      "train loss:0.006315536409730831\n",
      "train loss:0.03840178655342002\n",
      "train loss:0.03267414863158325\n",
      "train loss:0.001095354270796087\n",
      "train loss:0.0054462878675055285\n",
      "train loss:0.036840185967988326\n",
      "train loss:0.022678142767983647\n",
      "train loss:0.0031417386551721195\n",
      "train loss:0.006048027847185479\n",
      "train loss:0.05891535151344604\n",
      "train loss:0.006447398425051912\n",
      "train loss:0.008944953467267463\n",
      "train loss:0.0287879899125663\n",
      "train loss:0.010913690766501885\n",
      "train loss:0.021679582331391313\n",
      "train loss:0.007684755008819546\n",
      "train loss:0.004313543308712254\n",
      "train loss:0.006032965018457178\n",
      "train loss:0.004989472092606307\n",
      "train loss:0.015100714180315288\n",
      "train loss:0.00905243343684997\n",
      "train loss:0.02164694952576711\n",
      "train loss:0.0038338097046814253\n",
      "train loss:0.018660644103873362\n",
      "train loss:0.0068789491788914005\n",
      "train loss:0.012811519563960847\n",
      "train loss:0.005903558170139206\n",
      "train loss:0.0036665969733756594\n",
      "train loss:0.041299170310725185\n",
      "train loss:0.006769185682157862\n",
      "train loss:0.029663749799280038\n",
      "train loss:0.017604514552511157\n",
      "train loss:0.0065041277808347816\n",
      "train loss:0.05138744816948051\n",
      "train loss:0.0057495802692315474\n",
      "train loss:0.016444432349738126\n",
      "train loss:0.003852621368240036\n",
      "train loss:0.040821096406353535\n",
      "train loss:0.0014559886246524464\n",
      "train loss:0.014727439664624378\n",
      "train loss:0.00974802552389129\n",
      "train loss:0.0034589414203676566\n",
      "train loss:0.005617044310867648\n",
      "train loss:0.007241610392259345\n",
      "train loss:0.0026085769085714733\n",
      "train loss:0.0019092239005366806\n",
      "train loss:0.01223232435536902\n",
      "train loss:0.008751760573113491\n",
      "train loss:0.007218924090008778\n",
      "train loss:0.0220622676744132\n",
      "train loss:0.005320382047580967\n",
      "train loss:0.004875270113102435\n",
      "train loss:0.062038988332090976\n",
      "train loss:0.007820093758095522\n",
      "train loss:0.015069330811416466\n",
      "train loss:0.001094194341123679\n",
      "train loss:0.012290886850041012\n",
      "train loss:0.008095919435692364\n",
      "train loss:0.006334577181373482\n",
      "train loss:0.003809478871393197\n",
      "train loss:0.005117550567673954\n",
      "train loss:0.002535329652239463\n",
      "train loss:0.005028040721269723\n",
      "train loss:0.01758830194154848\n",
      "train loss:0.009147327598185687\n",
      "train loss:0.005077242158481891\n",
      "train loss:0.00042794793050172464\n",
      "train loss:0.0014256179934599284\n",
      "train loss:0.002530345905735438\n",
      "train loss:0.0014689727433405226\n",
      "train loss:0.04729312221062533\n",
      "train loss:0.011941865891068916\n",
      "train loss:0.014582959776781175\n",
      "train loss:0.006310679314761319\n",
      "train loss:0.000558939116915349\n",
      "train loss:0.004680062237381206\n",
      "train loss:0.0060208106123683155\n",
      "train loss:0.007395144663864777\n",
      "train loss:0.0007463430497543543\n",
      "train loss:0.011029339982494706\n",
      "train loss:0.0066391002901679845\n",
      "train loss:0.0032932849211513926\n",
      "train loss:0.004397144935919301\n",
      "train loss:0.024959864461489324\n",
      "train loss:0.015024404072852594\n",
      "train loss:0.02095073547188987\n",
      "train loss:0.009755570744773668\n",
      "train loss:0.004910842298700305\n",
      "train loss:0.006642413302737566\n",
      "train loss:0.0137237626613596\n",
      "train loss:0.00416326307889466\n",
      "train loss:0.0035283918020868367\n",
      "train loss:0.00671635717856642\n",
      "train loss:0.0024121668303266584\n",
      "train loss:0.002180945682177419\n",
      "train loss:0.020879217543701006\n",
      "train loss:0.005571292394384476\n",
      "train loss:0.0017046330808742104\n",
      "train loss:0.005737238638918441\n",
      "train loss:0.0018066521917396198\n",
      "train loss:0.004553393056927516\n",
      "train loss:0.005522656369208733\n",
      "train loss:0.0031110160728147914\n",
      "train loss:0.023913555428151795\n",
      "train loss:0.000912170548767883\n",
      "train loss:0.00815259769441724\n",
      "train loss:0.009017785166655256\n",
      "train loss:0.010900712845103277\n",
      "train loss:0.0035007664872322543\n",
      "train loss:0.007422702051915562\n",
      "train loss:0.008107000475887664\n",
      "train loss:0.017385171376576084\n",
      "train loss:0.010604094399279071\n",
      "train loss:0.0020127699894636566\n",
      "train loss:0.008469911787824412\n",
      "train loss:0.01821088776408925\n",
      "train loss:0.006383192708519198\n",
      "train loss:0.002799416271540749\n",
      "train loss:0.0013570232303635923\n",
      "train loss:0.005919575586877294\n",
      "train loss:0.027040953379105857\n",
      "train loss:0.004908829098446964\n",
      "train loss:0.0026369788685686375\n",
      "train loss:0.007060381216955665\n",
      "train loss:0.019449239763358696\n",
      "train loss:0.0020706384580121404\n",
      "train loss:0.0011719388009750898\n",
      "train loss:0.012288563454700075\n",
      "train loss:0.0028481951759454422\n",
      "train loss:0.006521909320962936\n",
      "train loss:0.010015846486150448\n",
      "train loss:0.0043528501960160195\n",
      "train loss:0.04814018303082603\n",
      "train loss:0.00371006379481664\n",
      "train loss:0.0019598680304345915\n",
      "train loss:0.022270896562055612\n",
      "train loss:0.0031421141369688244\n",
      "train loss:0.014365148167484127\n",
      "train loss:0.0051013545901672655\n",
      "train loss:0.0007683081462009131\n",
      "train loss:0.001337016258877408\n",
      "train loss:0.005208338797074744\n",
      "train loss:0.003306433550030491\n",
      "train loss:0.0010450065291815612\n",
      "train loss:0.0235980948160311\n",
      "train loss:0.02901577793653026\n",
      "train loss:0.002514071424663617\n",
      "train loss:0.002953812679505578\n",
      "train loss:0.010612941536184261\n",
      "train loss:0.006132952770536123\n",
      "train loss:0.004613663867828947\n",
      "train loss:0.013415604833747898\n",
      "train loss:0.025083156238662526\n",
      "train loss:0.006344516276323322\n",
      "train loss:0.0004315424836281784\n",
      "train loss:0.007235428677065201\n",
      "train loss:0.011099402574511821\n",
      "train loss:0.012130144406994958\n",
      "train loss:0.026237350032032158\n",
      "train loss:0.0008272208575045491\n",
      "train loss:0.006736927238373836\n",
      "train loss:0.007011499209268205\n",
      "train loss:0.004518794728366343\n",
      "train loss:0.005532098467189035\n",
      "train loss:0.00763343029872381\n",
      "train loss:0.0007695197472863671\n",
      "train loss:0.017409516439079165\n",
      "train loss:0.0033641829868367957\n",
      "train loss:0.009480208348740395\n",
      "train loss:0.003204174533950686\n",
      "train loss:0.02318086339836024\n",
      "train loss:0.022812989475424303\n",
      "train loss:0.0011540313123064349\n",
      "train loss:0.014641704573520084\n",
      "train loss:0.0010574275482521623\n",
      "train loss:0.0047414969415722095\n",
      "train loss:0.13885781191516586\n",
      "train loss:0.007528453920218455\n",
      "train loss:0.006791375380233005\n",
      "train loss:0.01028029703654561\n",
      "train loss:0.001723365857771031\n",
      "train loss:0.008652394230159231\n",
      "train loss:0.0011470825644276015\n",
      "train loss:0.0021414765963411095\n",
      "train loss:0.011024089254335028\n",
      "train loss:0.002979094990873109\n",
      "train loss:0.01268978185497033\n",
      "train loss:0.006340671807905858\n",
      "train loss:0.009155271753140244\n",
      "train loss:0.020839642511976578\n",
      "train loss:0.003821223960199453\n",
      "train loss:0.0035625386054089023\n",
      "train loss:0.0032470695103945756\n",
      "train loss:0.005898616101227871\n",
      "train loss:0.003253370722880176\n",
      "train loss:0.020191477502445713\n",
      "train loss:0.013283375318216929\n",
      "train loss:0.0016512276573598789\n",
      "train loss:0.0022719649460443024\n",
      "train loss:0.0014259113336504076\n",
      "train loss:0.037172210105391\n",
      "train loss:0.008957707913410372\n",
      "train loss:0.014292222637255197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003201363959420145\n",
      "train loss:0.0033603032433760925\n",
      "train loss:0.006841779156099475\n",
      "train loss:0.006081738006939743\n",
      "train loss:0.0024863245323815055\n",
      "train loss:0.009912626241989858\n",
      "train loss:0.00504644258997819\n",
      "train loss:0.0052014619579855625\n",
      "train loss:0.0027222680317628032\n",
      "train loss:0.0021940654079183972\n",
      "train loss:0.005058651562268971\n",
      "train loss:0.012183969999432298\n",
      "train loss:0.02091005235094092\n",
      "train loss:0.002104131772150336\n",
      "train loss:0.004334423587525413\n",
      "train loss:0.004010970475359751\n",
      "train loss:0.002550422398804647\n",
      "train loss:0.004790274624254739\n",
      "train loss:0.004748413053488441\n",
      "train loss:0.011088264899830053\n",
      "train loss:0.003453874350541455\n",
      "train loss:0.0010918580678685905\n",
      "train loss:0.0013575878567074543\n",
      "train loss:0.014505965952318343\n",
      "train loss:0.009773300799399197\n",
      "train loss:0.005199865227222429\n",
      "train loss:0.004140373214504515\n",
      "train loss:0.0036231217291548806\n",
      "train loss:0.017195879814006495\n",
      "train loss:0.008732650852774583\n",
      "train loss:0.006129510851431272\n",
      "train loss:0.0005710813178345203\n",
      "train loss:0.030470292986935966\n",
      "train loss:0.012471475662331678\n",
      "train loss:0.004621010658336612\n",
      "train loss:0.004757380242976609\n",
      "train loss:0.006127502676335926\n",
      "train loss:0.011999907357255464\n",
      "train loss:0.004636409099629113\n",
      "train loss:0.002384368723047754\n",
      "train loss:0.00395426854686037\n",
      "train loss:0.004748161940411625\n",
      "train loss:0.007290878037181355\n",
      "train loss:0.012752026673395742\n",
      "train loss:0.004655433137258265\n",
      "train loss:0.0009569413278614288\n",
      "train loss:0.003459584967821564\n",
      "train loss:0.0016665940957439045\n",
      "train loss:0.00376724598492063\n",
      "train loss:0.004185046956195562\n",
      "train loss:0.0022150211938592157\n",
      "train loss:0.02045546853271774\n",
      "train loss:0.0016021180836252307\n",
      "train loss:0.01886183758674534\n",
      "train loss:0.0009482536947095721\n",
      "train loss:0.012871582874194794\n",
      "train loss:0.0031078345262111223\n",
      "train loss:0.01621006554330222\n",
      "train loss:0.0023691883875487027\n",
      "train loss:0.018297388519303313\n",
      "train loss:0.02691577350859168\n",
      "train loss:0.007086138964761155\n",
      "train loss:0.00842573718532614\n",
      "train loss:0.007397720818183617\n",
      "train loss:0.006348688614674578\n",
      "train loss:0.001782439823001872\n",
      "train loss:0.01980994745291531\n",
      "train loss:0.005874257799626927\n",
      "train loss:0.003836607143181378\n",
      "train loss:0.0008545007902610062\n",
      "train loss:0.03184160564752285\n",
      "train loss:0.005986823574095619\n",
      "train loss:0.011495534906734306\n",
      "train loss:0.0012566419318473768\n",
      "train loss:0.0027159548613415363\n",
      "train loss:0.004473709428689649\n",
      "train loss:0.001063594328759034\n",
      "train loss:0.0011456698228465682\n",
      "train loss:0.003220791846513087\n",
      "train loss:0.0004116769776763468\n",
      "train loss:0.0042414448389216045\n",
      "train loss:0.10612709547163349\n",
      "train loss:0.00054838446792822\n",
      "train loss:0.006945653802364028\n",
      "train loss:0.008019104854888744\n",
      "train loss:0.01693757466655993\n",
      "train loss:0.004578662511170975\n",
      "train loss:0.004968056634381224\n",
      "train loss:0.0017719516967778855\n",
      "train loss:0.023609907865198863\n",
      "train loss:0.008195077457626258\n",
      "train loss:0.0010527066391951142\n",
      "train loss:0.005572195694303874\n",
      "train loss:0.001011567786919424\n",
      "train loss:0.0004772385524340004\n",
      "train loss:0.003843691796271105\n",
      "train loss:0.004553412191847436\n",
      "train loss:0.011403898300436373\n",
      "train loss:0.007864582749756835\n",
      "train loss:0.00045264586786110416\n",
      "train loss:0.005226780446637799\n",
      "train loss:0.00502564815087466\n",
      "train loss:0.045685538365854816\n",
      "train loss:0.0008675023797124362\n",
      "train loss:0.0012287888386339168\n",
      "train loss:0.0012524124357933314\n",
      "train loss:0.0038472894791264974\n",
      "train loss:0.0026066367469968444\n",
      "train loss:0.008912337791294689\n",
      "train loss:0.009046547943438645\n",
      "train loss:0.005373289578617106\n",
      "train loss:0.002905041150127346\n",
      "train loss:0.0027331874240828975\n",
      "train loss:0.0006601861125185981\n",
      "train loss:0.003135612623469337\n",
      "train loss:0.000465014788253376\n",
      "train loss:0.0012411407727563612\n",
      "train loss:0.025761085589965132\n",
      "train loss:0.00118400186474457\n",
      "train loss:0.002762402948246524\n",
      "train loss:0.002880391175557474\n",
      "train loss:0.040284479899454356\n",
      "train loss:0.005711253241139448\n",
      "train loss:0.012874785729369526\n",
      "train loss:0.003396953499075017\n",
      "train loss:0.01978089036383475\n",
      "train loss:0.0021067086634816343\n",
      "train loss:0.002988916530761155\n",
      "train loss:0.020491317052815247\n",
      "train loss:0.0317089846355196\n",
      "train loss:0.0021072665178735214\n",
      "train loss:0.00266048616992563\n",
      "train loss:0.019435884272008968\n",
      "train loss:0.0014484872729566378\n",
      "train loss:0.0027714165974806115\n",
      "train loss:0.011961106756663937\n",
      "train loss:0.0035294031507716846\n",
      "train loss:0.0028608348502600456\n",
      "train loss:0.016597122632736015\n",
      "train loss:0.016608152131715345\n",
      "train loss:0.006651393816841727\n",
      "train loss:0.00952315220832208\n",
      "train loss:0.002802400628434354\n",
      "train loss:0.031195938270384565\n",
      "train loss:0.007529698872104128\n",
      "train loss:0.00887506443093303\n",
      "train loss:0.003968620903164596\n",
      "train loss:0.001503003508079797\n",
      "train loss:0.009007924750255254\n",
      "train loss:0.0053231799163314265\n",
      "train loss:0.006860667438246981\n",
      "train loss:0.006688627525806159\n",
      "train loss:0.0022069531728204205\n",
      "train loss:0.009739530220669741\n",
      "train loss:0.01308932841553683\n",
      "train loss:0.005829115683277153\n",
      "train loss:0.0026956652814676507\n",
      "train loss:0.010536845682325395\n",
      "train loss:0.009201267856536636\n",
      "train loss:0.006076557453153292\n",
      "train loss:0.042263489333629556\n",
      "train loss:0.000731699132746055\n",
      "train loss:0.003969799960163044\n",
      "train loss:0.00918365323504226\n",
      "train loss:0.020654515502637815\n",
      "train loss:0.005816649377150675\n",
      "train loss:0.011217034008800128\n",
      "train loss:0.0030331895370508148\n",
      "train loss:0.003240809780527095\n",
      "train loss:0.001109332170481296\n",
      "train loss:0.02923880708818204\n",
      "train loss:0.0057597761927542564\n",
      "train loss:0.05278429799809667\n",
      "train loss:0.0024876761621235957\n",
      "train loss:0.0015880005124605811\n",
      "train loss:0.025491774099033283\n",
      "train loss:0.0020463882433995324\n",
      "train loss:0.01638494274306585\n",
      "train loss:0.0008850985464868765\n",
      "train loss:0.0032660407966566547\n",
      "train loss:0.0011466385793418186\n",
      "train loss:0.0019965515921447833\n",
      "train loss:0.0009294151952387497\n",
      "train loss:0.000981810433515737\n",
      "train loss:0.0012279510226186061\n",
      "train loss:0.009424784772806241\n",
      "train loss:0.0011063508938965957\n",
      "train loss:0.0052881015897089404\n",
      "train loss:0.01220601276698717\n",
      "train loss:0.0035604075169510347\n",
      "train loss:0.0010694286576772441\n",
      "train loss:0.008036588134908186\n",
      "train loss:0.0030894380524175385\n",
      "train loss:0.004574451228567316\n",
      "train loss:0.010165917242356569\n",
      "train loss:0.002132664385381815\n",
      "train loss:0.01385110421707606\n",
      "train loss:0.0038882254644263875\n",
      "train loss:0.001985449541709347\n",
      "train loss:0.00269757895539113\n",
      "train loss:0.0020649952853469965\n",
      "train loss:0.0027450700216127616\n",
      "train loss:0.009318287109794106\n",
      "train loss:0.006469676099842381\n",
      "train loss:0.00588332840191384\n",
      "train loss:0.002739083757845966\n",
      "train loss:0.0027765376495624294\n",
      "train loss:0.00690882227566661\n",
      "train loss:0.002885842087594148\n",
      "train loss:0.009119329366535978\n",
      "train loss:0.0031041000987311823\n",
      "train loss:0.004573730940472213\n",
      "train loss:0.0005694985852655857\n",
      "train loss:0.0009375661759880122\n",
      "train loss:0.0029009470883906733\n",
      "train loss:0.0005133972174460104\n",
      "train loss:0.012775228440575135\n",
      "train loss:0.009143116922616417\n",
      "train loss:0.01942475049917315\n",
      "train loss:0.010650537653913555\n",
      "train loss:0.001112996847470339\n",
      "train loss:0.0017551935111180725\n",
      "train loss:0.002257987040260426\n",
      "train loss:0.0034110935009230743\n",
      "train loss:0.008136106265483393\n",
      "train loss:0.005215026069062316\n",
      "train loss:0.010940472394356223\n",
      "train loss:0.007860921041411976\n",
      "train loss:0.004489963854466167\n",
      "train loss:0.008344521764159474\n",
      "train loss:0.0007690214129514747\n",
      "train loss:0.00039379916121385294\n",
      "train loss:0.006947818984076459\n",
      "train loss:0.0015386674387242933\n",
      "train loss:0.0015350038570650373\n",
      "train loss:0.020571826427245848\n",
      "train loss:0.0037795960350274645\n",
      "train loss:0.005797665540600329\n",
      "train loss:0.03942151603788617\n",
      "train loss:0.0023728579752259273\n",
      "train loss:0.0034518360009949023\n",
      "train loss:0.0036755855883053774\n",
      "train loss:0.01183654758358047\n",
      "train loss:0.03302631849490424\n",
      "train loss:0.0013105232321083027\n",
      "train loss:0.015744554012987532\n",
      "train loss:0.004598622147573809\n",
      "train loss:0.0041832934876635565\n",
      "train loss:0.0015013063658986612\n",
      "train loss:0.004850009857710664\n",
      "train loss:0.003899274180551053\n",
      "train loss:0.0017474979237384852\n",
      "train loss:0.0008797313489006073\n",
      "train loss:0.0006226955682296548\n",
      "train loss:0.000894666547175795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0025257479299375905\n",
      "train loss:0.006582830260546171\n",
      "train loss:0.0027267045268127145\n",
      "train loss:0.0067867745363298735\n",
      "train loss:0.0014884190391811164\n",
      "train loss:0.000708859229046017\n",
      "train loss:0.0012305390636484026\n",
      "train loss:0.0043522633790652795\n",
      "train loss:0.002044411019781778\n",
      "train loss:0.008881922124107556\n",
      "train loss:0.02261966780449725\n",
      "train loss:0.0005873488630561397\n",
      "train loss:0.006568956031875683\n",
      "train loss:0.08139651827225643\n",
      "train loss:0.054035585341324494\n",
      "train loss:0.009976600221381806\n",
      "train loss:0.009740177860383665\n",
      "train loss:0.0011199145066476983\n",
      "train loss:0.004278148860299872\n",
      "train loss:0.004202031842779413\n",
      "train loss:0.005034527928515493\n",
      "train loss:0.001581570850565677\n",
      "=== epoch:11, train acc:0.994, test acc:0.99 ===\n",
      "train loss:0.002793571472794838\n",
      "train loss:0.004320653107282424\n",
      "train loss:0.0023348229937515032\n",
      "train loss:0.016381481784600506\n",
      "train loss:0.004698117602862532\n",
      "train loss:0.007039635396444141\n",
      "train loss:0.00335883768197557\n",
      "train loss:0.014628253559982339\n",
      "train loss:0.042561157238525965\n",
      "train loss:0.001546964044443085\n",
      "train loss:0.003153482081098938\n",
      "train loss:0.014625355899461704\n",
      "train loss:0.0016704512952780734\n",
      "train loss:0.008584237969201264\n",
      "train loss:0.0877614948120486\n",
      "train loss:0.0014082624813470778\n",
      "train loss:0.005219650546179496\n",
      "train loss:0.02499470914746815\n",
      "train loss:0.004466264279220989\n",
      "train loss:0.018636516099588767\n",
      "train loss:0.0013390557939951945\n",
      "train loss:0.006889050370587361\n",
      "train loss:0.07836234306769613\n",
      "train loss:0.01288496324550149\n",
      "train loss:0.017963716313272537\n",
      "train loss:0.004205284845463978\n",
      "train loss:0.0009566844550840726\n",
      "train loss:0.002387625261165277\n",
      "train loss:0.001664845146944224\n",
      "train loss:0.004852492709331233\n",
      "train loss:0.007377900161602707\n",
      "train loss:0.020714502315633498\n",
      "train loss:0.009752795369365432\n",
      "train loss:0.004068525342473336\n",
      "train loss:0.001299144508210549\n",
      "train loss:0.011582388376877206\n",
      "train loss:0.008751660385818531\n",
      "train loss:0.009910089326632883\n",
      "train loss:0.003260903319798045\n",
      "train loss:0.0038754253592568817\n",
      "train loss:0.0058295411944925815\n",
      "train loss:0.015305743049530416\n",
      "train loss:0.005967310845248359\n",
      "train loss:0.0033950819303633\n",
      "train loss:0.01019949964444672\n",
      "train loss:0.0018884630492030437\n",
      "train loss:0.0020967610258345497\n",
      "train loss:0.005036461489983181\n",
      "train loss:0.013026758555403467\n",
      "train loss:0.001429026124437342\n",
      "train loss:0.005071325679832398\n",
      "train loss:0.004518744642025003\n",
      "train loss:0.0021714919213504124\n",
      "train loss:0.0030265379085545963\n",
      "train loss:0.0037733765700135474\n",
      "train loss:0.006600084309886512\n",
      "train loss:0.008771263473969169\n",
      "train loss:0.00518677869637117\n",
      "train loss:0.00208393200538559\n",
      "train loss:0.000337979108363369\n",
      "train loss:0.0017002688538461388\n",
      "train loss:0.006245709782959515\n",
      "train loss:0.006097170502944897\n",
      "train loss:0.004719472088375988\n",
      "train loss:0.0015538842466535291\n",
      "train loss:0.004331109028552182\n",
      "train loss:0.0029834961733287524\n",
      "train loss:0.007191800323017702\n",
      "train loss:0.0024060498174452803\n",
      "train loss:0.004644946839216853\n",
      "train loss:0.015669245460162975\n",
      "train loss:0.002022054993611294\n",
      "train loss:0.011229791804025793\n",
      "train loss:0.027264483101869\n",
      "train loss:0.0050566146693453795\n",
      "train loss:0.003403479401518577\n",
      "train loss:0.005193444188284416\n",
      "train loss:0.005395270914577782\n",
      "train loss:0.0024407911362905473\n",
      "train loss:0.0040653497704803985\n",
      "train loss:0.0014524700425191104\n",
      "train loss:0.0033469140551478033\n",
      "train loss:0.0077345505553855776\n",
      "train loss:0.004256038126239334\n",
      "train loss:0.01166595520550034\n",
      "train loss:0.005072643346360968\n",
      "train loss:0.005973597013579611\n",
      "train loss:0.0025259156856020106\n",
      "train loss:0.005879927628995041\n",
      "train loss:0.0046383474776295576\n",
      "train loss:0.0009142524958469401\n",
      "train loss:0.0017093882020369033\n",
      "train loss:0.010633477668611795\n",
      "train loss:0.0035888645818334926\n",
      "train loss:0.0010849719579378704\n",
      "train loss:0.004172182841275223\n",
      "train loss:0.004804472271416755\n",
      "train loss:0.008457117994600215\n",
      "train loss:0.0027464665049770657\n",
      "train loss:0.005471698703232322\n",
      "train loss:0.008577767670657124\n",
      "train loss:0.006755426941068584\n",
      "train loss:0.0013978159052546097\n",
      "train loss:0.0036163755022755218\n",
      "train loss:0.009324846853166379\n",
      "train loss:0.0305136840624163\n",
      "train loss:0.0017178383897801211\n",
      "train loss:0.0026989718829048487\n",
      "train loss:0.0018958369395213875\n",
      "train loss:0.004085484349049997\n",
      "train loss:0.0036296271829873144\n",
      "train loss:0.013253687610737279\n",
      "train loss:0.0031141549522255606\n",
      "train loss:0.0014573492851439234\n",
      "train loss:0.047420351792335606\n",
      "train loss:0.0019620750269634412\n",
      "train loss:0.002973361925122244\n",
      "train loss:0.003070721143292351\n",
      "train loss:0.00128718438455723\n",
      "train loss:0.0024173023103933496\n",
      "train loss:0.00729187746223395\n",
      "train loss:0.0004387962743870284\n",
      "train loss:0.021454145405030635\n",
      "train loss:0.004285478943585101\n",
      "train loss:0.006473415895932944\n",
      "train loss:0.005566591445619571\n",
      "train loss:0.030141266716718428\n",
      "train loss:0.0028131328086061862\n",
      "train loss:0.005778872067912035\n",
      "train loss:0.0009812737643118891\n",
      "train loss:0.002798248185619648\n",
      "train loss:0.00424863709647085\n",
      "train loss:0.00169583022470577\n",
      "train loss:0.004481133863582371\n",
      "train loss:0.0026328743003847725\n",
      "train loss:0.008688227207927487\n",
      "train loss:0.0033420074073139145\n",
      "train loss:0.004838841813884775\n",
      "train loss:0.01087227764943\n",
      "train loss:0.005429875152770213\n",
      "train loss:0.004822452026597989\n",
      "train loss:0.0001355330329266113\n",
      "train loss:0.002516611446932945\n",
      "train loss:0.0022489057439025167\n",
      "train loss:0.013649815729876004\n",
      "train loss:0.005722501781956543\n",
      "train loss:0.001794170730821895\n",
      "train loss:0.03098076293866642\n",
      "train loss:0.015015049581725526\n",
      "train loss:0.0029992591505034723\n",
      "train loss:0.0038722648215461252\n",
      "train loss:0.0010448502608833335\n",
      "train loss:0.009075916224461574\n",
      "train loss:0.003971888373567822\n",
      "train loss:0.0017182007791044667\n",
      "train loss:0.03282052205195387\n",
      "train loss:0.004971765032081383\n",
      "train loss:0.01607947867897136\n",
      "train loss:0.0090079920633815\n",
      "train loss:0.0008600142229762172\n",
      "train loss:0.019467855940960798\n",
      "train loss:0.004157675653286773\n",
      "train loss:0.006941433044393808\n",
      "train loss:0.009560658072023998\n",
      "train loss:0.0050620648750637634\n",
      "train loss:0.047321966576988936\n",
      "train loss:0.009166579643337221\n",
      "train loss:0.07449604694140213\n",
      "train loss:0.0017186300306102067\n",
      "train loss:0.004978805399448097\n",
      "train loss:0.004036413073587781\n",
      "train loss:0.016794658058903157\n",
      "train loss:0.01366321667057297\n",
      "train loss:0.016668899884954486\n",
      "train loss:0.0015680020394368585\n",
      "train loss:0.002965748439661895\n",
      "train loss:0.0007646503365197233\n",
      "train loss:0.009735073301772718\n",
      "train loss:0.016228245076837594\n",
      "train loss:0.005612035883751013\n",
      "train loss:0.0033478618589046017\n",
      "train loss:0.0022833654521394933\n",
      "train loss:0.08520673371440178\n",
      "train loss:0.006219940870913988\n",
      "train loss:0.007529951437909988\n",
      "train loss:0.011532893223669943\n",
      "train loss:0.028888631337285454\n",
      "train loss:0.0021767479415971125\n",
      "train loss:0.010389746112155908\n",
      "train loss:0.000490810373880842\n",
      "train loss:0.05767067546594779\n",
      "train loss:0.005626421104379725\n",
      "train loss:0.0006613639055528402\n",
      "train loss:0.0017586453037631458\n",
      "train loss:0.0034972402464682954\n",
      "train loss:0.009105452959339148\n",
      "train loss:0.010770874917050574\n",
      "train loss:0.00644809994752549\n",
      "train loss:0.0037970284363163225\n",
      "train loss:0.0007022626367454597\n",
      "train loss:0.009448844929054985\n",
      "train loss:0.021869486818005976\n",
      "train loss:0.02089207814650491\n",
      "train loss:0.0028970894063521683\n",
      "train loss:0.016924863430766393\n",
      "train loss:0.0005768028808691382\n",
      "train loss:0.0015435384634205106\n",
      "train loss:0.0019822936179782215\n",
      "train loss:0.00035032539912639444\n",
      "train loss:0.0004344225552102235\n",
      "train loss:0.011922080761483227\n",
      "train loss:0.01011874646616618\n",
      "train loss:0.006173896540873743\n",
      "train loss:0.006452308185126826\n",
      "train loss:0.007921809825335014\n",
      "train loss:0.010293756657310735\n",
      "train loss:0.02447086539440535\n",
      "train loss:0.0032198243369358963\n",
      "train loss:0.0015673518532594141\n",
      "train loss:0.016063431971480486\n",
      "train loss:0.004434736761235365\n",
      "train loss:0.005894278405098386\n",
      "train loss:0.00939173651885274\n",
      "train loss:0.09331460173813678\n",
      "train loss:0.002582999385387818\n",
      "train loss:0.003696679808222915\n",
      "train loss:0.0003997606575145042\n",
      "train loss:0.002824092194065264\n",
      "train loss:0.0158744858270567\n",
      "train loss:0.004658966000358873\n",
      "train loss:0.005594323142953561\n",
      "train loss:0.0570420907703841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0032586935516295003\n",
      "train loss:0.013091411225720941\n",
      "train loss:0.0172028317696406\n",
      "train loss:0.0012990225444601078\n",
      "train loss:0.007414687599438479\n",
      "train loss:0.002314271562251934\n",
      "train loss:0.003491913760926778\n",
      "train loss:0.010862538611919857\n",
      "train loss:0.003930936078419868\n",
      "train loss:0.014692045756585035\n",
      "train loss:0.012385432332706517\n",
      "train loss:0.00019368894007827192\n",
      "train loss:0.0071122442372115735\n",
      "train loss:0.003641178738133\n",
      "train loss:0.00501933136749545\n",
      "train loss:0.0006381585456453982\n",
      "train loss:0.02636996935988275\n",
      "train loss:0.0032102835210036018\n",
      "train loss:0.017180056594117275\n",
      "train loss:0.01007997395889622\n",
      "train loss:0.004207467801395841\n",
      "train loss:0.009591313480302231\n",
      "train loss:0.012498896563868999\n",
      "train loss:0.01086586562201996\n",
      "train loss:0.004244806957836212\n",
      "train loss:0.0004226369987669729\n",
      "train loss:0.005158102981512797\n",
      "train loss:0.007590327633140911\n",
      "train loss:0.0019398351724495369\n",
      "train loss:0.0026077152785391865\n",
      "train loss:0.017243670788496656\n",
      "train loss:0.0016892660394458884\n",
      "train loss:0.007329080973566807\n",
      "train loss:0.018134155502260354\n",
      "train loss:0.013639938601109623\n",
      "train loss:0.0015508883028129928\n",
      "train loss:0.0073016486626800246\n",
      "train loss:0.0016742749080342388\n",
      "train loss:0.0070645908347528215\n",
      "train loss:0.006885146639054996\n",
      "train loss:0.004310598636439228\n",
      "train loss:0.005891888478935705\n",
      "train loss:0.00577677166566985\n",
      "train loss:0.004458294636068766\n",
      "train loss:0.0056376357163763725\n",
      "train loss:0.00645534992095449\n",
      "train loss:0.019793442091941994\n",
      "train loss:0.02369878592714257\n",
      "train loss:0.00799533683646741\n",
      "train loss:0.002338910692103879\n",
      "train loss:0.0054541576998475205\n",
      "train loss:0.024552414824489253\n",
      "train loss:0.004658944727377851\n",
      "train loss:0.002432731089281667\n",
      "train loss:0.0010224079329965963\n",
      "train loss:0.0124825103060431\n",
      "train loss:0.021865896930357995\n",
      "train loss:0.026025952699622223\n",
      "train loss:0.0018209842659266849\n",
      "train loss:0.003008757165713892\n",
      "train loss:0.004832178117065926\n",
      "train loss:0.02358010174569761\n",
      "train loss:0.006029465298397732\n",
      "train loss:0.0016842774058843846\n",
      "train loss:0.011613742459659722\n",
      "train loss:0.010518513002944832\n",
      "train loss:0.002414747826737178\n",
      "train loss:0.0018655436552654147\n",
      "train loss:0.0005859264899937883\n",
      "train loss:0.004574419172969168\n",
      "train loss:0.016358316646559116\n",
      "train loss:0.0033223545087924917\n",
      "train loss:0.006880499502657884\n",
      "train loss:0.002388479685412143\n",
      "train loss:0.0030802666043990173\n",
      "train loss:0.0017636360105919033\n",
      "train loss:0.0028863901131274744\n",
      "train loss:0.007085415623884211\n",
      "train loss:0.0024540136895952543\n",
      "train loss:0.007542464132672297\n",
      "train loss:0.007827224629510292\n",
      "train loss:0.00703592506182623\n",
      "train loss:0.004169968939135726\n",
      "train loss:0.0026694785704641914\n",
      "train loss:0.004413510425201464\n",
      "train loss:0.0027913305925827726\n",
      "train loss:0.0026932843998536526\n",
      "train loss:0.005933525425294841\n",
      "train loss:0.007625945160366294\n",
      "train loss:0.0027538937635717244\n",
      "train loss:0.0035366402119063143\n",
      "train loss:0.00020413311939076486\n",
      "train loss:0.006072400386252519\n",
      "train loss:0.004745492603319482\n",
      "train loss:0.013898676376255342\n",
      "train loss:0.0021318910802107225\n",
      "train loss:0.0007990939004551804\n",
      "train loss:0.0004287669843848235\n",
      "train loss:0.05671980120012259\n",
      "train loss:0.017415017078428827\n",
      "train loss:0.0063332366258999125\n",
      "train loss:0.0021379732469448266\n",
      "train loss:0.01745154260924562\n",
      "train loss:0.0017114369200946081\n",
      "train loss:0.0009895712645045767\n",
      "train loss:0.0005725008343094038\n",
      "train loss:0.000580828992320558\n",
      "train loss:0.010125486354363788\n",
      "train loss:0.0015888471777160725\n",
      "train loss:0.004769014547731052\n",
      "train loss:0.014070205333571078\n",
      "train loss:0.00040407749419785546\n",
      "train loss:0.001705356980503337\n",
      "train loss:0.006929009838405447\n",
      "train loss:0.0025229328202839214\n",
      "train loss:0.008055873573819683\n",
      "train loss:0.0033404482825604266\n",
      "train loss:0.007271646713776435\n",
      "train loss:0.008009716410657173\n",
      "train loss:0.0010478404980204022\n",
      "train loss:0.010233258462031616\n",
      "train loss:0.04118634560743684\n",
      "train loss:0.0012980408326536874\n",
      "train loss:0.025280587650683275\n",
      "train loss:0.004666251786907365\n",
      "train loss:0.008882577745477701\n",
      "train loss:0.002566670722391529\n",
      "train loss:0.00615433345156548\n",
      "train loss:0.0007641309611316296\n",
      "train loss:0.003705059393325595\n",
      "train loss:0.020203677118846394\n",
      "train loss:0.001668934531558337\n",
      "train loss:0.008249964162987447\n",
      "train loss:0.002307342422694012\n",
      "train loss:0.00354913572876101\n",
      "train loss:0.003993902707424601\n",
      "train loss:0.0016097608174997315\n",
      "train loss:0.001834852245691017\n",
      "train loss:0.004130566619201031\n",
      "train loss:0.0013760821216307491\n",
      "train loss:0.0024685976018640515\n",
      "train loss:0.0010242341339445655\n",
      "train loss:0.0022486952385074137\n",
      "train loss:0.0017205312176069272\n",
      "train loss:0.002336035675737381\n",
      "train loss:0.003392447340397749\n",
      "train loss:0.005343195439314192\n",
      "train loss:0.01420595808313107\n",
      "train loss:0.007124102631208803\n",
      "train loss:0.0024546035545448277\n",
      "train loss:0.0017838978813290876\n",
      "train loss:0.004982865638983761\n",
      "train loss:0.0019421381583945999\n",
      "train loss:0.004357402911659545\n",
      "train loss:0.0038368970572814965\n",
      "train loss:0.006805901348838695\n",
      "train loss:0.07101669754582925\n",
      "train loss:0.009385404552581139\n",
      "train loss:0.005410863501783918\n",
      "train loss:0.000438826513999953\n",
      "train loss:0.009873561093046913\n",
      "train loss:0.0010749272094098563\n",
      "train loss:0.008520189091796993\n",
      "train loss:0.017100242385784902\n",
      "train loss:0.0009643303785005716\n",
      "train loss:0.0006685491391701718\n",
      "train loss:0.006638398500181759\n",
      "train loss:0.002140452200169939\n",
      "train loss:0.0073554632367770455\n",
      "train loss:0.005086538774975316\n",
      "train loss:0.00045651918603913257\n",
      "train loss:0.005053848790770381\n",
      "train loss:0.011044421325443\n",
      "train loss:0.010936724558616917\n",
      "train loss:0.0006617332646856363\n",
      "train loss:0.003108310142246089\n",
      "train loss:0.0019065296161591067\n",
      "train loss:0.0025915413355813845\n",
      "train loss:0.004264611881882886\n",
      "train loss:0.0024192151990780415\n",
      "train loss:0.004013753951940836\n",
      "train loss:0.010052879191450108\n",
      "train loss:0.003270138940073959\n",
      "train loss:0.0058563336091168264\n",
      "train loss:0.004033208083819917\n",
      "train loss:0.0014851593426500511\n",
      "train loss:0.002067022692572681\n",
      "train loss:0.006134818019070191\n",
      "train loss:0.0058993447988933845\n",
      "train loss:0.007371120365259955\n",
      "train loss:0.005997098888016535\n",
      "train loss:0.00888484240268252\n",
      "train loss:0.0011028344831953063\n",
      "train loss:0.0065481746068755\n",
      "train loss:0.001272881329192422\n",
      "train loss:0.0016707444275596004\n",
      "train loss:0.0016015085833875255\n",
      "train loss:0.026510106209914976\n",
      "train loss:0.008484078894720314\n",
      "train loss:0.0030719030293241633\n",
      "train loss:0.001329484631845994\n",
      "train loss:0.028477068472530793\n",
      "train loss:0.0010492738216548857\n",
      "train loss:0.004482337746840297\n",
      "train loss:0.012969415530568745\n",
      "train loss:0.007923664242208023\n",
      "train loss:0.003090256173725984\n",
      "train loss:0.005587100733257023\n",
      "train loss:0.0019471412269245266\n",
      "train loss:0.0036113097110568987\n",
      "train loss:0.006139819030722043\n",
      "train loss:0.00452902904610817\n",
      "train loss:0.0005146909324854236\n",
      "train loss:0.023364698585963316\n",
      "train loss:0.003300383762586099\n",
      "train loss:0.0048499924044224044\n",
      "train loss:0.0013608826884828826\n",
      "train loss:0.006894637946230398\n",
      "train loss:0.0012861118316459246\n",
      "train loss:0.0038475440752000468\n",
      "train loss:0.00928272354065578\n",
      "train loss:0.003992382888501327\n",
      "train loss:0.0008966621088350121\n",
      "train loss:0.009582182356672984\n",
      "train loss:0.002953842978054869\n",
      "train loss:0.009722138140400391\n",
      "train loss:0.0012481275892258048\n",
      "train loss:0.001482232779739377\n",
      "train loss:0.011682093088776553\n",
      "train loss:0.0332910444945977\n",
      "train loss:0.0030439928692394345\n",
      "train loss:0.0009284008225925154\n",
      "train loss:0.015448185897234297\n",
      "train loss:0.0009580845486636056\n",
      "train loss:0.007868862672738815\n",
      "train loss:0.002088190523839904\n",
      "train loss:0.0035453385872088305\n",
      "train loss:0.002247221217703195\n",
      "train loss:0.004222737271619028\n",
      "train loss:0.0017014586035575254\n",
      "train loss:0.002109982898343311\n",
      "train loss:0.0012564731121985583\n",
      "train loss:0.0021216907852098506\n",
      "train loss:0.004801328261270828\n",
      "train loss:0.0011497779196784576\n",
      "train loss:0.011648837315622926\n",
      "train loss:0.0032841011595640653\n",
      "train loss:0.000857430177210147\n",
      "train loss:0.0006687304831433303\n",
      "train loss:0.0034242539993272064\n",
      "train loss:0.0021497732467168763\n",
      "train loss:0.006509656821176932\n",
      "train loss:0.007498040685460382\n",
      "train loss:0.002111559547476107\n",
      "train loss:0.004201186686645823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0013514683908591458\n",
      "train loss:0.0011265236432445405\n",
      "train loss:0.006874904782552458\n",
      "train loss:0.0012481184246911888\n",
      "train loss:0.001002283883106156\n",
      "train loss:0.018069552618945682\n",
      "train loss:0.004073488424105161\n",
      "train loss:0.0009801431446290823\n",
      "train loss:0.0026512717619310354\n",
      "train loss:0.0017449193003198004\n",
      "train loss:0.0032026039664936647\n",
      "train loss:0.0019718226731269615\n",
      "train loss:0.0009923288189096137\n",
      "train loss:0.0028144990371772025\n",
      "train loss:0.0007650773480629659\n",
      "train loss:0.0004168139025021335\n",
      "train loss:0.0021850520348311434\n",
      "train loss:0.004236877917473078\n",
      "train loss:0.0064435936204058405\n",
      "train loss:0.0001702157117090432\n",
      "train loss:0.002997372018574136\n",
      "train loss:0.0038620731509771337\n",
      "train loss:0.004731745322670785\n",
      "train loss:0.00371394538019616\n",
      "train loss:0.00480749248569738\n",
      "train loss:0.016846885774564595\n",
      "train loss:0.003763154796269309\n",
      "train loss:0.01466523495980932\n",
      "train loss:0.00692985229361326\n",
      "train loss:0.004465578295760248\n",
      "train loss:0.0008369579809078903\n",
      "train loss:0.017076513459430277\n",
      "train loss:0.004198383386063316\n",
      "train loss:0.0012554118829890477\n",
      "train loss:0.002103687072416063\n",
      "train loss:0.001910066939188543\n",
      "train loss:0.02088758509922033\n",
      "train loss:0.01540775705762503\n",
      "train loss:0.00437408126351384\n",
      "train loss:0.001981016629568786\n",
      "train loss:0.009621353154785135\n",
      "train loss:0.0015534666824002063\n",
      "train loss:0.0005545689538223274\n",
      "train loss:0.010878281872503321\n",
      "train loss:0.019713504696781445\n",
      "train loss:0.0038236413988887476\n",
      "train loss:0.017241028548837908\n",
      "train loss:0.018747234135482682\n",
      "train loss:0.019746617758427\n",
      "train loss:0.004262932604749457\n",
      "train loss:0.018947802157257825\n",
      "train loss:0.014687899327288369\n",
      "train loss:0.0014803704481292073\n",
      "train loss:0.005658241605739387\n",
      "train loss:0.0038277135867980723\n",
      "train loss:0.0015538598338881867\n",
      "train loss:0.006139018243847387\n",
      "train loss:0.001214416941001272\n",
      "train loss:0.007310368659716905\n",
      "train loss:0.003052048110029338\n",
      "train loss:0.0008284535852549921\n",
      "train loss:0.004190309427628256\n",
      "train loss:0.0037098500802788333\n",
      "train loss:0.0033441653728296912\n",
      "train loss:0.007193293171431418\n",
      "train loss:0.0011112399228330018\n",
      "train loss:0.005142188225983946\n",
      "train loss:0.005685748997290472\n",
      "train loss:0.0014008252513979284\n",
      "train loss:0.021947636913116103\n",
      "train loss:0.0031921133057192337\n",
      "train loss:0.012777364165821046\n",
      "train loss:0.009846847519950954\n",
      "train loss:0.003019203195783168\n",
      "train loss:0.0037531404042187915\n",
      "train loss:0.0009113668028178874\n",
      "train loss:0.004397600822341396\n",
      "train loss:0.003457552862375428\n",
      "train loss:0.024920094433378108\n",
      "train loss:0.004498838266642237\n",
      "train loss:0.00043270957397179103\n",
      "train loss:0.01005656050064294\n",
      "train loss:0.00477677978780985\n",
      "train loss:0.0016536812243984603\n",
      "train loss:0.028855221869063852\n",
      "train loss:0.0055188788549604215\n",
      "train loss:0.0032645001438352667\n",
      "train loss:0.0018319484413978815\n",
      "train loss:0.0013342304810895966\n",
      "train loss:0.0017579300930310102\n",
      "train loss:0.004507553012236446\n",
      "train loss:0.006268561079954292\n",
      "train loss:0.0007665516399364785\n",
      "train loss:0.001125956239400292\n",
      "train loss:0.002407641682031308\n",
      "train loss:0.0031341315278230553\n",
      "train loss:0.0012125570636742254\n",
      "train loss:0.0019569920731629608\n",
      "train loss:0.004552330618912406\n",
      "train loss:0.004545618458051248\n",
      "train loss:0.005192584762457323\n",
      "train loss:0.010535239627996287\n",
      "train loss:0.008105772544439694\n",
      "train loss:0.005309894011347814\n",
      "train loss:0.0007898477893996973\n",
      "train loss:0.0016349353897603647\n",
      "train loss:0.00033706177542707904\n",
      "train loss:0.000494171129789543\n",
      "train loss:0.014874040260261815\n",
      "train loss:0.0017379883840321533\n",
      "train loss:0.011764020921045655\n",
      "train loss:0.004143717596214473\n",
      "train loss:0.005294285636911079\n",
      "=== epoch:12, train acc:0.996, test acc:0.987 ===\n",
      "train loss:0.0018346053899370408\n",
      "train loss:0.0015100059906205496\n",
      "train loss:0.0011011859908274576\n",
      "train loss:0.0029869426825608\n",
      "train loss:0.003413952705963718\n",
      "train loss:0.013618463889997245\n",
      "train loss:0.08477752649977954\n",
      "train loss:0.004946197477601813\n",
      "train loss:0.007286314507805828\n",
      "train loss:0.0030460669917848466\n",
      "train loss:0.0008225387753478842\n",
      "train loss:0.009133818928191878\n",
      "train loss:0.0006792924978358525\n",
      "train loss:0.008009287205056795\n",
      "train loss:0.003138488456705034\n",
      "train loss:0.004851053512134918\n",
      "train loss:0.005514947223141082\n",
      "train loss:0.0012911441126344176\n",
      "train loss:0.005544341722612725\n",
      "train loss:0.0030067930148371426\n",
      "train loss:0.003459453529077184\n",
      "train loss:0.008695914028674619\n",
      "train loss:0.003121239849623367\n",
      "train loss:0.008273379968849432\n",
      "train loss:0.008381909942056802\n",
      "train loss:0.009149196569826691\n",
      "train loss:0.02960429690212883\n",
      "train loss:0.002860978814776427\n",
      "train loss:0.0038656475483381525\n",
      "train loss:0.0033272101096342038\n",
      "train loss:0.0027223345565780834\n",
      "train loss:0.013590342069380167\n",
      "train loss:0.0014745372042188373\n",
      "train loss:0.0036064732958144934\n",
      "train loss:0.0007746373318308115\n",
      "train loss:0.006726550385933524\n",
      "train loss:0.008295897227072078\n",
      "train loss:0.0032533402216857184\n",
      "train loss:0.004562331478001761\n",
      "train loss:0.005606970983095889\n",
      "train loss:0.009285953763066039\n",
      "train loss:0.004615313220297071\n",
      "train loss:0.0019764140079860525\n",
      "train loss:0.0009399972624998799\n",
      "train loss:0.0007195814678796611\n",
      "train loss:0.0019107079695529564\n",
      "train loss:0.00264152873298387\n",
      "train loss:0.003360571841832024\n",
      "train loss:0.008658948565778283\n",
      "train loss:0.00531241472606058\n",
      "train loss:0.008768882294410746\n",
      "train loss:0.0030550905478084777\n",
      "train loss:0.0002727597964915915\n",
      "train loss:0.000979184734238915\n",
      "train loss:0.014277282914298577\n",
      "train loss:0.0038237547493643483\n",
      "train loss:0.01293008656850988\n",
      "train loss:0.0017502668715046695\n",
      "train loss:0.004218122420589579\n",
      "train loss:0.0018821184026786284\n",
      "train loss:0.0018917121781347648\n",
      "train loss:0.004966185260027336\n",
      "train loss:0.0060562390343498855\n",
      "train loss:0.06868643733227411\n",
      "train loss:0.015544342043816722\n",
      "train loss:0.005493373674984679\n",
      "train loss:0.02140620439941388\n",
      "train loss:0.0011358125696751408\n",
      "train loss:0.003590660817086228\n",
      "train loss:0.01942834489644416\n",
      "train loss:0.0012659144660947283\n",
      "train loss:0.006565001496559032\n",
      "train loss:0.007946405411456215\n",
      "train loss:0.006972387143098392\n",
      "train loss:0.010825026133380662\n",
      "train loss:0.0020597110502452\n",
      "train loss:0.004549194541239415\n",
      "train loss:0.00035428530250113056\n",
      "train loss:0.00925331076975127\n",
      "train loss:0.009958439170618954\n",
      "train loss:0.008290985395881604\n",
      "train loss:0.004929106418839579\n",
      "train loss:0.000786215987693871\n",
      "train loss:0.010124533424514604\n",
      "train loss:0.006974657622746952\n",
      "train loss:0.006937987554112143\n",
      "train loss:0.008501904895936174\n",
      "train loss:0.0006235572943676742\n",
      "train loss:0.0068965551789461265\n",
      "train loss:0.006010674982787682\n",
      "train loss:0.0011255166519220639\n",
      "train loss:0.007428924448876095\n",
      "train loss:0.0019042385086779786\n",
      "train loss:0.0018216145200758785\n",
      "train loss:0.004886683923973793\n",
      "train loss:0.0015576798801477047\n",
      "train loss:0.02375183808092891\n",
      "train loss:0.004263008555801804\n",
      "train loss:0.018748775603353057\n",
      "train loss:0.0018849148605012344\n",
      "train loss:0.016689798188135853\n",
      "train loss:0.0015685764944251947\n",
      "train loss:0.013148590960117583\n",
      "train loss:0.006896077317038951\n",
      "train loss:0.001786260558352521\n",
      "train loss:0.006784002987098525\n",
      "train loss:0.0038315918694499782\n",
      "train loss:0.004096892406520585\n",
      "train loss:0.002215998934221724\n",
      "train loss:0.065876034040959\n",
      "train loss:0.0008744191348229456\n",
      "train loss:0.0023151797361685646\n",
      "train loss:0.0009455400862312768\n",
      "train loss:0.0015158968311442455\n",
      "train loss:0.0010629990172686397\n",
      "train loss:0.0015567702740950018\n",
      "train loss:0.05527296226127711\n",
      "train loss:0.005667796769747347\n",
      "train loss:0.007039893524455142\n",
      "train loss:0.0005107505566131682\n",
      "train loss:0.0008860888431145822\n",
      "train loss:0.0024753459758919973\n",
      "train loss:0.0035763067330958753\n",
      "train loss:0.000561495104921539\n",
      "train loss:0.0012692730290723817\n",
      "train loss:0.007362740182395485\n",
      "train loss:0.0021063592099708974\n",
      "train loss:0.0044290061819787785\n",
      "train loss:0.010981866600615309\n",
      "train loss:0.003142218881515258\n",
      "train loss:0.009372433609152592\n",
      "train loss:0.002789141495353929\n",
      "train loss:0.004835057940271502\n",
      "train loss:0.009056766251991588\n",
      "train loss:0.00315043807468709\n",
      "train loss:0.003870461949016197\n",
      "train loss:0.0007188922793210229\n",
      "train loss:0.000502926606560122\n",
      "train loss:0.0017180836697020833\n",
      "train loss:0.0038412459116089126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0031905794017278903\n",
      "train loss:0.0024564372995959263\n",
      "train loss:0.0006351449984545752\n",
      "train loss:0.015138653588381007\n",
      "train loss:0.0025715620178871175\n",
      "train loss:0.006034538036605902\n",
      "train loss:0.00019597047702187627\n",
      "train loss:0.016568972833393966\n",
      "train loss:0.007177931547954831\n",
      "train loss:0.004518831712549066\n",
      "train loss:0.0038844418841758005\n",
      "train loss:0.0014898859845153048\n",
      "train loss:0.005057790937197753\n",
      "train loss:0.032609483326557775\n",
      "train loss:0.003792713474546587\n",
      "train loss:0.0031777624262367414\n",
      "train loss:0.0013275688398439436\n",
      "train loss:0.003330065166581109\n",
      "train loss:0.00034017530089354496\n",
      "train loss:0.0008769459196782359\n",
      "train loss:0.010543035074647138\n",
      "train loss:0.005067376522343237\n",
      "train loss:0.007311573567156142\n",
      "train loss:0.002311440624864334\n",
      "train loss:0.018276446536165298\n",
      "train loss:0.0028678784524461503\n",
      "train loss:0.001855890077326678\n",
      "train loss:0.005989159418203915\n",
      "train loss:0.008558819264435361\n",
      "train loss:0.0026705128678035516\n",
      "train loss:0.0033433769917306337\n",
      "train loss:0.002401353568481084\n",
      "train loss:0.02100107245693995\n",
      "train loss:0.00263918161017734\n",
      "train loss:0.007527634029357482\n",
      "train loss:0.0004492569487569169\n",
      "train loss:0.0007943504625268229\n",
      "train loss:0.0023884624322906443\n",
      "train loss:0.0020739062169018276\n",
      "train loss:0.004908888410386312\n",
      "train loss:0.014590769368660933\n",
      "train loss:0.0025956660054911583\n",
      "train loss:0.06706402371681917\n",
      "train loss:0.004660253440341768\n",
      "train loss:0.0007747898666788641\n",
      "train loss:0.005839878317644443\n",
      "train loss:0.0015819568112756571\n",
      "train loss:0.0026622695294966493\n",
      "train loss:0.0031997894371359483\n",
      "train loss:0.0006389383932399323\n",
      "train loss:0.005356958316068815\n",
      "train loss:0.0033662056534276264\n",
      "train loss:0.007095104029293034\n",
      "train loss:0.005147306564579628\n",
      "train loss:0.002928103982972271\n",
      "train loss:0.00027328241330705163\n",
      "train loss:0.000735466997347715\n",
      "train loss:0.002960981111655372\n",
      "train loss:0.00276221194767884\n",
      "train loss:0.008271882173614768\n",
      "train loss:0.0006724924460315066\n",
      "train loss:0.0018389885656037983\n",
      "train loss:0.003123767156387529\n",
      "train loss:0.006392126639693438\n",
      "train loss:0.005553043471949757\n",
      "train loss:0.0007318398435442553\n",
      "train loss:0.004304386735349803\n",
      "train loss:0.0013173284707216398\n",
      "train loss:0.018572226674724045\n",
      "train loss:0.0006139394978736308\n",
      "train loss:0.004047412130350125\n",
      "train loss:0.0014086010332157695\n",
      "train loss:0.0073395221714952705\n",
      "train loss:0.011661994159661055\n",
      "train loss:0.006236611340425605\n",
      "train loss:0.0007216058631645312\n",
      "train loss:0.0008663046572851189\n",
      "train loss:0.0029565697555561767\n",
      "train loss:0.0031028274855254222\n",
      "train loss:0.019213850372060012\n",
      "train loss:0.0019356845847649392\n",
      "train loss:0.0013662964083849614\n",
      "train loss:0.0011667793301179934\n",
      "train loss:0.0060833172468593546\n",
      "train loss:0.000770096355390498\n",
      "train loss:0.0010809334066975056\n",
      "train loss:0.0009902994318872881\n",
      "train loss:0.003412155318075631\n",
      "train loss:0.0010240224392815745\n",
      "train loss:0.008352777916886987\n",
      "train loss:0.0026813129657893083\n",
      "train loss:0.003967748043694614\n",
      "train loss:0.0038385056412047367\n",
      "train loss:0.007048339985025866\n",
      "train loss:0.010168277357971402\n",
      "train loss:0.0009742169128709374\n",
      "train loss:0.009281006431244184\n",
      "train loss:0.0009585453237749797\n",
      "train loss:0.004464676448154561\n",
      "train loss:0.001237607824210809\n",
      "train loss:0.0025248501618877293\n",
      "train loss:0.0042065446912843635\n",
      "train loss:0.00299392904268717\n",
      "train loss:0.0012005681270877886\n",
      "train loss:0.00911024811135367\n",
      "train loss:0.00917319774346807\n",
      "train loss:0.004927193815675738\n",
      "train loss:0.0013304396727867743\n",
      "train loss:0.0062528101618861635\n",
      "train loss:0.0037831826004111418\n",
      "train loss:0.0024736003051716686\n",
      "train loss:0.024146636545434336\n",
      "train loss:0.00022960629563458605\n",
      "train loss:0.010404855678873915\n",
      "train loss:0.0018399802921587043\n",
      "train loss:0.00802243242090387\n",
      "train loss:0.0003783003608920796\n",
      "train loss:0.003466970429713401\n",
      "train loss:0.004343259699922227\n",
      "train loss:0.004763347837879541\n",
      "train loss:0.001729015424547336\n",
      "train loss:0.007814985710376478\n",
      "train loss:0.0005774976518053915\n",
      "train loss:0.002579716684126797\n",
      "train loss:0.002401554162623082\n",
      "train loss:0.0035051860710113474\n",
      "train loss:0.012064603154775746\n",
      "train loss:0.0088741703452685\n",
      "train loss:0.0019975486238331917\n",
      "train loss:0.0074378871962463055\n",
      "train loss:0.0011322341184000146\n",
      "train loss:0.0010453327257742456\n",
      "train loss:0.002429854950502773\n",
      "train loss:0.023671293860764418\n",
      "train loss:0.044677578124616736\n",
      "train loss:0.003472513615441874\n",
      "train loss:0.0032227455221635853\n",
      "train loss:0.008465792327474396\n",
      "train loss:0.013747038960627527\n",
      "train loss:0.004902487407052172\n",
      "train loss:0.0058814974306716184\n",
      "train loss:0.020141873023587435\n",
      "train loss:0.006547462291184036\n",
      "train loss:0.008799010276581544\n",
      "train loss:0.0017427422474149499\n",
      "train loss:0.037528750873761924\n",
      "train loss:0.007246917961016088\n",
      "train loss:0.0004632695404417524\n",
      "train loss:0.0021921901143583562\n",
      "train loss:0.007622897448517727\n",
      "train loss:0.009466673625616755\n",
      "train loss:0.002567312103059447\n",
      "train loss:0.009870174041895143\n",
      "train loss:0.0013595242864439005\n",
      "train loss:0.0019579199909991445\n",
      "train loss:0.0004115316745018148\n",
      "train loss:0.011770623789686739\n",
      "train loss:0.01132751833215062\n",
      "train loss:0.0033092397728028706\n",
      "train loss:0.010810291500559401\n",
      "train loss:0.005503732122977668\n",
      "train loss:0.011488073440507528\n",
      "train loss:0.002310572329039469\n",
      "train loss:0.013570683205059296\n",
      "train loss:0.00845731713157312\n",
      "train loss:0.011699406805340875\n",
      "train loss:0.00441363554211242\n",
      "train loss:0.00685261726492563\n",
      "train loss:0.002887332541811452\n",
      "train loss:0.014219540430425568\n",
      "train loss:0.01906317717115197\n",
      "train loss:0.008480019542245011\n",
      "train loss:0.019124613967618175\n",
      "train loss:0.0072057335300084804\n",
      "train loss:0.0017700207233389384\n",
      "train loss:0.0026505576283634624\n",
      "train loss:0.01717229661846239\n",
      "train loss:0.002601172982398736\n",
      "train loss:0.0027165220114089743\n",
      "train loss:0.0037128929119248887\n",
      "train loss:0.005022165589237982\n",
      "train loss:0.0010964302472492452\n",
      "train loss:0.04031760323600817\n",
      "train loss:0.0010431187269970717\n",
      "train loss:0.01416244407695297\n",
      "train loss:0.010904153579510101\n",
      "train loss:0.0010874850290294137\n",
      "train loss:0.0018078498024787085\n",
      "train loss:0.019064695618787198\n",
      "train loss:0.0011902048458198545\n",
      "train loss:0.001896805652910832\n",
      "train loss:0.007147997884093145\n",
      "train loss:0.0017186641303370842\n",
      "train loss:0.001333625441791217\n",
      "train loss:0.0072007418477995225\n",
      "train loss:0.0026615447259211744\n",
      "train loss:0.006122188570688953\n",
      "train loss:0.011644047740224055\n",
      "train loss:0.0013942766899865\n",
      "train loss:0.015612941328885585\n",
      "train loss:0.0018621903668832567\n",
      "train loss:0.0018020553773892142\n",
      "train loss:0.0023097275448125745\n",
      "train loss:0.004280171798815658\n",
      "train loss:0.004569047380725267\n",
      "train loss:0.005923148585951299\n",
      "train loss:0.012611364410588397\n",
      "train loss:0.005531243473653152\n",
      "train loss:0.0016225100812133325\n",
      "train loss:0.008350847264701389\n",
      "train loss:0.00028648539715187893\n",
      "train loss:0.005354547960881339\n",
      "train loss:0.007325854660976921\n",
      "train loss:0.0029491843928305893\n",
      "train loss:0.0009436488011772756\n",
      "train loss:0.006031979751619217\n",
      "train loss:0.004857281261475017\n",
      "train loss:0.008629930659960419\n",
      "train loss:0.0008596587842751709\n",
      "train loss:0.0018641022986802974\n",
      "train loss:0.006528382221878476\n",
      "train loss:0.0007473224164532298\n",
      "train loss:0.0008979972190009503\n",
      "train loss:0.0015713148491669745\n",
      "train loss:0.006086595304847746\n",
      "train loss:0.010512687946222364\n",
      "train loss:0.0017018358622887877\n",
      "train loss:0.033519988566861614\n",
      "train loss:0.002071189456127127\n",
      "train loss:0.00036539380487466566\n",
      "train loss:0.011497523584759901\n",
      "train loss:0.014479234311883051\n",
      "train loss:0.017039903026444085\n",
      "train loss:0.0035025356832149913\n",
      "train loss:0.00482051599000599\n",
      "train loss:0.004946234550822063\n",
      "train loss:0.03522634359984211\n",
      "train loss:0.011733342379941109\n",
      "train loss:0.004432516912417858\n",
      "train loss:6.765521486728124e-05\n",
      "train loss:0.0035392207983866004\n",
      "train loss:0.013521810835666654\n",
      "train loss:0.0016102992613342912\n",
      "train loss:0.012699353699330153\n",
      "train loss:0.0035240562973964107\n",
      "train loss:0.0027202942120619317\n",
      "train loss:0.02786441416779289\n",
      "train loss:0.009767626578622585\n",
      "train loss:0.00280585836695542\n",
      "train loss:0.0018097818250917199\n",
      "train loss:0.002179888978085803\n",
      "train loss:0.002449489707675565\n",
      "train loss:0.0031703820088239206\n",
      "train loss:0.005443307345840147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002973106390942626\n",
      "train loss:0.015429344277708845\n",
      "train loss:0.01319243801699381\n",
      "train loss:0.005313561390113286\n",
      "train loss:0.006106277665508442\n",
      "train loss:0.0045005640154557195\n",
      "train loss:0.005383594651869506\n",
      "train loss:0.018750870192800806\n",
      "train loss:0.018901040928517698\n",
      "train loss:0.005716794907724435\n",
      "train loss:0.0037395817587461654\n",
      "train loss:0.005327691874211868\n",
      "train loss:0.002645457170248125\n",
      "train loss:0.011378084969607245\n",
      "train loss:0.004260851574144991\n",
      "train loss:0.000325678761271442\n",
      "train loss:0.00030039848048630277\n",
      "train loss:0.002051858291974874\n",
      "train loss:0.0008066975129179672\n",
      "train loss:0.002046264411358221\n",
      "train loss:0.0025068649537746414\n",
      "train loss:0.012877223055429068\n",
      "train loss:0.002815837038082483\n",
      "train loss:0.00935502416019706\n",
      "train loss:0.002788992406455724\n",
      "train loss:0.014914145328979783\n",
      "train loss:0.0001897282780682145\n",
      "train loss:0.0004636116812584238\n",
      "train loss:0.004971425644066597\n",
      "train loss:0.0007709913465831606\n",
      "train loss:0.0030983681681964765\n",
      "train loss:0.017736441487311426\n",
      "train loss:0.006121293691700124\n",
      "train loss:0.004117442634509131\n",
      "train loss:0.0021689023507579642\n",
      "train loss:0.00966930771180013\n",
      "train loss:0.031294243695395185\n",
      "train loss:0.0017430560905516176\n",
      "train loss:0.00011772868069703416\n",
      "train loss:0.0006499813827820382\n",
      "train loss:0.002673150438774552\n",
      "train loss:0.007676375997559253\n",
      "train loss:0.002230839272503072\n",
      "train loss:0.016297569359727128\n",
      "train loss:0.14450219514585838\n",
      "train loss:0.00727051692961491\n",
      "train loss:0.0006989922138870811\n",
      "train loss:0.002068259883418401\n",
      "train loss:0.0021300912866474126\n",
      "train loss:0.000852876196362493\n",
      "train loss:0.003290876154050344\n",
      "train loss:0.015909999323474727\n",
      "train loss:0.029117621374751983\n",
      "train loss:0.006577988292866612\n",
      "train loss:0.00543802574482858\n",
      "train loss:0.0037269068477183555\n",
      "train loss:0.005822380710923407\n",
      "train loss:0.004484249222774866\n",
      "train loss:0.0019421235778156137\n",
      "train loss:0.013587071053717266\n",
      "train loss:0.0036645302948701015\n",
      "train loss:0.00832295046250744\n",
      "train loss:0.00517470248021397\n",
      "train loss:0.0010645974797539332\n",
      "train loss:0.0036250008385233096\n",
      "train loss:0.006744418701742983\n",
      "train loss:0.005942978040599571\n",
      "train loss:0.003725282981552936\n",
      "train loss:0.005021931670958201\n",
      "train loss:0.006163065437615244\n",
      "train loss:0.011089671972506362\n",
      "train loss:0.001414210069900888\n",
      "train loss:0.00331000938349122\n",
      "train loss:0.00222161175938794\n",
      "train loss:0.004632062971149537\n",
      "train loss:0.01522992725432013\n",
      "train loss:0.004975513758044181\n",
      "train loss:0.0017180671583818508\n",
      "train loss:0.0005267696502463067\n",
      "train loss:0.0013459104205992764\n",
      "train loss:0.0007903940743599785\n",
      "train loss:0.0031618930587387285\n",
      "train loss:0.0029859485401695805\n",
      "train loss:0.0005173534352387579\n",
      "train loss:0.011625218574456347\n",
      "train loss:0.0030601850481498318\n",
      "train loss:0.0009159183423670772\n",
      "train loss:0.006542660244394816\n",
      "train loss:0.010695518275272813\n",
      "train loss:0.0009247597131337758\n",
      "train loss:0.004343849253954187\n",
      "train loss:0.0027531352315745745\n",
      "train loss:0.008635464176640144\n",
      "train loss:0.010841038098632327\n",
      "train loss:0.0025327991121487305\n",
      "train loss:0.006474494887228142\n",
      "train loss:0.00390937876537779\n",
      "train loss:0.0007113967826612297\n",
      "train loss:0.010245225347302121\n",
      "train loss:0.0012900807203011782\n",
      "train loss:0.014500942604701566\n",
      "train loss:0.0007040407178676298\n",
      "train loss:0.0035062123996218554\n",
      "train loss:0.005784680402442645\n",
      "train loss:0.0012202540078939794\n",
      "train loss:0.013805698195120524\n",
      "train loss:0.00781687542981087\n",
      "train loss:0.0041950047766732374\n",
      "train loss:0.0027573375035334245\n",
      "train loss:0.003806225276554288\n",
      "train loss:0.00457990197974996\n",
      "train loss:0.006166000924736136\n",
      "train loss:0.0064962378294845\n",
      "train loss:0.0011787635230454876\n",
      "train loss:0.0007981377899075009\n",
      "train loss:0.01035165999007854\n",
      "train loss:0.017599780020112536\n",
      "train loss:0.005613508303025372\n",
      "train loss:0.02171149880053826\n",
      "train loss:0.010173460492582187\n",
      "train loss:0.0015402698325809447\n",
      "train loss:0.004435242720581494\n",
      "train loss:0.008721644050937392\n",
      "train loss:0.0005580234883858155\n",
      "train loss:0.008957171639635844\n",
      "train loss:0.007286397633730032\n",
      "train loss:0.006347388139114227\n",
      "train loss:0.00405650542766333\n",
      "train loss:0.0050009940458932275\n",
      "train loss:0.006595810541578924\n",
      "train loss:0.014153987683733858\n",
      "train loss:0.006057049820595903\n",
      "train loss:0.0070249336796152214\n",
      "train loss:0.00243157059190871\n",
      "train loss:0.012441089217677144\n",
      "train loss:0.0030783299276193566\n",
      "train loss:0.0013534006065271161\n",
      "train loss:0.0014745928547898388\n",
      "train loss:0.012173146024765675\n",
      "train loss:0.007125990585324548\n",
      "train loss:0.014981342407046237\n",
      "train loss:0.005095712999690028\n",
      "train loss:0.005459446725489838\n",
      "train loss:0.004100189056083825\n",
      "train loss:0.010277985893022402\n",
      "train loss:0.004879942839726725\n",
      "train loss:0.006945363100565729\n",
      "train loss:0.005111242782063236\n",
      "train loss:0.008038696361226557\n",
      "train loss:0.0006311378341566884\n",
      "train loss:0.0004780668916233818\n",
      "train loss:0.0020281136905747335\n",
      "train loss:0.006553164587638542\n",
      "train loss:0.004512032010836785\n",
      "train loss:0.0010575049904752007\n",
      "train loss:0.001079043587340959\n",
      "train loss:0.00972467906035893\n",
      "train loss:0.0024422704818083257\n",
      "train loss:0.00429322177927697\n",
      "train loss:0.003101334721259535\n",
      "train loss:0.008219719491183414\n",
      "train loss:0.0068681018427943176\n",
      "train loss:0.0007183208364166413\n",
      "train loss:0.0017649916590445152\n",
      "train loss:0.0028346635562882124\n",
      "train loss:0.0064467435793326925\n",
      "train loss:0.0009496394157012234\n",
      "train loss:0.016954732247052122\n",
      "train loss:0.0050512926737488716\n",
      "train loss:0.0007438788740431985\n",
      "train loss:0.004544764558108569\n",
      "train loss:0.0011385597559475592\n",
      "train loss:0.00948127947531059\n",
      "train loss:0.020075567880283137\n",
      "train loss:0.035549485117661456\n",
      "train loss:0.0014793449530747615\n",
      "train loss:0.003568346592606666\n",
      "train loss:0.0020864725618314644\n",
      "train loss:0.009696377074445192\n",
      "train loss:0.05064004293700939\n",
      "train loss:0.0009734979009597749\n",
      "train loss:0.0001594946557967916\n",
      "train loss:0.001788072197995574\n",
      "train loss:0.0037446101005836506\n",
      "train loss:0.0005054252922665536\n",
      "train loss:0.03313785124269989\n",
      "train loss:0.009516196584791282\n",
      "train loss:0.0025077499271706277\n",
      "train loss:0.005585236775159114\n",
      "train loss:0.0005696766215389167\n",
      "train loss:0.00749476731990699\n",
      "train loss:0.009561909851309735\n",
      "train loss:0.008871173113051774\n",
      "train loss:0.011872706584450747\n",
      "train loss:0.0029654658000354372\n",
      "train loss:0.007216311420826027\n",
      "train loss:0.006673586166823025\n",
      "train loss:0.0062029228934039685\n",
      "train loss:0.007000184805748947\n",
      "train loss:0.020542337274347906\n",
      "train loss:0.0015902812230682145\n",
      "train loss:0.002766850256991854\n",
      "train loss:0.0006736197900906345\n",
      "train loss:0.008363342832342583\n",
      "train loss:0.01697201161052386\n",
      "train loss:0.0007677541519905336\n",
      "=== epoch:13, train acc:0.998, test acc:0.984 ===\n",
      "train loss:0.040337233674060495\n",
      "train loss:0.012143792278671406\n",
      "train loss:0.0054519775344344015\n",
      "train loss:0.010203621354771254\n",
      "train loss:0.00324704906770365\n",
      "train loss:0.005850504434467229\n",
      "train loss:0.004197203325939035\n",
      "train loss:0.01605929655020498\n",
      "train loss:0.0007602253104365062\n",
      "train loss:0.012336727795596962\n",
      "train loss:0.014222012166063686\n",
      "train loss:0.005254621167937952\n",
      "train loss:0.01312023955779291\n",
      "train loss:0.005142675511297675\n",
      "train loss:0.0006211869646334633\n",
      "train loss:0.0005325112853931446\n",
      "train loss:0.004596474206098936\n",
      "train loss:0.008542225370304763\n",
      "train loss:0.0037950473338497995\n",
      "train loss:0.04213132363091938\n",
      "train loss:0.0005799319564127743\n",
      "train loss:0.009704664310681307\n",
      "train loss:0.003388340269119661\n",
      "train loss:0.007014573140826348\n",
      "train loss:0.0006839212200573761\n",
      "train loss:0.0016401451594348913\n",
      "train loss:0.009216773445027384\n",
      "train loss:0.002144142964605197\n",
      "train loss:0.005348800989403605\n",
      "train loss:0.05809826875094081\n",
      "train loss:0.003192941076387703\n",
      "train loss:0.008588613483236127\n",
      "train loss:0.0014548376579819435\n",
      "train loss:0.0016625936533928394\n",
      "train loss:0.004129315930887953\n",
      "train loss:0.001861230906241296\n",
      "train loss:0.010443279374308636\n",
      "train loss:0.01096876562599267\n",
      "train loss:0.01754012335422648\n",
      "train loss:0.004187703942696792\n",
      "train loss:0.010615941681604577\n",
      "train loss:0.06933415853753129\n",
      "train loss:0.0026748034248288964\n",
      "train loss:0.007652792036426694\n",
      "train loss:0.0026401997887723467\n",
      "train loss:0.0005815547473942139\n",
      "train loss:0.0008290509334901398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0038317682672343984\n",
      "train loss:0.01077192564431878\n",
      "train loss:0.002516944759758858\n",
      "train loss:0.009762113474384817\n",
      "train loss:0.0010601829491487854\n",
      "train loss:0.0011429959293969684\n",
      "train loss:0.0018450627351404708\n",
      "train loss:0.005364824398488466\n",
      "train loss:0.004642203916129792\n",
      "train loss:0.008608794501537745\n",
      "train loss:0.0008075887152736577\n",
      "train loss:0.0037048392113981305\n",
      "train loss:0.017440211768476675\n",
      "train loss:0.019120281627809457\n",
      "train loss:0.00816463689614169\n",
      "train loss:0.00031470210623464834\n",
      "train loss:0.0007624703345803205\n",
      "train loss:0.0032376295500297424\n",
      "train loss:0.034021645101039326\n",
      "train loss:0.003096194776597741\n",
      "train loss:0.0019210283338265302\n",
      "train loss:0.00046103348707962665\n",
      "train loss:0.0004835694078636285\n",
      "train loss:0.008537212598890214\n",
      "train loss:0.0018706774125892835\n",
      "train loss:0.0009669842761889424\n",
      "train loss:0.004919525438211677\n",
      "train loss:0.0005756021950384619\n",
      "train loss:0.0022747761091407494\n",
      "train loss:0.0011700310424849715\n",
      "train loss:0.0037189772167877367\n",
      "train loss:0.005569211172578972\n",
      "train loss:0.0022429641356270956\n",
      "train loss:0.0027781295695598705\n",
      "train loss:0.01047801740653125\n",
      "train loss:0.011746065537455464\n",
      "train loss:0.009751106863162294\n",
      "train loss:0.02009260227359937\n",
      "train loss:0.0004710527028270078\n",
      "train loss:0.0031653466095720763\n",
      "train loss:0.000773573526102352\n",
      "train loss:0.0013411304341472332\n",
      "train loss:0.0016954870321148102\n",
      "train loss:0.0028271408525640525\n",
      "train loss:0.0013104542079345261\n",
      "train loss:0.005213907341187884\n",
      "train loss:0.0028028527449838587\n",
      "train loss:0.002457471174088028\n",
      "train loss:0.001017127258310715\n",
      "train loss:0.004342607022994365\n",
      "train loss:0.0013692148711407404\n",
      "train loss:0.002577888374187428\n",
      "train loss:0.00045766503522474646\n",
      "train loss:0.00103355688326047\n",
      "train loss:0.006114357531739216\n",
      "train loss:0.0033704672186335425\n",
      "train loss:0.00042002938281228137\n",
      "train loss:0.0013406031610203122\n",
      "train loss:0.0030538461219798024\n",
      "train loss:0.0004789088640321121\n",
      "train loss:0.002062124961083992\n",
      "train loss:0.0017165300783157705\n",
      "train loss:0.002678663917190762\n",
      "train loss:0.0035059908895420855\n",
      "train loss:0.0026097118309339634\n",
      "train loss:0.0006036270998631167\n",
      "train loss:0.008613004204942355\n",
      "train loss:0.009797833107128144\n",
      "train loss:0.0015803147358930602\n",
      "train loss:0.0012147482528205317\n",
      "train loss:0.002138576464121969\n",
      "train loss:0.0012303013517099234\n",
      "train loss:0.0015575850783882527\n",
      "train loss:0.0024889569878598\n",
      "train loss:0.007111727105754092\n",
      "train loss:0.003339243638787346\n",
      "train loss:0.0009123445912897081\n",
      "train loss:0.000780164141089642\n",
      "train loss:0.0049284564365783086\n",
      "train loss:0.0011721606298602247\n",
      "train loss:0.006934436881094347\n",
      "train loss:0.002140969626500524\n",
      "train loss:0.002908025598943643\n",
      "train loss:0.002982017732011595\n",
      "train loss:0.000710471770401477\n",
      "train loss:0.0018820614763016205\n",
      "train loss:0.001198096870569592\n",
      "train loss:0.015514420895976098\n",
      "train loss:0.006570788651984813\n",
      "train loss:0.0017438037400242738\n",
      "train loss:0.005988031355005231\n",
      "train loss:0.00030430564773671316\n",
      "train loss:0.002669692393823299\n",
      "train loss:0.012869248190384937\n",
      "train loss:0.00683883695065039\n",
      "train loss:0.005493283293825175\n",
      "train loss:0.005762141777581205\n",
      "train loss:0.004255073996041908\n",
      "train loss:0.003024263946862138\n",
      "train loss:0.022875258348481132\n",
      "train loss:0.0020395995805444146\n",
      "train loss:0.005408069362778695\n",
      "train loss:0.00048243262644061675\n",
      "train loss:0.0014340619541700916\n",
      "train loss:0.005680305396525699\n",
      "train loss:0.0005839780934411508\n",
      "train loss:0.0007822542317459222\n",
      "train loss:0.005690684583978181\n",
      "train loss:0.006264195507773112\n",
      "train loss:0.006449822177526991\n",
      "train loss:0.0032590776053540394\n",
      "train loss:0.002724000419747668\n",
      "train loss:0.00012160687591138357\n",
      "train loss:0.007130867037588236\n",
      "train loss:0.0018391809991942698\n",
      "train loss:0.0033546896232704852\n",
      "train loss:0.0007512489172161182\n",
      "train loss:0.0028598218451828055\n",
      "train loss:0.0014029402134845591\n",
      "train loss:0.012729283851718391\n",
      "train loss:0.0047303068885552225\n",
      "train loss:0.0002893678363950047\n",
      "train loss:0.005333747722148126\n",
      "train loss:0.002549762508401741\n",
      "train loss:0.0038735173355533216\n",
      "train loss:0.006169491885995666\n",
      "train loss:0.0019601388222345475\n",
      "train loss:0.00437336012009683\n",
      "train loss:0.0035110309538544065\n",
      "train loss:0.0015848310866243027\n",
      "train loss:0.0004930136408607626\n",
      "train loss:0.0032056328087484366\n",
      "train loss:0.00058677860081952\n",
      "train loss:0.0024865100708028284\n",
      "train loss:0.0028198047112033193\n",
      "train loss:0.0008670130982896271\n",
      "train loss:0.0009731777044914465\n",
      "train loss:0.006054872995560286\n",
      "train loss:0.0011850027435434058\n",
      "train loss:0.0015195842150295766\n",
      "train loss:0.0004786170659978403\n",
      "train loss:0.0035383596164362775\n",
      "train loss:0.019722997000850187\n",
      "train loss:0.0028397702848312625\n",
      "train loss:0.0034374296821229836\n",
      "train loss:0.0008119100629842067\n",
      "train loss:0.002603953947013562\n",
      "train loss:0.0014704738115606498\n",
      "train loss:0.005098053769292058\n",
      "train loss:0.0011945064848569741\n",
      "train loss:0.005130280919581887\n",
      "train loss:0.0009049154831858304\n",
      "train loss:0.0003323702347797002\n",
      "train loss:0.0019652137895768544\n",
      "train loss:0.002159218015618183\n",
      "train loss:0.0014242463430642028\n",
      "train loss:0.0004947698923136909\n",
      "train loss:0.002386025334299536\n",
      "train loss:0.0025211767653283007\n",
      "train loss:0.00020218753712169239\n",
      "train loss:0.04314055194759571\n",
      "train loss:0.0220456735446639\n",
      "train loss:0.0012054525269154209\n",
      "train loss:0.020128076883181793\n",
      "train loss:0.0008285151659727502\n",
      "train loss:0.003038243932907618\n",
      "train loss:0.0006331670271356855\n",
      "train loss:0.0005745475417872619\n",
      "train loss:0.004410065354496062\n",
      "train loss:0.0029709755481053934\n",
      "train loss:0.0020104301452498405\n",
      "train loss:0.0009320142851540213\n",
      "train loss:0.0015430552811716398\n",
      "train loss:0.0031451245359085532\n",
      "train loss:0.002486964645791091\n",
      "train loss:0.0009145226649341195\n",
      "train loss:0.027025428553171853\n",
      "train loss:0.0016459607864274812\n",
      "train loss:0.0016335661338247093\n",
      "train loss:0.021066429220974667\n",
      "train loss:0.0012022159938375216\n",
      "train loss:0.0012773484129499021\n",
      "train loss:0.0009236649031719063\n",
      "train loss:0.0008836806440795744\n",
      "train loss:0.007248196658917995\n",
      "train loss:0.0042392046488374255\n",
      "train loss:0.003771898072155144\n",
      "train loss:0.005375162747628493\n",
      "train loss:0.003969192617763288\n",
      "train loss:0.0013685960448556267\n",
      "train loss:0.0026931647984442418\n",
      "train loss:0.010986206389345927\n",
      "train loss:0.0006230294898040895\n",
      "train loss:0.009724745903948001\n",
      "train loss:0.0017050056577678251\n",
      "train loss:0.0007514486019808754\n",
      "train loss:0.004193290896800504\n",
      "train loss:0.0026885528179422125\n",
      "train loss:0.001954888782308844\n",
      "train loss:0.005516208294258602\n",
      "train loss:0.0009003903304189292\n",
      "train loss:0.002626391220952913\n",
      "train loss:0.0006305882476662122\n",
      "train loss:0.006869533710099355\n",
      "train loss:0.0011848263192299762\n",
      "train loss:0.0005879179510780698\n",
      "train loss:0.0003380137933102415\n",
      "train loss:0.0007964659851685768\n",
      "train loss:0.00496132724543456\n",
      "train loss:0.0003841098686523192\n",
      "train loss:0.0006716190341246758\n",
      "train loss:0.002998174084358969\n",
      "train loss:0.0029371954590204125\n",
      "train loss:0.001725185080735601\n",
      "train loss:0.0010272004681477946\n",
      "train loss:0.0032266627719740866\n",
      "train loss:0.0007191232105112019\n",
      "train loss:0.002679722178482083\n",
      "train loss:0.0003126799074182746\n",
      "train loss:0.002035986597687952\n",
      "train loss:0.0029655004771950554\n",
      "train loss:0.009041621534875942\n",
      "train loss:0.0005376164292177868\n",
      "train loss:0.002206806429962001\n",
      "train loss:0.008866523055331999\n",
      "train loss:9.263141665913898e-05\n",
      "train loss:0.005749520523615033\n",
      "train loss:0.0002425675571495624\n",
      "train loss:0.002055595006215159\n",
      "train loss:0.005915185845792192\n",
      "train loss:0.005829724509345182\n",
      "train loss:0.0050638795232586945\n",
      "train loss:0.0024082757149110757\n",
      "train loss:0.005148483784419915\n",
      "train loss:0.003171408595463104\n",
      "train loss:0.002172361364586115\n",
      "train loss:0.0033122895370213358\n",
      "train loss:0.011667317190652027\n",
      "train loss:0.0007732074481998755\n",
      "train loss:0.0003435397507115504\n",
      "train loss:0.01673798481063358\n",
      "train loss:0.05480389724074683\n",
      "train loss:0.000831405359538441\n",
      "train loss:0.006525434387935342\n",
      "train loss:0.00788289538796249\n",
      "train loss:0.002124401501174063\n",
      "train loss:0.021224773754384533\n",
      "train loss:0.01234841197060071\n",
      "train loss:0.0004897382984404502\n",
      "train loss:0.09005661964607899\n",
      "train loss:0.004028493203878597\n",
      "train loss:0.005690743390623346\n",
      "train loss:0.004313105718629906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0016499642113661998\n",
      "train loss:0.002964537955401543\n",
      "train loss:0.002448668183048641\n",
      "train loss:0.003375411146177252\n",
      "train loss:0.007115096608198883\n",
      "train loss:0.0018110458371868587\n",
      "train loss:0.010075956279651476\n",
      "train loss:0.0002398384307253524\n",
      "train loss:0.01318818226947571\n",
      "train loss:0.001051439617762644\n",
      "train loss:0.0053151399837373815\n",
      "train loss:0.00039749802287625057\n",
      "train loss:0.004606958182304005\n",
      "train loss:0.0065977023349170815\n",
      "train loss:0.0008625709198569596\n",
      "train loss:0.0030229794573789414\n",
      "train loss:0.0030228839707766987\n",
      "train loss:0.0017364234862137793\n",
      "train loss:0.002384835992162426\n",
      "train loss:0.00495595633089386\n",
      "train loss:0.0015158383696997804\n",
      "train loss:0.0009612015812360265\n",
      "train loss:0.002382585699036318\n",
      "train loss:0.014482701177721042\n",
      "train loss:0.0009531370668282559\n",
      "train loss:0.0010382863064269637\n",
      "train loss:0.0008093228069651201\n",
      "train loss:0.019890058235429366\n",
      "train loss:0.001739789088195082\n",
      "train loss:0.016180873380590547\n",
      "train loss:0.008297008784415137\n",
      "train loss:0.0006464305130618113\n",
      "train loss:0.01232002041393762\n",
      "train loss:0.0007754573937378005\n",
      "train loss:0.0062394281577445865\n",
      "train loss:0.0017547959997041749\n",
      "train loss:0.013376276737162567\n",
      "train loss:0.003806514811594856\n",
      "train loss:0.003896777364287296\n",
      "train loss:0.0010452028529845307\n",
      "train loss:0.0008944221212026609\n",
      "train loss:0.027725943217616324\n",
      "train loss:0.003853449571973119\n",
      "train loss:0.001557821318925177\n",
      "train loss:0.0014595036251748995\n",
      "train loss:0.0011561940028368934\n",
      "train loss:0.012238168033544963\n",
      "train loss:0.0014316894034238793\n",
      "train loss:0.0038499334590015016\n",
      "train loss:0.0014564942774603618\n",
      "train loss:0.0036178765291537567\n",
      "train loss:0.005583890484540278\n",
      "train loss:0.0014841750282987138\n",
      "train loss:0.0011758515209354756\n",
      "train loss:0.0006703582663845394\n",
      "train loss:0.004947784209442488\n",
      "train loss:0.00108870302682773\n",
      "train loss:0.002930160414186795\n",
      "train loss:0.009266456097700266\n",
      "train loss:0.011185743602565362\n",
      "train loss:0.0033967682215197475\n",
      "train loss:0.00032553316578662756\n",
      "train loss:0.0004100986843515043\n",
      "train loss:0.0006491323796103683\n",
      "train loss:0.0005861381892378433\n",
      "train loss:0.010003987146060902\n",
      "train loss:0.010645470668368186\n",
      "train loss:0.001561972985519597\n",
      "train loss:0.002287067057271336\n",
      "train loss:0.0024929212435335895\n",
      "train loss:0.0008931261169783829\n",
      "train loss:0.0016654981409816411\n",
      "train loss:0.0018114129405221984\n",
      "train loss:0.0008395149026956326\n",
      "train loss:0.0007593771703403019\n",
      "train loss:0.0009329073247869318\n",
      "train loss:0.01859116359251148\n",
      "train loss:0.0009429674098206599\n",
      "train loss:0.0034025033089177363\n",
      "train loss:0.001355109577871249\n",
      "train loss:0.0001428816931352325\n",
      "train loss:0.0014183516309041813\n",
      "train loss:0.0005388290841201939\n",
      "train loss:0.002665017300742548\n",
      "train loss:0.00815409900830611\n",
      "train loss:0.001336506605625843\n",
      "train loss:0.0046248828913289615\n",
      "train loss:0.0008074581882845565\n",
      "train loss:0.004569980826043401\n",
      "train loss:0.010042018452776436\n",
      "train loss:0.002060847500955889\n",
      "train loss:0.00038445454562833033\n",
      "train loss:0.0041636408567439645\n",
      "train loss:0.0026041461838734337\n",
      "train loss:0.0001442576650777998\n",
      "train loss:0.004606401869032061\n",
      "train loss:0.0029628485208249293\n",
      "train loss:0.0028543527074094462\n",
      "train loss:0.0003964800830980236\n",
      "train loss:0.0016376662897962472\n",
      "train loss:0.0016784733135706495\n",
      "train loss:0.002018961870389655\n",
      "train loss:0.0016905986580294115\n",
      "train loss:0.0020300324071059347\n",
      "train loss:0.0010175126956667973\n",
      "train loss:0.018285599888455822\n",
      "train loss:0.000452245392179376\n",
      "train loss:0.0004607531937222322\n",
      "train loss:0.00011197109574452195\n",
      "train loss:0.0018100970962565957\n",
      "train loss:0.00039767872103687875\n",
      "train loss:0.0016010538422014228\n",
      "train loss:0.0006649021986649983\n",
      "train loss:0.0043660151510805205\n",
      "train loss:0.001235149205434011\n",
      "train loss:0.003787709074017444\n",
      "train loss:0.000752930821036382\n",
      "train loss:0.0004409593641975476\n",
      "train loss:0.0008214787730530927\n",
      "train loss:0.0023449626990385162\n",
      "train loss:0.009704059883252266\n",
      "train loss:0.001240884889566203\n",
      "train loss:0.010187561569077302\n",
      "train loss:0.0018175302741249557\n",
      "train loss:0.003301899240738405\n",
      "train loss:4.5572735562142286e-05\n",
      "train loss:0.0012602126904085772\n",
      "train loss:0.002777937410122617\n",
      "train loss:0.00120337650930419\n",
      "train loss:0.006783804459567584\n",
      "train loss:0.00016246505369903695\n",
      "train loss:0.003805033393978794\n",
      "train loss:0.002635316601836252\n",
      "train loss:0.0014088536546243988\n",
      "train loss:0.0012014134207883561\n",
      "train loss:0.0009621145358028541\n",
      "train loss:0.0006006289811633517\n",
      "train loss:0.0016824587184141567\n",
      "train loss:0.0017680803223621355\n",
      "train loss:0.00366707842020285\n",
      "train loss:0.005308513434771829\n",
      "train loss:0.0009037402014165912\n",
      "train loss:0.008712869387045402\n",
      "train loss:0.0042594247230170025\n",
      "train loss:0.0040064502646063255\n",
      "train loss:0.0006809134657554447\n",
      "train loss:0.00169708538924227\n",
      "train loss:0.004665745817784479\n",
      "train loss:0.001349757980162631\n",
      "train loss:0.007158273385690151\n",
      "train loss:0.0009101831277984067\n",
      "train loss:0.008359619683213967\n",
      "train loss:0.0009416321486253545\n",
      "train loss:0.0007031223335981395\n",
      "train loss:0.03391505546865927\n",
      "train loss:0.003722151960222768\n",
      "train loss:0.003700369418980236\n",
      "train loss:0.004135670939231912\n",
      "train loss:0.003307287928348282\n",
      "train loss:0.0003014636464271301\n",
      "train loss:0.003943225379538467\n",
      "train loss:0.00047935665467955087\n",
      "train loss:0.009993158350848984\n",
      "train loss:0.00021098173498571414\n",
      "train loss:0.0005344284414416477\n",
      "train loss:0.0012765472434713614\n",
      "train loss:0.0005143998068918939\n",
      "train loss:0.027688207767764653\n",
      "train loss:0.007137053250590763\n",
      "train loss:0.0011270906865501532\n",
      "train loss:0.013380579996699431\n",
      "train loss:0.004297500704975794\n",
      "train loss:0.0017838535778185185\n",
      "train loss:0.004390293960838114\n",
      "train loss:0.0034348236698939134\n",
      "train loss:0.013216699906666527\n",
      "train loss:0.0004344355506092176\n",
      "train loss:0.00034250501905481144\n",
      "train loss:0.0015894070979602716\n",
      "train loss:0.010720333064327556\n",
      "train loss:0.0019931624158521996\n",
      "train loss:0.002740932206265359\n",
      "train loss:0.000249278677020906\n",
      "train loss:0.0035135582552331367\n",
      "train loss:0.021487836617534187\n",
      "train loss:0.0056229629398773726\n",
      "train loss:0.008567568709630914\n",
      "train loss:0.00026053541254315523\n",
      "train loss:0.0005118529019861163\n",
      "train loss:0.005018050904910885\n",
      "train loss:0.0013139522009468188\n",
      "train loss:0.004880775231845147\n",
      "train loss:0.0011774427882225997\n",
      "train loss:0.003603823164408546\n",
      "train loss:0.0019506296284395048\n",
      "train loss:0.0027136405617121605\n",
      "train loss:0.004607817428099253\n",
      "train loss:0.04219612545156395\n",
      "train loss:0.0011562151344242406\n",
      "train loss:0.0015695434320882268\n",
      "train loss:0.0003891962379085765\n",
      "train loss:0.0004216204372752598\n",
      "train loss:0.0007012159978453551\n",
      "train loss:0.00016004980095117086\n",
      "train loss:0.0003292366517950588\n",
      "train loss:0.004345830774885272\n",
      "train loss:0.004014815261642426\n",
      "train loss:0.000653888164970995\n",
      "train loss:0.0011036777378936919\n",
      "train loss:0.007588900792833581\n",
      "train loss:0.0007082022706343676\n",
      "train loss:0.001804735502099141\n",
      "train loss:0.0024309470522823253\n",
      "train loss:0.0006954293535341077\n",
      "train loss:0.0016956483897936745\n",
      "train loss:0.0013284723604777913\n",
      "train loss:0.004412059105171426\n",
      "train loss:0.0020058684356889047\n",
      "train loss:0.012087714215906407\n",
      "train loss:0.0027279036575435355\n",
      "train loss:0.0017562785416554933\n",
      "train loss:0.0001197625704706719\n",
      "train loss:0.004491697635179758\n",
      "train loss:0.00104576623701417\n",
      "train loss:0.0009849016196242242\n",
      "train loss:0.00995382174498041\n",
      "train loss:0.008995136945852099\n",
      "train loss:0.004435480609740727\n",
      "train loss:0.0002987054731482152\n",
      "train loss:0.0016722621442780631\n",
      "train loss:0.0004883088905147186\n",
      "train loss:0.0006214950054035285\n",
      "train loss:0.006272184795338312\n",
      "train loss:0.0003242861394246408\n",
      "train loss:0.0016139269738260178\n",
      "train loss:0.002431421292548386\n",
      "train loss:0.001997019227202385\n",
      "train loss:0.011791573703498244\n",
      "train loss:0.025880330683904454\n",
      "train loss:0.0021725839810860835\n",
      "train loss:0.0016247299098028863\n",
      "train loss:0.0020421343418603587\n",
      "train loss:0.00026015683392657726\n",
      "train loss:0.004094657439574482\n",
      "train loss:0.006030643830111355\n",
      "train loss:0.000754001447341702\n",
      "train loss:0.004769427413952246\n",
      "train loss:0.0028951129656350173\n",
      "train loss:0.0011463031467212335\n",
      "train loss:0.0006808816490780217\n",
      "train loss:0.0007668922301322949\n",
      "train loss:0.009673531375161824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:9.971703124109702e-05\n",
      "train loss:0.0049518546165546\n",
      "train loss:0.059409183112987624\n",
      "train loss:0.0012267505379749725\n",
      "train loss:0.0003515142857785422\n",
      "train loss:0.004608261642826081\n",
      "train loss:0.0024970412168779047\n",
      "train loss:0.05371498447144792\n",
      "train loss:0.01864144475384135\n",
      "train loss:0.0066573533111069704\n",
      "train loss:0.003007532278818412\n",
      "train loss:0.03173610641826884\n",
      "train loss:0.005121176563715438\n",
      "train loss:0.00036529354074189976\n",
      "train loss:0.0020987314158380723\n",
      "train loss:0.0017631396223423315\n",
      "train loss:0.05475729911036598\n",
      "train loss:0.002737726440875255\n",
      "train loss:0.0026048659293425327\n",
      "train loss:0.002460590450687308\n",
      "train loss:0.008005725239296366\n",
      "train loss:0.0048088966598333\n",
      "train loss:0.0010652677157889433\n",
      "train loss:0.007257397481310014\n",
      "train loss:0.007419083255547906\n",
      "train loss:0.0008522983375261221\n",
      "train loss:0.001587506590799274\n",
      "train loss:0.002982661833270053\n",
      "train loss:0.0013501666649184051\n",
      "train loss:0.0028044478759233537\n",
      "train loss:0.0007621949547713725\n",
      "train loss:0.0008505214934050081\n",
      "train loss:0.002733548915403474\n",
      "train loss:0.0034885634540048806\n",
      "train loss:0.002759878919246684\n",
      "train loss:0.0004931300918411321\n",
      "train loss:7.000390785484196e-05\n",
      "train loss:0.004922942688422182\n",
      "train loss:0.00475927024033086\n",
      "train loss:0.0018379962141594527\n",
      "train loss:0.0008422178851533571\n",
      "train loss:0.0011150547909825035\n",
      "train loss:0.00012306515279880448\n",
      "train loss:0.005360842114690552\n",
      "train loss:0.0002575322650149401\n",
      "train loss:0.002917061720287618\n",
      "train loss:0.003781336940645877\n",
      "train loss:0.0007443408185511993\n",
      "=== epoch:14, train acc:0.997, test acc:0.983 ===\n",
      "train loss:0.003465926210947829\n",
      "train loss:0.0010131960989664573\n",
      "train loss:0.0010110594581956456\n",
      "train loss:0.0004506380640164349\n",
      "train loss:0.0006300060523998863\n",
      "train loss:0.002168628471129728\n",
      "train loss:0.014334126837997452\n",
      "train loss:0.00032631145433587006\n",
      "train loss:0.00013119460994115035\n",
      "train loss:0.0017364230066477754\n",
      "train loss:0.0009115726979139962\n",
      "train loss:0.003997092368915615\n",
      "train loss:0.0028822088761880343\n",
      "train loss:0.0004493234985464302\n",
      "train loss:0.00034536754034545356\n",
      "train loss:0.002785814548562443\n",
      "train loss:0.0008319387574950057\n",
      "train loss:0.0005538527631512775\n",
      "train loss:0.00038853776439335395\n",
      "train loss:0.019779443118398254\n",
      "train loss:0.0002409125222735088\n",
      "train loss:0.003214246086815583\n",
      "train loss:0.0022271091429358313\n",
      "train loss:0.0019352678410028137\n",
      "train loss:0.0025126589145680355\n",
      "train loss:0.0014070438913093364\n",
      "train loss:0.000386422871089614\n",
      "train loss:0.004820587671794227\n",
      "train loss:0.009480637117875166\n",
      "train loss:0.0016737131920508677\n",
      "train loss:0.007622149152600616\n",
      "train loss:0.0012003987815558804\n",
      "train loss:0.003752237656312607\n",
      "train loss:0.0016819911419859244\n",
      "train loss:0.002028842585912133\n",
      "train loss:0.0003710521837862019\n",
      "train loss:0.023715500141704222\n",
      "train loss:0.01696220642017661\n",
      "train loss:0.008837970544000078\n",
      "train loss:0.000364341515681584\n",
      "train loss:0.0026801547992741986\n",
      "train loss:0.0013201839203826054\n",
      "train loss:0.007354132038267503\n",
      "train loss:0.0011345835186922788\n",
      "train loss:0.034537930965724085\n",
      "train loss:0.0036673816390028605\n",
      "train loss:0.0041713089249280555\n",
      "train loss:0.0022231851798048194\n",
      "train loss:0.00042381212550150196\n",
      "train loss:0.006813781835319238\n",
      "train loss:0.0024617759820891047\n",
      "train loss:0.000740971330544948\n",
      "train loss:0.003539026021883295\n",
      "train loss:0.00545773334171074\n",
      "train loss:0.002600534186408005\n",
      "train loss:0.009475183379455633\n",
      "train loss:0.0015290518929584396\n",
      "train loss:0.0004160306224038348\n",
      "train loss:0.011464901808116395\n",
      "train loss:0.006120810981777453\n",
      "train loss:0.0100126814541063\n",
      "train loss:0.003637405544247942\n",
      "train loss:0.0006469927392840506\n",
      "train loss:0.002717911222649739\n",
      "train loss:0.0010004720137830401\n",
      "train loss:0.0035369481052610246\n",
      "train loss:0.0036333195571450895\n",
      "train loss:0.0008995762449401642\n",
      "train loss:0.001937001111339724\n",
      "train loss:0.0005371045299609734\n",
      "train loss:0.002162689256788969\n",
      "train loss:0.006929269267535514\n",
      "train loss:0.0016629034363107292\n",
      "train loss:0.004649316560757314\n",
      "train loss:0.003154428387266646\n",
      "train loss:0.002229264515870189\n",
      "train loss:0.010856580234168342\n",
      "train loss:0.0018289041720315918\n",
      "train loss:0.001879766967709832\n",
      "train loss:0.00042385282168465343\n",
      "train loss:0.001186551052614311\n",
      "train loss:0.0032558499976706634\n",
      "train loss:0.0012212663395213192\n",
      "train loss:0.004161391077722596\n",
      "train loss:0.00029561729409972436\n",
      "train loss:0.00028717457347355506\n",
      "train loss:0.002306786132533395\n",
      "train loss:0.007636296214788841\n",
      "train loss:0.001980026344358983\n",
      "train loss:0.003037491315509181\n",
      "train loss:0.0022272182877363968\n",
      "train loss:0.004961026176698041\n",
      "train loss:0.003323783528660702\n",
      "train loss:0.003068174430727102\n",
      "train loss:0.005201596333468762\n",
      "train loss:0.006752810582183544\n",
      "train loss:0.0005129140787811161\n",
      "train loss:0.0010134112272829018\n",
      "train loss:0.011215480037024755\n",
      "train loss:0.00020310814585715472\n",
      "train loss:0.0024344816407763166\n",
      "train loss:0.016258982762767722\n",
      "train loss:0.00835044032796432\n",
      "train loss:0.003196620174868161\n",
      "train loss:0.0005902776110724964\n",
      "train loss:0.0005970253270078267\n",
      "train loss:0.0022832325717920174\n",
      "train loss:0.002723796242197395\n",
      "train loss:0.0012477371167974934\n",
      "train loss:0.021255822720171503\n",
      "train loss:0.0014525284794817462\n",
      "train loss:0.0014734804289834988\n",
      "train loss:0.0038652694839953054\n",
      "train loss:0.005370653231318559\n",
      "train loss:0.04444409969698301\n",
      "train loss:0.02845088804239289\n",
      "train loss:0.006917776319951318\n",
      "train loss:0.0063680540953998796\n",
      "train loss:0.0028114848384069207\n",
      "train loss:0.000818502001551028\n",
      "train loss:0.0004016151971756112\n",
      "train loss:0.010420344783283972\n",
      "train loss:0.010867685103952791\n",
      "train loss:0.0014763746612376746\n",
      "train loss:0.0035673611111877524\n",
      "train loss:0.0030127081536467015\n",
      "train loss:0.005908561804703323\n",
      "train loss:0.0021322911834180973\n",
      "train loss:0.0035960600715663456\n",
      "train loss:0.000911560433292711\n",
      "train loss:0.0011974965652353437\n",
      "train loss:0.006719179707258544\n",
      "train loss:0.02869264672738893\n",
      "train loss:0.0009162015198267237\n",
      "train loss:9.526413707115857e-05\n",
      "train loss:0.017979498964860164\n",
      "train loss:0.001974455588361956\n",
      "train loss:0.005950206246735122\n",
      "train loss:0.009595731481740437\n",
      "train loss:0.006424693914651113\n",
      "train loss:0.0037979823800908634\n",
      "train loss:0.005441399594359393\n",
      "train loss:0.005884350696756625\n",
      "train loss:0.0048734633921603465\n",
      "train loss:0.000577551403306746\n",
      "train loss:0.007338926271072955\n",
      "train loss:0.0011455807243896342\n",
      "train loss:0.0003964265002422416\n",
      "train loss:0.010552971557442465\n",
      "train loss:0.0034026868743296267\n",
      "train loss:0.00018301374691836382\n",
      "train loss:0.008354539014162497\n",
      "train loss:0.0006351021837430028\n",
      "train loss:0.0010830754887775022\n",
      "train loss:0.0006187056714321267\n",
      "train loss:0.0005301382335181104\n",
      "train loss:0.0054932224665239305\n",
      "train loss:0.012143609633213776\n",
      "train loss:0.01026213521591813\n",
      "train loss:0.0057403054434859505\n",
      "train loss:0.0014102868610373757\n",
      "train loss:0.0007918246341147656\n",
      "train loss:0.0010524075933419043\n",
      "train loss:0.012205025366824516\n",
      "train loss:0.01451500365761735\n",
      "train loss:0.0013867477249961957\n",
      "train loss:0.0009493299001766274\n",
      "train loss:0.0034136069890000277\n",
      "train loss:0.005338451273969187\n",
      "train loss:0.007202019027108374\n",
      "train loss:0.002440917455176372\n",
      "train loss:0.0015380074722570532\n",
      "train loss:0.0025348706730460584\n",
      "train loss:0.006240301442046209\n",
      "train loss:0.007760918389114808\n",
      "train loss:0.005146365094517218\n",
      "train loss:0.004021252827131232\n",
      "train loss:0.006697805796891875\n",
      "train loss:0.001105398693889844\n",
      "train loss:0.014883164952761428\n",
      "train loss:0.00056204548802655\n",
      "train loss:6.608037291240882e-05\n",
      "train loss:0.003942405299083145\n",
      "train loss:0.006694950497083377\n",
      "train loss:0.007160107985126697\n",
      "train loss:0.0004470405011713991\n",
      "train loss:0.0012687766483798944\n",
      "train loss:0.04208011977761724\n",
      "train loss:0.004157427508108181\n",
      "train loss:0.0002637506487557083\n",
      "train loss:0.0028240683973334633\n",
      "train loss:0.005771876831973725\n",
      "train loss:0.0013866974670959055\n",
      "train loss:0.001320625910421265\n",
      "train loss:0.009737677412804768\n",
      "train loss:0.0002628468900429797\n",
      "train loss:0.0016385056126716163\n",
      "train loss:0.0005279426345607543\n",
      "train loss:0.001224963096800859\n",
      "train loss:0.0004238926421261198\n",
      "train loss:0.00015716175288539992\n",
      "train loss:0.0002641730537435371\n",
      "train loss:0.014316278612130135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006917286972536121\n",
      "train loss:0.0035322201720765557\n",
      "train loss:0.002269001744221183\n",
      "train loss:0.0034553502813134004\n",
      "train loss:0.0006382088719557899\n",
      "train loss:0.001105517186642357\n",
      "train loss:0.007493758418083456\n",
      "train loss:0.000475242003572498\n",
      "train loss:0.0009221760468490575\n",
      "train loss:0.0024770923988222918\n",
      "train loss:0.0008736603177797378\n",
      "train loss:0.0033943659912120073\n",
      "train loss:0.005588445277987169\n",
      "train loss:0.0009264141202523517\n",
      "train loss:0.003143523547594454\n",
      "train loss:0.0009147743950358381\n",
      "train loss:0.0029951137465189944\n",
      "train loss:0.0009897314100091336\n",
      "train loss:0.005533455716735679\n",
      "train loss:0.011427433033847783\n",
      "train loss:0.009155289803695475\n",
      "train loss:0.01027142385716487\n",
      "train loss:0.008759153158148968\n",
      "train loss:0.002349051594265198\n",
      "train loss:0.0067215570015580215\n",
      "train loss:0.00016797465591794159\n",
      "train loss:0.008166007083785927\n",
      "train loss:0.004481793901599195\n",
      "train loss:0.0010216426922707111\n",
      "train loss:0.0010102812024460719\n",
      "train loss:0.002350708864926849\n",
      "train loss:0.003764812667493182\n",
      "train loss:0.011071957288210078\n",
      "train loss:0.005168769505847626\n",
      "train loss:0.017625253416031047\n",
      "train loss:0.006806781888812532\n",
      "train loss:0.0159228390214637\n",
      "train loss:0.00044254432130884635\n",
      "train loss:0.007999476359095143\n",
      "train loss:0.0028028450560347697\n",
      "train loss:0.005820143594065891\n",
      "train loss:0.00023464258120526433\n",
      "train loss:0.0027832149716459607\n",
      "train loss:0.002627491074315505\n",
      "train loss:0.011788991932475795\n",
      "train loss:0.0025737566873446594\n",
      "train loss:0.0016484722316595726\n",
      "train loss:0.000794941145533455\n",
      "train loss:0.0003166653482666897\n",
      "train loss:0.004228781053620132\n",
      "train loss:0.001446962324438842\n",
      "train loss:0.00041931884911747486\n",
      "train loss:0.0035789679383522958\n",
      "train loss:0.00899290798494564\n",
      "train loss:0.004062123069067202\n",
      "train loss:0.008050643686566973\n",
      "train loss:0.01726729521130623\n",
      "train loss:0.00014003536254061837\n",
      "train loss:0.03478882964863563\n",
      "train loss:0.0032257270073213274\n",
      "train loss:0.00930525831769642\n",
      "train loss:0.0015736580294137476\n",
      "train loss:0.001284223817083199\n",
      "train loss:0.0007053261426631237\n",
      "train loss:0.0016354267353437554\n",
      "train loss:0.0007460412280847707\n",
      "train loss:0.002347458509809656\n",
      "train loss:0.0011706896263657127\n",
      "train loss:0.0018877834527027096\n",
      "train loss:0.0005441021063158924\n",
      "train loss:0.005142130903851055\n",
      "train loss:0.0010142732873538796\n",
      "train loss:0.00230177348622807\n",
      "train loss:0.005528697831793805\n",
      "train loss:0.009455173194177652\n",
      "train loss:0.005041973991326384\n",
      "train loss:0.00013051962256775196\n",
      "train loss:0.0043748188301266965\n",
      "train loss:0.0005906652142570374\n",
      "train loss:0.027385843440028892\n",
      "train loss:0.004112341947191628\n",
      "train loss:0.0038239660752268836\n",
      "train loss:0.013468621591782312\n",
      "train loss:0.006111389076279717\n",
      "train loss:0.007400997623397961\n",
      "train loss:0.00414587982370947\n",
      "train loss:0.002133226733079393\n",
      "train loss:0.003331610752765099\n",
      "train loss:0.00019508565199279938\n",
      "train loss:0.0006316295311131981\n",
      "train loss:0.0036250484967938917\n",
      "train loss:0.0019916564403091902\n",
      "train loss:0.0005642300611252405\n",
      "train loss:0.0021758520208699865\n",
      "train loss:0.0011220541452360584\n",
      "train loss:0.0022687305312014843\n",
      "train loss:0.001135068930487003\n",
      "train loss:0.006072029197225227\n",
      "train loss:0.0006817249554553771\n",
      "train loss:0.008509139173950846\n",
      "train loss:0.005031405067297909\n",
      "train loss:0.0020078819713096755\n",
      "train loss:0.00036917047409319454\n",
      "train loss:0.0017779015635946325\n",
      "train loss:0.003958047377535765\n",
      "train loss:0.0007824430957493072\n",
      "train loss:0.0013354311137926873\n",
      "train loss:0.0005139060374940347\n",
      "train loss:0.0012178078950110518\n",
      "train loss:0.003681361774436244\n",
      "train loss:0.0004114602897018446\n",
      "train loss:0.006914285866168756\n",
      "train loss:0.0028895939710813323\n",
      "train loss:0.002490814586875235\n",
      "train loss:0.0015258463493857065\n",
      "train loss:0.004622302346358766\n",
      "train loss:0.008416171292267991\n",
      "train loss:0.0019396077034534178\n",
      "train loss:0.006829588184060006\n",
      "train loss:0.003237929768679967\n",
      "train loss:0.012630489468885389\n",
      "train loss:0.0004643305343857033\n",
      "train loss:0.0003815517402982541\n",
      "train loss:0.0003298763367930714\n",
      "train loss:0.011708442095421611\n",
      "train loss:0.0040483471102276585\n",
      "train loss:0.0076444694883008235\n",
      "train loss:0.002910498218588911\n",
      "train loss:0.0017721685210482579\n",
      "train loss:0.0028354366361133154\n",
      "train loss:0.011095335038665619\n",
      "train loss:0.002757154416649465\n",
      "train loss:0.004558090332816024\n",
      "train loss:0.0005435904686255851\n",
      "train loss:0.00704816483790846\n",
      "train loss:0.0009486578509135241\n",
      "train loss:0.0011785339834139545\n",
      "train loss:0.005098925706299823\n",
      "train loss:0.0006484588875544412\n",
      "train loss:0.0020529858342890465\n",
      "train loss:0.0015706866394565935\n",
      "train loss:0.0007494123752664454\n",
      "train loss:0.0006881850295734955\n",
      "train loss:0.0004894331075810822\n",
      "train loss:0.0033141883582470644\n",
      "train loss:0.004696204008914165\n",
      "train loss:0.0036447402064994057\n",
      "train loss:0.0013660205844725952\n",
      "train loss:0.0006615651013210376\n",
      "train loss:0.0013337368160347253\n",
      "train loss:0.0010404270299071113\n",
      "train loss:0.0004344381947289213\n",
      "train loss:0.006857505523171752\n",
      "train loss:0.0024951999938828172\n",
      "train loss:0.0003379117779817031\n",
      "train loss:0.005898644250412308\n",
      "train loss:0.0007730427728746169\n",
      "train loss:0.0036609623047586166\n",
      "train loss:0.0010070100581945874\n",
      "train loss:0.013926215131303033\n",
      "train loss:0.00035108672026069605\n",
      "train loss:0.004658424751541339\n",
      "train loss:0.0038170809200713807\n",
      "train loss:0.0014470138972113352\n",
      "train loss:0.002123632608207616\n",
      "train loss:0.0030296960043173053\n",
      "train loss:0.001092962092817642\n",
      "train loss:0.004711358824519471\n",
      "train loss:0.00018601113909135793\n",
      "train loss:0.00018301807273764475\n",
      "train loss:0.003730074423792656\n",
      "train loss:0.0022010096440570944\n",
      "train loss:0.0034233276114376834\n",
      "train loss:0.001719659289873811\n",
      "train loss:0.07724731002685567\n",
      "train loss:0.0005161363475883501\n",
      "train loss:0.0003687553845867942\n",
      "train loss:0.0034214843614005096\n",
      "train loss:0.003144506270586453\n",
      "train loss:0.009407088971076082\n",
      "train loss:0.0005188325386453714\n",
      "train loss:0.004286695394049436\n",
      "train loss:0.014459820637788811\n",
      "train loss:0.0063800518881067\n",
      "train loss:0.0002451488328263179\n",
      "train loss:0.005910432471413111\n",
      "train loss:0.0047925560931545595\n",
      "train loss:0.00026807631270097694\n",
      "train loss:0.0007956846396961839\n",
      "train loss:0.0030175834480897197\n",
      "train loss:0.0017065109209132706\n",
      "train loss:0.003773347078415631\n",
      "train loss:0.0007170348551423007\n",
      "train loss:0.002806826357269427\n",
      "train loss:0.0011669363643271634\n",
      "train loss:0.002859621766353843\n",
      "train loss:0.002153008452978523\n",
      "train loss:0.000573799075364226\n",
      "train loss:0.00025448678246282343\n",
      "train loss:0.0005550987245422256\n",
      "train loss:0.004170533070907445\n",
      "train loss:0.001954575246373174\n",
      "train loss:0.0004755130859647899\n",
      "train loss:0.0041588020280381765\n",
      "train loss:0.00343328574913303\n",
      "train loss:0.002941446792497005\n",
      "train loss:0.00023608742268160755\n",
      "train loss:0.0031470419541384737\n",
      "train loss:0.00020379546246816714\n",
      "train loss:9.625796262260426e-05\n",
      "train loss:0.0019439251530565852\n",
      "train loss:0.00516881701148012\n",
      "train loss:0.001373947130456367\n",
      "train loss:0.005429101492662574\n",
      "train loss:0.0017768113825009204\n",
      "train loss:0.03754749879988853\n",
      "train loss:0.004041335859936938\n",
      "train loss:0.006007380495437937\n",
      "train loss:0.0027575807149642696\n",
      "train loss:0.00277171462879779\n",
      "train loss:0.0020622216798615364\n",
      "train loss:0.0016095143622806907\n",
      "train loss:0.0014856186911067048\n",
      "train loss:0.0004528892568619293\n",
      "train loss:0.00018286678514561428\n",
      "train loss:0.002312111066991907\n",
      "train loss:0.002862305751773421\n",
      "train loss:0.003119730960797294\n",
      "train loss:0.007274766598913039\n",
      "train loss:0.0039817647453250825\n",
      "train loss:0.006075805984845299\n",
      "train loss:0.002010021048456536\n",
      "train loss:0.0017808679903224582\n",
      "train loss:0.0007502245457102033\n",
      "train loss:0.006593189789233217\n",
      "train loss:0.0003929204668718941\n",
      "train loss:0.007383540698410418\n",
      "train loss:0.0002815070678104208\n",
      "train loss:0.0009940030822151863\n",
      "train loss:0.0022441238630710025\n",
      "train loss:0.00859470353094364\n",
      "train loss:0.002398434068128969\n",
      "train loss:0.00037380725965187697\n",
      "train loss:0.0008456471943687184\n",
      "train loss:0.003412689042222322\n",
      "train loss:0.0016937030659781816\n",
      "train loss:0.0003753889546739931\n",
      "train loss:0.017032193552172552\n",
      "train loss:0.003644437333452623\n",
      "train loss:0.004949898592288904\n",
      "train loss:0.0030579385747661796\n",
      "train loss:0.007814905873871065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001200766705437224\n",
      "train loss:0.005546995834956369\n",
      "train loss:0.0023094022121648208\n",
      "train loss:0.004086544536547458\n",
      "train loss:0.0025090828360932516\n",
      "train loss:0.0019568598933966813\n",
      "train loss:0.004318550406923424\n",
      "train loss:0.03146029119130518\n",
      "train loss:0.0007726979433255918\n",
      "train loss:0.009563246441634705\n",
      "train loss:0.01054836254491422\n",
      "train loss:0.010480381613294652\n",
      "train loss:0.003307207212300805\n",
      "train loss:0.005341125320149212\n",
      "train loss:0.0015543725327311396\n",
      "train loss:0.007109472665027046\n",
      "train loss:0.02867829992454316\n",
      "train loss:0.010799009035307595\n",
      "train loss:0.0027079243962032334\n",
      "train loss:0.0012278069251214735\n",
      "train loss:0.0010740744964884688\n",
      "train loss:0.0025703207755071785\n",
      "train loss:0.0015331762037053128\n",
      "train loss:0.0014926371199447492\n",
      "train loss:0.00026394420164287927\n",
      "train loss:0.0026147635368931094\n",
      "train loss:0.00026793239209622086\n",
      "train loss:0.0008622978983813392\n",
      "train loss:0.0006355513738663901\n",
      "train loss:0.004676665503081397\n",
      "train loss:0.00475702545063737\n",
      "train loss:0.006620312741024855\n",
      "train loss:0.0005521001180157005\n",
      "train loss:0.0009157703924673993\n",
      "train loss:0.005073719257309071\n",
      "train loss:0.008512161817707416\n",
      "train loss:0.003575765126826603\n",
      "train loss:0.0022839111747112346\n",
      "train loss:0.001853724393822435\n",
      "train loss:0.000937342525735005\n",
      "train loss:0.0001837434351053411\n",
      "train loss:0.002577978495505909\n",
      "train loss:0.007928769685724304\n",
      "train loss:0.004458760170680139\n",
      "train loss:0.0050109378977545\n",
      "train loss:0.013795062298587632\n",
      "train loss:0.00011410098907383185\n",
      "train loss:0.0009124872257714973\n",
      "train loss:0.00885905266183226\n",
      "train loss:6.67588401019851e-05\n",
      "train loss:0.00480519799636739\n",
      "train loss:0.000666972906843082\n",
      "train loss:0.0004548814171216244\n",
      "train loss:0.030314828491509647\n",
      "train loss:0.004332966425684443\n",
      "train loss:0.0035264418615765414\n",
      "train loss:0.002408597732237955\n",
      "train loss:0.0007310445194707876\n",
      "train loss:0.001323560017483388\n",
      "train loss:0.0007328754640028059\n",
      "train loss:0.0024339134922869497\n",
      "train loss:0.0007027917831143181\n",
      "train loss:0.0026124692288698585\n",
      "train loss:0.0008173815911662645\n",
      "train loss:0.005294162436659051\n",
      "train loss:0.0029160749174772594\n",
      "train loss:0.0033695622153755616\n",
      "train loss:0.002939574685372983\n",
      "train loss:0.0012882565671804007\n",
      "train loss:0.0019141320981945625\n",
      "train loss:0.00016104538274568732\n",
      "train loss:0.00084193097908101\n",
      "train loss:0.00024051099364981964\n",
      "train loss:0.006902949999994177\n",
      "train loss:0.010472287106667819\n",
      "train loss:0.007092772014655832\n",
      "train loss:0.0008880879072995526\n",
      "train loss:0.0019117329032182515\n",
      "train loss:0.001483017059440565\n",
      "train loss:0.0013823252685821272\n",
      "train loss:0.004753852833223417\n",
      "train loss:0.0022581490598922115\n",
      "train loss:0.0029089155697282552\n",
      "train loss:6.440446345010578e-05\n",
      "train loss:0.002076801329421843\n",
      "train loss:0.0010170313986011706\n",
      "train loss:0.0023715725380277497\n",
      "train loss:0.00339497842770103\n",
      "train loss:0.002517559737760554\n",
      "train loss:0.00019853682441653832\n",
      "train loss:0.0008032197999329946\n",
      "train loss:0.0075989954137732465\n",
      "train loss:0.00018260990540955397\n",
      "train loss:0.002676383970749798\n",
      "train loss:0.0002989100372785398\n",
      "train loss:0.004195108011548645\n",
      "train loss:0.0011592875405885602\n",
      "train loss:0.011565952450478558\n",
      "train loss:0.0017503416857047145\n",
      "train loss:0.010002404488813243\n",
      "train loss:0.005524265884895872\n",
      "train loss:0.00584031418552463\n",
      "train loss:0.016309435483028583\n",
      "train loss:0.0022010399407666505\n",
      "train loss:0.0007234971616264285\n",
      "train loss:0.001549878556483555\n",
      "train loss:0.006361367521642863\n",
      "train loss:0.0023542849929766877\n",
      "train loss:0.003333209269388134\n",
      "train loss:0.0006006253630347131\n",
      "train loss:0.0033709808090965376\n",
      "train loss:0.04174810262818036\n",
      "train loss:0.023694079403318094\n",
      "train loss:0.0077790448743013055\n",
      "train loss:0.004720544003639766\n",
      "train loss:0.0006060182348609677\n",
      "train loss:0.00042876033659582265\n",
      "train loss:0.0011065053467276833\n",
      "train loss:0.0024198707078009066\n",
      "train loss:0.002209229213883027\n",
      "train loss:0.0013457633042832384\n",
      "train loss:0.0010047032012840548\n",
      "train loss:0.010835910984197677\n",
      "train loss:0.0008650977291711637\n",
      "train loss:0.004688432150009894\n",
      "train loss:0.014061341093741065\n",
      "train loss:0.0023856031965320246\n",
      "train loss:0.0015569232281555795\n",
      "train loss:0.025386920578074155\n",
      "train loss:0.001133025088921098\n",
      "train loss:0.0019441351633662167\n",
      "train loss:0.0008568463780804351\n",
      "train loss:0.00944745219440746\n",
      "train loss:0.0016948071960587534\n",
      "train loss:0.0014126743289933602\n",
      "train loss:0.0033655868855711544\n",
      "train loss:0.0011234323243635108\n",
      "train loss:0.002173065128910575\n",
      "train loss:0.0006601617493166917\n",
      "train loss:0.05515542765046156\n",
      "train loss:0.0019641043442899277\n",
      "train loss:0.027152729643112834\n",
      "train loss:0.0018842150505947604\n",
      "train loss:0.0005563095994555355\n",
      "train loss:0.007316733213750373\n",
      "=== epoch:15, train acc:0.997, test acc:0.985 ===\n",
      "train loss:0.00039992343755948317\n",
      "train loss:0.0006594540296445003\n",
      "train loss:0.005371204489528855\n",
      "train loss:0.004621263371593008\n",
      "train loss:0.0004799188435397869\n",
      "train loss:0.002734147118317043\n",
      "train loss:0.0004430141074202532\n",
      "train loss:0.0008190436221851582\n",
      "train loss:0.0008153746977086534\n",
      "train loss:0.01961995170515471\n",
      "train loss:0.0341165231262981\n",
      "train loss:0.0010422647066639108\n",
      "train loss:0.007216567143099917\n",
      "train loss:0.001330582002761902\n",
      "train loss:0.00013607327264505165\n",
      "train loss:0.004370228161618894\n",
      "train loss:0.008121527432922875\n",
      "train loss:0.008234800108455924\n",
      "train loss:0.0016266789416691735\n",
      "train loss:0.0002636771855124458\n",
      "train loss:0.0011596412725757418\n",
      "train loss:0.0008120059274050507\n",
      "train loss:0.0039181763836540475\n",
      "train loss:0.0037791231984048244\n",
      "train loss:0.0005468210016062009\n",
      "train loss:0.0006470338748775916\n",
      "train loss:0.0013503657541963086\n",
      "train loss:0.004719877097586255\n",
      "train loss:0.0019299452049057796\n",
      "train loss:0.00916546328582931\n",
      "train loss:0.0001526192064993782\n",
      "train loss:0.015998551644153234\n",
      "train loss:0.0001585637681215259\n",
      "train loss:0.002580378251365706\n",
      "train loss:0.001201256966418517\n",
      "train loss:0.007153155716146157\n",
      "train loss:3.528632831215288e-05\n",
      "train loss:0.0012003039512100471\n",
      "train loss:0.0014687290932753794\n",
      "train loss:0.0009187392860158046\n",
      "train loss:0.008505754623595482\n",
      "train loss:0.00021149773152097641\n",
      "train loss:0.01125140365524566\n",
      "train loss:0.002040158339904049\n",
      "train loss:0.0025876753934821906\n",
      "train loss:0.0004428029369957331\n",
      "train loss:0.000895537183174403\n",
      "train loss:0.0008675181139787007\n",
      "train loss:0.0001439830972222192\n",
      "train loss:0.00923033809000276\n",
      "train loss:0.0011180958310382837\n",
      "train loss:0.00039050486201825426\n",
      "train loss:0.002989666828415655\n",
      "train loss:0.010107801503420317\n",
      "train loss:0.0011200454830907485\n",
      "train loss:0.0040751588633264925\n",
      "train loss:0.001092550404608959\n",
      "train loss:0.006932012912551447\n",
      "train loss:0.0008664127933091903\n",
      "train loss:0.002501332759420391\n",
      "train loss:0.001065623830784506\n",
      "train loss:0.002018634307117212\n",
      "train loss:0.0016763561038122625\n",
      "train loss:0.0009615847710976595\n",
      "train loss:0.009951812684589284\n",
      "train loss:0.0018468413968581922\n",
      "train loss:0.003532909904511752\n",
      "train loss:0.0016702583215196562\n",
      "train loss:0.005721285566574522\n",
      "train loss:0.0022044923708924623\n",
      "train loss:0.0026643714464609936\n",
      "train loss:0.0064523593792178355\n",
      "train loss:0.0030173665563897837\n",
      "train loss:0.01150973538604879\n",
      "train loss:0.00017110991080973676\n",
      "train loss:0.001689974469126327\n",
      "train loss:0.002516247917439129\n",
      "train loss:0.0008653283712540538\n",
      "train loss:0.0015460366801318412\n",
      "train loss:0.003576696521579341\n",
      "train loss:0.004562100531292114\n",
      "train loss:0.0013247634753396525\n",
      "train loss:0.0023632457733232435\n",
      "train loss:0.0235022745274134\n",
      "train loss:0.005049492443403296\n",
      "train loss:0.0038230378518448855\n",
      "train loss:0.0077622193767532665\n",
      "train loss:0.006163241132665354\n",
      "train loss:0.014991715088455402\n",
      "train loss:0.002415525375681243\n",
      "train loss:0.0023923981384745565\n",
      "train loss:0.001265836675986272\n",
      "train loss:0.0007193356723502203\n",
      "train loss:0.016720291447508407\n",
      "train loss:0.0005728049680723362\n",
      "train loss:0.00213177956700661\n",
      "train loss:0.0007482539527732045\n",
      "train loss:0.0003715532050993414\n",
      "train loss:0.00048656331927041753\n",
      "train loss:0.005974939962822262\n",
      "train loss:0.00467075826614759\n",
      "train loss:0.001003166378533757\n",
      "train loss:0.006163135799367044\n",
      "train loss:0.0008090681992882774\n",
      "train loss:0.0023703827616312345\n",
      "train loss:0.0025799944378641594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.030129732885637427\n",
      "train loss:0.0014280159325378591\n",
      "train loss:0.001029165711434719\n",
      "train loss:0.004956771427134871\n",
      "train loss:0.006673888084600577\n",
      "train loss:0.0017523876643116294\n",
      "train loss:0.007683461253364981\n",
      "train loss:0.0010646311505277685\n",
      "train loss:0.001616952209685175\n",
      "train loss:0.0004511885295500964\n",
      "train loss:0.0011256866045488037\n",
      "train loss:0.0006021789100658015\n",
      "train loss:0.00046800870800717243\n",
      "train loss:0.004607641804141202\n",
      "train loss:0.0022635618481584015\n",
      "train loss:0.0118097992770529\n",
      "train loss:0.00012172198631922717\n",
      "train loss:0.0031241575161874524\n",
      "train loss:0.0003275017002654814\n",
      "train loss:0.007878301371180948\n",
      "train loss:0.0029223928824449723\n",
      "train loss:0.0017378011277635408\n",
      "train loss:0.0016906743026455855\n",
      "train loss:0.0023588180135411104\n",
      "train loss:0.0011399828321039655\n",
      "train loss:0.0003299069911435231\n",
      "train loss:0.0012245757846585047\n",
      "train loss:0.000454768350548073\n",
      "train loss:0.06806540781147925\n",
      "train loss:0.0018664877465262933\n",
      "train loss:0.0015512006552953054\n",
      "train loss:0.0033796996265730334\n",
      "train loss:0.0024240479275577913\n",
      "train loss:0.007278698350906292\n",
      "train loss:0.004926790415606587\n",
      "train loss:0.0007284523551106284\n",
      "train loss:0.009216903327310925\n",
      "train loss:0.00013022630473715093\n",
      "train loss:0.0007092299993041375\n",
      "train loss:0.0024552173652289625\n",
      "train loss:0.0026223183422587116\n",
      "train loss:0.0040546339110186375\n",
      "train loss:0.0015674819661127032\n",
      "train loss:0.00786266629039905\n",
      "train loss:0.0014587276919348698\n",
      "train loss:0.00778761585363072\n",
      "train loss:0.0017488212513412588\n",
      "train loss:0.0005176377957007258\n",
      "train loss:0.0021363747026945596\n",
      "train loss:0.000606452110778615\n",
      "train loss:0.0041682334649362504\n",
      "train loss:0.004035090825681436\n",
      "train loss:0.005136146474232312\n",
      "train loss:0.0006264345584698029\n",
      "train loss:0.0007316794624954874\n",
      "train loss:0.0010924210260876187\n",
      "train loss:0.0005267589106491003\n",
      "train loss:0.003722169774591803\n",
      "train loss:0.004292318523701153\n",
      "train loss:0.004405153910466835\n",
      "train loss:0.00029863129894765986\n",
      "train loss:0.0023906380910486942\n",
      "train loss:0.0013810419092139985\n",
      "train loss:0.0008851840182161712\n",
      "train loss:0.005232072688607024\n",
      "train loss:0.0024758073145263147\n",
      "train loss:0.0023834531869414695\n",
      "train loss:0.000531381988711186\n",
      "train loss:0.0006551370202915582\n",
      "train loss:0.03462450906307315\n",
      "train loss:0.0007797255849401359\n",
      "train loss:0.0023595964291870486\n",
      "train loss:0.0026142345669131167\n",
      "train loss:0.005774342968649604\n",
      "train loss:0.002788070988051648\n",
      "train loss:0.0014084547069245766\n",
      "train loss:0.002474772132201635\n",
      "train loss:0.004156579082028377\n",
      "train loss:0.000241127428512967\n",
      "train loss:0.004335711403440815\n",
      "train loss:0.0073223679259278515\n",
      "train loss:0.042343933945859814\n",
      "train loss:0.0006489646046785397\n",
      "train loss:0.00667918573222041\n",
      "train loss:0.0020754578202511515\n",
      "train loss:0.005696623024823089\n",
      "train loss:0.004547168610028824\n",
      "train loss:0.019759330958110697\n",
      "train loss:0.00030964442574046825\n",
      "train loss:0.010153728625767569\n",
      "train loss:0.0013490699775529772\n",
      "train loss:0.001640812994152718\n",
      "train loss:0.004121761637221302\n",
      "train loss:0.001171646808359033\n",
      "train loss:0.010088678630464958\n",
      "train loss:0.004319868336540484\n",
      "train loss:0.0013016075333929984\n",
      "train loss:0.0016386037693834638\n",
      "train loss:0.003105367477756846\n",
      "train loss:0.0014744383929348084\n",
      "train loss:0.0015449753997059208\n",
      "train loss:0.0008649380903432371\n",
      "train loss:0.0019668570474388842\n",
      "train loss:0.0017540032187561628\n",
      "train loss:0.0008305816987756264\n",
      "train loss:0.0007015397647445837\n",
      "train loss:0.0004743046539579528\n",
      "train loss:0.0002362278596633883\n",
      "train loss:0.000371738318976683\n",
      "train loss:0.004193133909152887\n",
      "train loss:0.0028040861563662606\n",
      "train loss:0.0037144214522003144\n",
      "train loss:0.0008526377391145979\n",
      "train loss:0.0020569378419370695\n",
      "train loss:0.0003750936527659179\n",
      "train loss:0.0010514388718107198\n",
      "train loss:0.00026392228877246903\n",
      "train loss:0.005422181560057069\n",
      "train loss:0.00027507969962310106\n",
      "train loss:0.002960363837469103\n",
      "train loss:0.0012488519054057443\n",
      "train loss:0.005343352033342339\n",
      "train loss:0.0006004144660609131\n",
      "train loss:0.0013497786638753484\n",
      "train loss:0.00036316186095615254\n",
      "train loss:0.0005920455934071427\n",
      "train loss:0.0014050288496506936\n",
      "train loss:0.00705989816940361\n",
      "train loss:0.0012506996095509352\n",
      "train loss:0.0034132822294397186\n",
      "train loss:0.002053872851119279\n",
      "train loss:0.0025221996986252533\n",
      "train loss:0.0034942402370286728\n",
      "train loss:0.00034729204143383696\n",
      "train loss:0.000430469305587425\n",
      "train loss:0.00040843638990650967\n",
      "train loss:0.0018438206846918665\n",
      "train loss:0.0007641708704659046\n",
      "train loss:0.007368930612086861\n",
      "train loss:0.00013312396955852382\n",
      "train loss:0.0007155991209257188\n",
      "train loss:0.0021691375495924647\n",
      "train loss:0.0021577315357569227\n",
      "train loss:0.007791338069072816\n",
      "train loss:0.0055343878551432635\n",
      "train loss:0.00032757131697110846\n",
      "train loss:0.0005092521542685734\n",
      "train loss:0.0026374480501294407\n",
      "train loss:0.0006776416978003022\n",
      "train loss:0.0005031118459472388\n",
      "train loss:0.00043275481453600655\n",
      "train loss:0.010349882331407165\n",
      "train loss:0.0008655818737143998\n",
      "train loss:0.001827715827373397\n",
      "train loss:0.000545654243540912\n",
      "train loss:0.0007301263687243437\n",
      "train loss:0.0030341888395633426\n",
      "train loss:0.003380522795307603\n",
      "train loss:0.002170937723001028\n",
      "train loss:0.00026692753972305133\n",
      "train loss:0.0008244470787544363\n",
      "train loss:0.0007980547212114807\n",
      "train loss:0.000509782419471409\n",
      "train loss:0.0008771307938615352\n",
      "train loss:0.00272993922438286\n",
      "train loss:0.0012480012820279788\n",
      "train loss:0.031108122571428653\n",
      "train loss:0.004159229433639293\n",
      "train loss:0.0049484109482677615\n",
      "train loss:0.007971896791318012\n",
      "train loss:0.0015331589420823002\n",
      "train loss:0.001598649156907438\n",
      "train loss:0.0010830812910980687\n",
      "train loss:0.002233870505794112\n",
      "train loss:0.0007296250516939088\n",
      "train loss:0.0015655400191773338\n",
      "train loss:0.0014471593546606576\n",
      "train loss:0.00170740832155055\n",
      "train loss:0.004667985443456468\n",
      "train loss:0.003342765641375315\n",
      "train loss:0.001264138449291724\n",
      "train loss:0.00070631977335016\n",
      "train loss:0.0012037533836823924\n",
      "train loss:0.007509771816185515\n",
      "train loss:0.00025755428040866336\n",
      "train loss:0.0022862059969872475\n",
      "train loss:0.0005330992589789975\n",
      "train loss:0.02126066129893169\n",
      "train loss:0.0007123060009306957\n",
      "train loss:0.0031143964473942655\n",
      "train loss:0.00015318118044663033\n",
      "train loss:0.007483005766464213\n",
      "train loss:0.0001429841068548955\n",
      "train loss:0.003105911389082094\n",
      "train loss:0.005935570916462999\n",
      "train loss:0.00083746561590103\n",
      "train loss:0.00025315799906344016\n",
      "train loss:0.00016730572647546886\n",
      "train loss:0.07721281875115092\n",
      "train loss:0.00018053900417137032\n",
      "train loss:0.001541665242734081\n",
      "train loss:0.001305813315486164\n",
      "train loss:0.0019470108666679298\n",
      "train loss:0.0004988984466925659\n",
      "train loss:0.0008495635230458522\n",
      "train loss:0.0031919007861099112\n",
      "train loss:0.007355593413842374\n",
      "train loss:0.0026950657909850266\n",
      "train loss:0.0024089864399703636\n",
      "train loss:0.001533483858677667\n",
      "train loss:0.0003573572735621964\n",
      "train loss:0.0007638731849290058\n",
      "train loss:0.0011601657028243735\n",
      "train loss:0.0008240690527356213\n",
      "train loss:0.00016395186959727718\n",
      "train loss:0.000258521214795342\n",
      "train loss:0.0006893992075490196\n",
      "train loss:0.0013226432652875205\n",
      "train loss:0.0013345219120916825\n",
      "train loss:0.0010281757109483404\n",
      "train loss:0.0026294770677212824\n",
      "train loss:0.0004304673814818819\n",
      "train loss:0.03385240440157313\n",
      "train loss:0.0021367410945646098\n",
      "train loss:0.003553033045504027\n",
      "train loss:0.005644467670163512\n",
      "train loss:0.0015786748157659114\n",
      "train loss:0.00018109141925774493\n",
      "train loss:0.003930544797202079\n",
      "train loss:0.001631259570392049\n",
      "train loss:0.0007077260086927342\n",
      "train loss:0.0012316015446618904\n",
      "train loss:0.0026010929765219017\n",
      "train loss:0.0004291346282097914\n",
      "train loss:0.008641812937340383\n",
      "train loss:0.004318896320646555\n",
      "train loss:0.0011615649640711193\n",
      "train loss:0.0010327768969827884\n",
      "train loss:0.00016685921092113198\n",
      "train loss:0.001645632621810686\n",
      "train loss:0.00016224753786949137\n",
      "train loss:0.003922391127691174\n",
      "train loss:0.002934367434287928\n",
      "train loss:0.00321185213375698\n",
      "train loss:0.0028511155428516993\n",
      "train loss:0.0008831852915431644\n",
      "train loss:0.0010297383025261624\n",
      "train loss:0.0008666636072252429\n",
      "train loss:0.0008687652429927739\n",
      "train loss:0.0028597401269659863\n",
      "train loss:0.0014011470235410501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0014859839471444104\n",
      "train loss:0.006720299296271005\n",
      "train loss:4.54171948559601e-05\n",
      "train loss:0.002669180257571182\n",
      "train loss:0.002742607242963791\n",
      "train loss:0.006573164913769373\n",
      "train loss:0.00022786937303113857\n",
      "train loss:0.0034071861979711243\n",
      "train loss:0.004165857838167764\n",
      "train loss:0.0006804721529626783\n",
      "train loss:0.0029609335568851463\n",
      "train loss:0.0010155445108412685\n",
      "train loss:0.011089948416122996\n",
      "train loss:0.0006324653309334652\n",
      "train loss:0.002642494853846615\n",
      "train loss:0.0008734625410800227\n",
      "train loss:0.00022692459041057672\n",
      "train loss:0.002431095121552432\n",
      "train loss:0.0060090732001618205\n",
      "train loss:0.0003565839175552373\n",
      "train loss:0.00292574218391877\n",
      "train loss:0.0009894001993639128\n",
      "train loss:0.0025720144846832767\n",
      "train loss:0.002416931607403217\n",
      "train loss:0.0024790999887140067\n",
      "train loss:0.00018886775340104192\n",
      "train loss:0.004060517298645742\n",
      "train loss:0.005304193596087525\n",
      "train loss:0.0011077306778968872\n",
      "train loss:0.003929953628280006\n",
      "train loss:0.0006328052362513997\n",
      "train loss:0.003895958374844478\n",
      "train loss:0.01177173055966015\n",
      "train loss:8.977901307953016e-05\n",
      "train loss:0.0015819203591217982\n",
      "train loss:0.0002419816469313076\n",
      "train loss:0.002494966159038642\n",
      "train loss:0.0004118553142683949\n",
      "train loss:0.0004675029283431782\n",
      "train loss:0.009438914915028311\n",
      "train loss:0.0038718461306778027\n",
      "train loss:0.003172090018668367\n",
      "train loss:0.004539582152238068\n",
      "train loss:0.004779846615097368\n",
      "train loss:0.001266987730278586\n",
      "train loss:0.005783348845359058\n",
      "train loss:0.0008806190647006631\n",
      "train loss:0.00045485362529747614\n",
      "train loss:0.00048157030533772495\n",
      "train loss:0.0007620369677547323\n",
      "train loss:0.0032797452476487203\n",
      "train loss:0.002055577014288562\n",
      "train loss:0.000182141764995809\n",
      "train loss:4.8694750295075674e-05\n",
      "train loss:0.0022133987767263604\n",
      "train loss:0.000962087277564728\n",
      "train loss:0.0029101351946817337\n",
      "train loss:0.0005562891067149798\n",
      "train loss:0.0011733722663014303\n",
      "train loss:0.004343185909014032\n",
      "train loss:0.0008403529034674032\n",
      "train loss:0.0012494192084477524\n",
      "train loss:0.0049462678620010945\n",
      "train loss:0.004768824061689872\n",
      "train loss:0.0016365569951570019\n",
      "train loss:0.004131169180895183\n",
      "train loss:0.00019495048085311318\n",
      "train loss:0.0010190265838266605\n",
      "train loss:0.0005905056034296014\n",
      "train loss:0.0030874753418687027\n",
      "train loss:0.0009037203362212559\n",
      "train loss:0.002363645339535245\n",
      "train loss:0.00027513433398861255\n",
      "train loss:0.0014155290211362486\n",
      "train loss:0.001506077648685142\n",
      "train loss:0.0024069343345289144\n",
      "train loss:0.004583595195048425\n",
      "train loss:0.000698840355327483\n",
      "train loss:0.0010230398309995635\n",
      "train loss:0.02154764397506199\n",
      "train loss:0.0005755611814438913\n",
      "train loss:0.0009776083694183844\n",
      "train loss:0.0001104715066393874\n",
      "train loss:0.003311993926002907\n",
      "train loss:0.0013182008425426028\n",
      "train loss:0.00044279010125449533\n",
      "train loss:0.005442113735259392\n",
      "train loss:0.007072669292166747\n",
      "train loss:0.00017334018195183223\n",
      "train loss:0.0021223233754672933\n",
      "train loss:0.0003998103342001207\n",
      "train loss:0.00034637639863947177\n",
      "train loss:0.002190103775291372\n",
      "train loss:0.0009719612607140924\n",
      "train loss:0.0006218586579053814\n",
      "train loss:0.0016407766584336462\n",
      "train loss:0.0007015388674962399\n",
      "train loss:0.0014299789456102615\n",
      "train loss:9.27475108142289e-05\n",
      "train loss:0.0011599122599224602\n",
      "train loss:0.0005163648261324194\n",
      "train loss:0.000329394950456682\n",
      "train loss:0.006214696702272756\n",
      "train loss:0.0020571817966618467\n",
      "train loss:0.008762590946919117\n",
      "train loss:8.018167853721324e-05\n",
      "train loss:0.00025724198774017845\n",
      "train loss:0.0003938078105740957\n",
      "train loss:0.00023011553994993245\n",
      "train loss:0.0011558261475493352\n",
      "train loss:0.00011047583294551718\n",
      "train loss:0.0029365380189028045\n",
      "train loss:0.00030705205863327926\n",
      "train loss:0.004011983313636214\n",
      "train loss:0.00014930065535396917\n",
      "train loss:0.0003190196803836575\n",
      "train loss:0.0001104743835112634\n",
      "train loss:0.0006077169704866035\n",
      "train loss:0.0010875785469228007\n",
      "train loss:0.0027714773003019934\n",
      "train loss:0.0005941348592534168\n",
      "train loss:0.002181766053663074\n",
      "train loss:0.0001964719198465525\n",
      "train loss:0.001038620512812517\n",
      "train loss:0.0010008665353981666\n",
      "train loss:0.001986540584787649\n",
      "train loss:0.0026659614476569993\n",
      "train loss:0.00045580157674667715\n",
      "train loss:0.0007376443216894871\n",
      "train loss:0.0015198251716038837\n",
      "train loss:0.0010020353390569068\n",
      "train loss:0.0019726621931385967\n",
      "train loss:0.0004948600910966139\n",
      "train loss:0.0039441125076969015\n",
      "train loss:0.00038480848395978424\n",
      "train loss:0.00022820602495268668\n",
      "train loss:8.461136995243824e-05\n",
      "train loss:0.0003654528232288846\n",
      "train loss:0.002074226028441269\n",
      "train loss:0.0015891482960007073\n",
      "train loss:0.0003145212378061605\n",
      "train loss:0.004158544506420902\n",
      "train loss:0.01167915953300675\n",
      "train loss:0.0070791682492728795\n",
      "train loss:0.0010786437982473701\n",
      "train loss:0.0001939579763671195\n",
      "train loss:0.00012862307534973363\n",
      "train loss:0.0007561551284856659\n",
      "train loss:0.017651938496205905\n",
      "train loss:0.0023776192718536256\n",
      "train loss:0.0028150445822164244\n",
      "train loss:0.014165539934671676\n",
      "train loss:0.002459915429367249\n",
      "train loss:0.0021317664486290196\n",
      "train loss:0.03392597742909512\n",
      "train loss:0.00424536525647391\n",
      "train loss:0.005633473866230938\n",
      "train loss:0.0003409105598466347\n",
      "train loss:0.0023682140604289704\n",
      "train loss:0.0010121004427930212\n",
      "train loss:0.0018645121172516795\n",
      "train loss:0.007763256853680409\n",
      "train loss:0.008810665101720684\n",
      "train loss:0.00024707512209054696\n",
      "train loss:0.00039931276921562737\n",
      "train loss:0.00039686530178715705\n",
      "train loss:0.0009905366136641323\n",
      "train loss:0.0018421662901595055\n",
      "train loss:0.006729327801278413\n",
      "train loss:0.0014118058514784283\n",
      "train loss:0.00018296274836394563\n",
      "train loss:0.0005434970949356827\n",
      "train loss:0.0005723891424924312\n",
      "train loss:0.00046372322122895576\n",
      "train loss:0.0029547655910295667\n",
      "train loss:0.0008995216491259822\n",
      "train loss:0.0041978209568314575\n",
      "train loss:0.002440127505248528\n",
      "train loss:0.026016793289149184\n",
      "train loss:0.00030143126565130245\n",
      "train loss:0.00016131338032822858\n",
      "train loss:0.0013449958592470451\n",
      "train loss:0.0017746948972483007\n",
      "train loss:0.0004006262842060399\n",
      "train loss:0.0002748726840458939\n",
      "train loss:0.00029021123705510695\n",
      "train loss:0.0008309969477612285\n",
      "train loss:0.0034119130017160586\n",
      "train loss:0.0034301582324083087\n",
      "train loss:0.0003639797507186407\n",
      "train loss:0.00033777174925033674\n",
      "train loss:0.000712236456500188\n",
      "train loss:0.004529696824568659\n",
      "train loss:0.004578916599214093\n",
      "train loss:0.00025372169089534933\n",
      "train loss:0.00045832316067204626\n",
      "train loss:0.0011596973807598205\n",
      "train loss:0.0006931980969101982\n",
      "train loss:0.0001492039105476584\n",
      "train loss:0.0006039023812852217\n",
      "train loss:0.00029249660415960543\n",
      "train loss:0.0011852669285792087\n",
      "train loss:0.0035023145612455204\n",
      "train loss:0.00027595468237198565\n",
      "train loss:0.0017858519302717528\n",
      "train loss:0.0005136399856075104\n",
      "train loss:0.0006517387020759954\n",
      "train loss:0.0009362138765005362\n",
      "train loss:0.007253364851782354\n",
      "train loss:0.004244673704673826\n",
      "train loss:0.00023728264723376052\n",
      "train loss:0.0013231197778411044\n",
      "train loss:0.0006669133482653951\n",
      "train loss:0.00010334378535070472\n",
      "train loss:0.0024993889698450263\n",
      "train loss:0.0003066671861303383\n",
      "train loss:0.0016766321215657609\n",
      "train loss:0.0034352273916215437\n",
      "train loss:0.00018188541306631922\n",
      "train loss:0.0031453878112013968\n",
      "train loss:0.0013429996403714183\n",
      "train loss:0.0007779385408129447\n",
      "train loss:0.014076257540222261\n",
      "train loss:0.001027812413586684\n",
      "train loss:0.0009733904999408298\n",
      "train loss:0.0033796031170544067\n",
      "train loss:7.893402287696874e-05\n",
      "train loss:0.002470947120311915\n",
      "train loss:0.0012195177432207088\n",
      "train loss:0.0022696626529718853\n",
      "train loss:0.0034666363935054356\n",
      "train loss:0.0010043183768688449\n",
      "train loss:0.0019680121202465743\n",
      "train loss:0.001629533280411895\n",
      "train loss:0.00028561548971894397\n",
      "train loss:0.019414499145023523\n",
      "train loss:0.0016215566985479995\n",
      "train loss:0.0037760129147997863\n",
      "train loss:0.00015037471665405012\n",
      "train loss:0.017479158707936468\n",
      "train loss:0.00012830370656883306\n",
      "train loss:0.0009248894613745279\n",
      "train loss:0.0002561351052985125\n",
      "=== epoch:16, train acc:0.997, test acc:0.988 ===\n",
      "train loss:0.0005148650576698624\n",
      "train loss:0.002185978938846605\n",
      "train loss:0.00521700728587487\n",
      "train loss:0.001982251392641088\n",
      "train loss:0.00037521438099911856\n",
      "train loss:8.809492831430469e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0619589466526449\n",
      "train loss:0.003845423910386144\n",
      "train loss:0.0003318142706742347\n",
      "train loss:0.0004511972671281779\n",
      "train loss:0.00023941987268444927\n",
      "train loss:0.003201515145475913\n",
      "train loss:0.002301989453931562\n",
      "train loss:0.004516355225906827\n",
      "train loss:0.004791256056892768\n",
      "train loss:0.0007578530780260127\n",
      "train loss:0.005844971365687774\n",
      "train loss:0.00023816894778274912\n",
      "train loss:0.010687067523014657\n",
      "train loss:0.0013082681752603158\n",
      "train loss:0.0004256928627184307\n",
      "train loss:0.0008880891470243558\n",
      "train loss:0.0016158578473350923\n",
      "train loss:0.004885054799876338\n",
      "train loss:0.0008106746381807654\n",
      "train loss:0.001982563425615123\n",
      "train loss:0.0020619607537146565\n",
      "train loss:0.0019941177326783196\n",
      "train loss:0.004964186498215766\n",
      "train loss:0.00746787910713553\n",
      "train loss:0.0061165155531465775\n",
      "train loss:0.02730394600287679\n",
      "train loss:0.0015559851812159925\n",
      "train loss:0.0026263269617203618\n",
      "train loss:0.00246656236534545\n",
      "train loss:0.0007676914349991156\n",
      "train loss:0.00456680666194891\n",
      "train loss:0.036236282374007424\n",
      "train loss:0.0013258729076488897\n",
      "train loss:0.0038194081204618842\n",
      "train loss:0.00048240121988055574\n",
      "train loss:0.00020588198361368206\n",
      "train loss:0.001639038928229358\n",
      "train loss:0.000967647596773338\n",
      "train loss:0.004639982590756818\n",
      "train loss:0.003212729610257549\n",
      "train loss:0.005247503216125957\n",
      "train loss:0.0002580141087002225\n",
      "train loss:0.020038688874897428\n",
      "train loss:0.000767727741509372\n",
      "train loss:0.0017095471245661298\n",
      "train loss:0.004220603481158538\n",
      "train loss:0.004673585259627858\n",
      "train loss:0.0012345382201310057\n",
      "train loss:0.0038834770202488054\n",
      "train loss:0.0007358174391048924\n",
      "train loss:0.002003692235239378\n",
      "train loss:0.00221575969266649\n",
      "train loss:0.0025897673862037367\n",
      "train loss:0.001451459891496389\n",
      "train loss:0.04233958665769624\n",
      "train loss:0.0012997745386582541\n",
      "train loss:0.0051621565374318275\n",
      "train loss:0.0006965185708578962\n",
      "train loss:0.001046354165300339\n",
      "train loss:0.003992424927970095\n",
      "train loss:0.015841276224352833\n",
      "train loss:0.0009648881076383713\n",
      "train loss:0.0016290273649371594\n",
      "train loss:0.00020959152030772057\n",
      "train loss:0.0016109708661765335\n",
      "train loss:9.428576521713415e-05\n",
      "train loss:0.0046557121968280775\n",
      "train loss:0.0008295230979221177\n",
      "train loss:0.0008502561849680391\n",
      "train loss:0.0021281576748809956\n",
      "train loss:0.0019825568573159187\n",
      "train loss:0.0020294064565875556\n",
      "train loss:4.2534894288063595e-05\n",
      "train loss:0.0017817313459439488\n",
      "train loss:0.011273761174971997\n",
      "train loss:0.0019938036497021776\n",
      "train loss:0.002720888053299133\n",
      "train loss:0.0010455973475777124\n",
      "train loss:0.0010605511542194418\n",
      "train loss:0.001554002556018738\n",
      "train loss:0.0003401542961214931\n",
      "train loss:0.0032149638458306264\n",
      "train loss:0.0014475524147566968\n",
      "train loss:0.0061966263303275685\n",
      "train loss:7.606431572466926e-05\n",
      "train loss:0.0022011367381239906\n",
      "train loss:0.0017264175143307109\n",
      "train loss:0.00045149374588448777\n",
      "train loss:0.0019000667188143543\n",
      "train loss:0.007032459281169626\n",
      "train loss:4.6656631867876397e-05\n",
      "train loss:0.003715406975677422\n",
      "train loss:0.0012638423578257365\n",
      "train loss:0.0016245091284669726\n",
      "train loss:0.002859857906177726\n",
      "train loss:0.002631595188492996\n",
      "train loss:0.0012762877529249373\n",
      "train loss:0.0034419092168800187\n",
      "train loss:0.0029581196944808118\n",
      "train loss:0.0006647852706616017\n",
      "train loss:0.002010133766948708\n",
      "train loss:0.004274942231079191\n",
      "train loss:0.0005600914455238475\n",
      "train loss:0.002975570643275251\n",
      "train loss:0.003159689672738592\n",
      "train loss:0.001220238998737123\n",
      "train loss:0.00264221088071967\n",
      "train loss:0.004338635839127458\n",
      "train loss:0.001947971611397897\n",
      "train loss:0.00023786210403457575\n",
      "train loss:0.017602910609014935\n",
      "train loss:0.0019214963889411948\n",
      "train loss:0.0034123181211109578\n",
      "train loss:0.001467892075998213\n",
      "train loss:0.001737816144537222\n",
      "train loss:0.0006546508259701616\n",
      "train loss:0.0070605946582818595\n",
      "train loss:0.025001262992491533\n",
      "train loss:0.017339515662673485\n",
      "train loss:0.0023905322330051632\n",
      "train loss:0.010014533186821448\n",
      "train loss:0.008338094478161077\n",
      "train loss:0.0030193023244194333\n",
      "train loss:0.0033649078118129926\n",
      "train loss:0.0012225278374345054\n",
      "train loss:0.001367194725890211\n",
      "train loss:0.00022888132676805617\n",
      "train loss:0.0004077654084069246\n",
      "train loss:8.593981413444954e-05\n",
      "train loss:0.0011938997841832659\n",
      "train loss:0.0057613713045112066\n",
      "train loss:0.014074596373960555\n",
      "train loss:0.0032119775204137303\n",
      "train loss:0.0013336742806771865\n",
      "train loss:0.0003090142735661324\n",
      "train loss:0.002578984873604131\n",
      "train loss:0.0009082984008321088\n",
      "train loss:0.00018703402324329963\n",
      "train loss:0.0050705634183505445\n",
      "train loss:0.002621973600762881\n",
      "train loss:0.0022306526935827967\n",
      "train loss:0.0020751618089163717\n",
      "train loss:0.0032450241859257383\n",
      "train loss:0.0004022974339895859\n",
      "train loss:0.015893250019631763\n",
      "train loss:0.006099722793864575\n",
      "train loss:0.0020983633594995913\n",
      "train loss:0.006714829311797563\n",
      "train loss:0.00046553240334229744\n",
      "train loss:0.0031044025323016975\n",
      "train loss:0.010292269663682749\n",
      "train loss:0.0024150937406162455\n",
      "train loss:0.0013395261575335124\n",
      "train loss:0.0002948394380402394\n",
      "train loss:0.002147561396527925\n",
      "train loss:0.0014911977404366296\n",
      "train loss:0.0001667446911256152\n",
      "train loss:0.00015681439562100256\n",
      "train loss:0.005030374733231551\n",
      "train loss:0.0004081678313431247\n",
      "train loss:0.0012139002708991926\n",
      "train loss:0.00906199376770227\n",
      "train loss:0.01838271059995937\n",
      "train loss:0.0020357865255929836\n",
      "train loss:0.0018455818131256658\n",
      "train loss:0.02896046279260371\n",
      "train loss:0.00047460670328002675\n",
      "train loss:0.0010096553779675107\n",
      "train loss:0.0015008409033885237\n",
      "train loss:0.0008773654746541504\n",
      "train loss:0.0018224029705321359\n",
      "train loss:0.0028423459990883702\n",
      "train loss:0.0012438592397086487\n",
      "train loss:0.002791361613884277\n",
      "train loss:0.0029735116733069387\n",
      "train loss:0.00027199990338815143\n",
      "train loss:0.021514178171744752\n",
      "train loss:0.0014640073332919611\n",
      "train loss:0.00038565445740293457\n",
      "train loss:0.00397144288779197\n",
      "train loss:0.0011758399764324752\n",
      "train loss:0.002267941391934367\n",
      "train loss:0.0018131173167805759\n",
      "train loss:0.0026702540175764533\n",
      "train loss:0.0003427424403835781\n",
      "train loss:0.005950100227325822\n",
      "train loss:0.0022863578036392967\n",
      "train loss:0.0021394377055953687\n",
      "train loss:0.0033599176041129164\n",
      "train loss:0.0006507195915010608\n",
      "train loss:0.005448912088868565\n",
      "train loss:0.005661085430775817\n",
      "train loss:0.0035712778271048216\n",
      "train loss:0.009599172488145652\n",
      "train loss:0.0006132572034899597\n",
      "train loss:0.0006465752973122066\n",
      "train loss:0.002863244197832451\n",
      "train loss:0.005381314596226413\n",
      "train loss:0.00033742793496351336\n",
      "train loss:0.01918546796971049\n",
      "train loss:0.0015715942049839848\n",
      "train loss:0.0014200744870287122\n",
      "train loss:0.015023118652337252\n",
      "train loss:0.0021307535596324827\n",
      "train loss:0.011018736126151901\n",
      "train loss:0.003165729101133766\n",
      "train loss:0.000594819309532907\n",
      "train loss:0.00045058624320751917\n",
      "train loss:0.0020396863732778494\n",
      "train loss:0.0015307342468872027\n",
      "train loss:0.003002769521512869\n",
      "train loss:0.0006255978416810286\n",
      "train loss:0.0068238861617271815\n",
      "train loss:0.0004052022582804517\n",
      "train loss:0.0004825355508457578\n",
      "train loss:0.0032603643527998505\n",
      "train loss:0.0017424327444667763\n",
      "train loss:0.0001506860394435948\n",
      "train loss:0.0016784897479782761\n",
      "train loss:0.01101368328672689\n",
      "train loss:0.0013414755365617423\n",
      "train loss:0.0011927643178083038\n",
      "train loss:0.0028292462707812226\n",
      "train loss:0.011231036230678854\n",
      "train loss:0.0023927532348617035\n",
      "train loss:0.007440104949704054\n",
      "train loss:0.003911043882126283\n",
      "train loss:0.0005195647774937489\n",
      "train loss:0.0010658974493010815\n",
      "train loss:0.0006845012227310753\n",
      "train loss:0.03366190633288883\n",
      "train loss:0.0016869332035275666\n",
      "train loss:0.001995098657062204\n",
      "train loss:0.00016499693441900592\n",
      "train loss:0.007046040797027312\n",
      "train loss:0.00013707563771571139\n",
      "train loss:0.01131296074472684\n",
      "train loss:0.003953324351135693\n",
      "train loss:0.006951572914364742\n",
      "train loss:0.0008708524476241379\n",
      "train loss:0.0074587746973365145\n",
      "train loss:0.001926352178770268\n",
      "train loss:0.0024604027306050335\n",
      "train loss:0.0023236126436295777\n",
      "train loss:0.0021809284918695294\n",
      "train loss:0.010961701986371914\n",
      "train loss:0.0008859124965359978\n",
      "train loss:0.010199109623936758\n",
      "train loss:0.008610293968947589\n",
      "train loss:0.0012319424919448143\n",
      "train loss:0.002144279393169899\n",
      "train loss:0.0015662787926205611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009794195429421082\n",
      "train loss:0.002199864323117358\n",
      "train loss:0.0005077166488581227\n",
      "train loss:0.0003355104190806912\n",
      "train loss:0.00039395613752949956\n",
      "train loss:0.0032812144842633366\n",
      "train loss:0.0008074416811603524\n",
      "train loss:0.003109468513761306\n",
      "train loss:0.0027301097104178106\n",
      "train loss:0.00023720145140723376\n",
      "train loss:0.0018248264476325657\n",
      "train loss:0.0010402856496291248\n",
      "train loss:0.0015275564496785386\n",
      "train loss:0.0031789600622687307\n",
      "train loss:0.0019735802883942633\n",
      "train loss:0.002026751537579915\n",
      "train loss:0.003816398787369174\n",
      "train loss:0.000698278113446607\n",
      "train loss:0.0032458446841425147\n",
      "train loss:0.0034028804098735336\n",
      "train loss:0.0007400181120828435\n",
      "train loss:0.0013066160427396456\n",
      "train loss:0.0024193449991842917\n",
      "train loss:0.005017222723282393\n",
      "train loss:0.0004290360130999769\n",
      "train loss:0.0013087460027199906\n",
      "train loss:0.0007706848110726051\n",
      "train loss:0.004005101163506028\n",
      "train loss:0.0007193671884817759\n",
      "train loss:0.0006427860504389251\n",
      "train loss:0.00039770337038751396\n",
      "train loss:0.00011847654412778906\n",
      "train loss:0.0005179784370993518\n",
      "train loss:0.0010242279653322306\n",
      "train loss:0.002446631813655517\n",
      "train loss:0.0005286499443347526\n",
      "train loss:0.028659166291285367\n",
      "train loss:0.0002330087727987885\n",
      "train loss:0.002560601333654794\n",
      "train loss:0.0002667547051444368\n",
      "train loss:0.0006026798753643856\n",
      "train loss:0.002246723643303771\n",
      "train loss:0.002107401498909871\n",
      "train loss:0.00048466134943255836\n",
      "train loss:0.002609559194410652\n",
      "train loss:0.00564474274737433\n",
      "train loss:0.0013144377773158672\n",
      "train loss:0.01850653642090548\n",
      "train loss:0.0028044919769843243\n",
      "train loss:0.0016724696077796894\n",
      "train loss:0.0005239189330942871\n",
      "train loss:0.005625672610556085\n",
      "train loss:0.00266243419146771\n",
      "train loss:0.001041843796036546\n",
      "train loss:0.0004179895247523955\n",
      "train loss:0.001456867441724143\n",
      "train loss:0.0007318832244556001\n",
      "train loss:0.00015635176307305542\n",
      "train loss:0.0012938547800450675\n",
      "train loss:0.0038103625551274933\n",
      "train loss:0.00282709665049755\n",
      "train loss:0.0024650278583523547\n",
      "train loss:0.0033449763065538677\n",
      "train loss:0.0018741258993202575\n",
      "train loss:0.0015199366464774032\n",
      "train loss:0.002711834048142173\n",
      "train loss:0.00426160828934771\n",
      "train loss:0.003983055386239599\n",
      "train loss:0.0006069550235037524\n",
      "train loss:0.000710131789759804\n",
      "train loss:0.0044264737827498625\n",
      "train loss:0.001269327725965329\n",
      "train loss:0.003216523254006541\n",
      "train loss:0.0019702625342587475\n",
      "train loss:0.0004670095973423343\n",
      "train loss:0.004388223015431839\n",
      "train loss:0.00038094621633330344\n",
      "train loss:0.009325989338428743\n",
      "train loss:0.0034899208850712763\n",
      "train loss:0.0008659650524411861\n",
      "train loss:0.002722379671198901\n",
      "train loss:0.005435618520158775\n",
      "train loss:0.002111423213729018\n",
      "train loss:0.0013397334294294814\n",
      "train loss:0.007971534619486057\n",
      "train loss:0.00033933814915126806\n",
      "train loss:0.008862784233812598\n",
      "train loss:0.0009883521764026502\n",
      "train loss:0.0008629689514737419\n",
      "train loss:0.012107353870830364\n",
      "train loss:0.0018693111168377246\n",
      "train loss:0.004771924936408278\n",
      "train loss:0.040083203777832546\n",
      "train loss:0.0008693250853014866\n",
      "train loss:0.0003440888918864733\n",
      "train loss:0.001341761767043176\n",
      "train loss:0.0008640991043273766\n",
      "train loss:0.0006270920498066455\n",
      "train loss:0.00034073008045417254\n",
      "train loss:0.01697453931770303\n",
      "train loss:0.0020837976344509194\n",
      "train loss:0.0005726276333593417\n",
      "train loss:0.0018451776206669676\n",
      "train loss:0.0022581725107992208\n",
      "train loss:0.0010587707899707508\n",
      "train loss:0.002001465032037309\n",
      "train loss:0.0017159280108206042\n",
      "train loss:0.0009184419687943437\n",
      "train loss:0.0021119911432945448\n",
      "train loss:0.0018657941030597782\n",
      "train loss:0.0006387253801263848\n",
      "train loss:0.0012920455226006237\n",
      "train loss:0.006459897403131635\n",
      "train loss:0.00024940542251327487\n",
      "train loss:0.004317935316748456\n",
      "train loss:0.0003497591704412012\n",
      "train loss:0.0029648313169621703\n",
      "train loss:0.0005766844694899505\n",
      "train loss:0.0017827271107622791\n",
      "train loss:0.00018680991326144836\n",
      "train loss:0.00401207711354554\n",
      "train loss:0.0025489735778425403\n",
      "train loss:0.002356611477619123\n",
      "train loss:0.003429893847019089\n",
      "train loss:0.0024322072263003283\n",
      "train loss:0.000731735743232224\n",
      "train loss:0.0018739676600141376\n",
      "train loss:0.0037441217212355504\n",
      "train loss:0.0004202371077483818\n",
      "train loss:0.011623370567282115\n",
      "train loss:0.005584477957608123\n",
      "train loss:0.003467205499667261\n",
      "train loss:0.004734034550492093\n",
      "train loss:0.0006561264013203464\n",
      "train loss:7.552273234962868e-05\n",
      "train loss:0.0011045918144386734\n",
      "train loss:0.0017590462414690804\n",
      "train loss:0.0009346803363010562\n",
      "train loss:0.0027551426471501637\n",
      "train loss:0.0002107262789988673\n",
      "train loss:0.004236585557806636\n",
      "train loss:0.00192743951124091\n",
      "train loss:0.0027189918433333554\n",
      "train loss:0.00040165331791539824\n",
      "train loss:0.0006781633190472062\n",
      "train loss:0.007575281172127558\n",
      "train loss:0.0005401900536398169\n",
      "train loss:0.003674535786035896\n",
      "train loss:0.0003802631046439104\n",
      "train loss:0.00013290365169138925\n",
      "train loss:0.0015793671001969657\n",
      "train loss:0.0003157684323917838\n",
      "train loss:0.00021364852491629252\n",
      "train loss:0.020912024875663782\n",
      "train loss:0.004727025242889356\n",
      "train loss:0.0008823662555418368\n",
      "train loss:0.0018044538920198242\n",
      "train loss:0.0038633331435112485\n",
      "train loss:0.0002626770809593983\n",
      "train loss:0.0049836175034759025\n",
      "train loss:0.002488418706782268\n",
      "train loss:0.000216145832635719\n",
      "train loss:0.003992284420459406\n",
      "train loss:0.0012025091730537248\n",
      "train loss:0.0003132266127357104\n",
      "train loss:0.003217305811727554\n",
      "train loss:0.0038962417845530093\n",
      "train loss:0.0008617422362181743\n",
      "train loss:0.0012476958703826824\n",
      "train loss:0.0003004415111114199\n",
      "train loss:0.002535492426815249\n",
      "train loss:0.0023880336588350255\n",
      "train loss:0.0018470541817178473\n",
      "train loss:0.0042222282056650785\n",
      "train loss:0.00018567240925581783\n",
      "train loss:0.01340979511713631\n",
      "train loss:0.0003223701735623017\n",
      "train loss:0.002089474474523301\n",
      "train loss:0.0026225062535867897\n",
      "train loss:0.0011006556874360836\n",
      "train loss:0.006930245015975778\n",
      "train loss:0.0023442772682335717\n",
      "train loss:0.017876181198446896\n",
      "train loss:0.001969979466944869\n",
      "train loss:0.005281731958391548\n",
      "train loss:0.0007244574933079027\n",
      "train loss:0.000863486213613112\n",
      "train loss:0.0019065397564684056\n",
      "train loss:0.0003653787780160913\n",
      "train loss:0.0004150386306908513\n",
      "train loss:0.0002208328320215628\n",
      "train loss:0.0011940274198218124\n",
      "train loss:0.00011963910701590186\n",
      "train loss:0.0018021907959550306\n",
      "train loss:0.0004440616817597772\n",
      "train loss:0.0008979595133945527\n",
      "train loss:0.0006187698898080854\n",
      "train loss:0.002750167023786715\n",
      "train loss:0.015001521911762907\n",
      "train loss:0.004068720305813004\n",
      "train loss:0.0009210312538191389\n",
      "train loss:0.004900428593355869\n",
      "train loss:0.0003803086391492549\n",
      "train loss:0.0006459215950772536\n",
      "train loss:0.00035697143713090155\n",
      "train loss:0.003956534247323346\n",
      "train loss:0.0010110151975422036\n",
      "train loss:0.00020701991412243377\n",
      "train loss:0.000971337130049096\n",
      "train loss:0.00037662315197197475\n",
      "train loss:0.00015688728643460943\n",
      "train loss:0.0008552631767375627\n",
      "train loss:0.004508580512174929\n",
      "train loss:0.000498675060366157\n",
      "train loss:0.006913854913342904\n",
      "train loss:0.0023883794585781324\n",
      "train loss:0.00017206868218641396\n",
      "train loss:0.0003800317737551003\n",
      "train loss:0.0008618205973335608\n",
      "train loss:0.0013736052300160478\n",
      "train loss:0.0022880019191120495\n",
      "train loss:0.004556289326821849\n",
      "train loss:0.00031123703908604133\n",
      "train loss:0.002549278931391674\n",
      "train loss:0.0027378203740212985\n",
      "train loss:0.0008635789843322222\n",
      "train loss:0.003493770688938399\n",
      "train loss:0.0007218947640633526\n",
      "train loss:0.0032307754683872257\n",
      "train loss:0.0011645335381005623\n",
      "train loss:0.0009721691048438975\n",
      "train loss:0.003674184427220661\n",
      "train loss:0.0035154530227443827\n",
      "train loss:0.001130325674359892\n",
      "train loss:0.00033523287084070226\n",
      "train loss:0.0010527842926739968\n",
      "train loss:0.0017415201158180013\n",
      "train loss:0.001467017733406801\n",
      "train loss:0.000841084451906695\n",
      "train loss:0.0002291327556876203\n",
      "train loss:0.00204507739148193\n",
      "train loss:0.005990222219623748\n",
      "train loss:0.0022408636190820908\n",
      "train loss:0.00023248353713624083\n",
      "train loss:0.00030362010539699354\n",
      "train loss:0.0030345287838307\n",
      "train loss:0.00014064476039602576\n",
      "train loss:0.0010503833555131994\n",
      "train loss:0.007377270698695148\n",
      "train loss:0.00013284822825492828\n",
      "train loss:0.0007333905238211627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0013799331955031513\n",
      "train loss:0.0007801866248197488\n",
      "train loss:0.0009206697445534998\n",
      "train loss:3.568467881286856e-05\n",
      "train loss:7.149983885888062e-05\n",
      "train loss:0.0001288000807829777\n",
      "train loss:0.0009043781167872578\n",
      "train loss:0.003110124622588069\n",
      "train loss:0.01119226268499674\n",
      "train loss:7.804577814233235e-05\n",
      "train loss:0.020830096296028115\n",
      "train loss:0.0009139524713195829\n",
      "train loss:0.0007070259827742043\n",
      "train loss:0.0014190571914203115\n",
      "train loss:0.004685332459243239\n",
      "train loss:0.0004822279271724796\n",
      "train loss:0.0009349232672325365\n",
      "train loss:0.001005887450054268\n",
      "train loss:0.0005746454999645545\n",
      "train loss:0.0043996707285391306\n",
      "train loss:0.0014819967877253112\n",
      "train loss:0.0008100528342381019\n",
      "train loss:0.002964319129638603\n",
      "train loss:0.00333356706076319\n",
      "train loss:0.004719927407363305\n",
      "train loss:0.0001008842138964851\n",
      "train loss:6.317864555451891e-05\n",
      "train loss:0.0012546598505450116\n",
      "train loss:0.004634360519920905\n",
      "train loss:0.003491493874438286\n",
      "train loss:0.0077779832909380285\n",
      "train loss:0.0027457671549015817\n",
      "train loss:0.0015021078029057197\n",
      "train loss:0.000696365832762646\n",
      "train loss:0.0009654163600807655\n",
      "train loss:0.0026080961618936607\n",
      "train loss:0.0004311049209045006\n",
      "train loss:0.00032119765738462694\n",
      "train loss:0.0017311181151457807\n",
      "train loss:0.0012014354051905415\n",
      "train loss:0.0006761798200940844\n",
      "train loss:0.00032967101784318805\n",
      "train loss:0.004218757578041954\n",
      "train loss:0.047322256148559\n",
      "train loss:0.002526900776074123\n",
      "train loss:0.003325643916275033\n",
      "train loss:0.0066550259611219435\n",
      "train loss:0.0004582812112467979\n",
      "train loss:0.0011816824363810867\n",
      "train loss:0.005350462737154496\n",
      "train loss:0.009470399296589611\n",
      "train loss:0.0015511173835795157\n",
      "train loss:0.0028002877563423996\n",
      "train loss:0.00010145283840806409\n",
      "train loss:0.00418364718046041\n",
      "train loss:0.010713779595409574\n",
      "train loss:0.00445531253917973\n",
      "train loss:0.009433175495919452\n",
      "train loss:0.004112603072247891\n",
      "train loss:0.0003443994108553244\n",
      "train loss:0.0008606000397573033\n",
      "train loss:0.0024376834147281285\n",
      "train loss:0.001547494971117397\n",
      "train loss:0.000752297717086586\n",
      "train loss:0.0012882245891923346\n",
      "train loss:0.0042541119094000185\n",
      "train loss:0.0024674629752665348\n",
      "train loss:0.00036495591075326857\n",
      "train loss:0.0009685909800158588\n",
      "train loss:0.006560790076248803\n",
      "train loss:0.002758892321788145\n",
      "train loss:0.0001460436336753641\n",
      "train loss:0.0010247443262103677\n",
      "train loss:0.0006976908510422787\n",
      "train loss:0.006855881153753279\n",
      "train loss:0.00044690936564385065\n",
      "train loss:0.00019438497198045142\n",
      "train loss:0.0018159905737935309\n",
      "train loss:7.704428983188483e-05\n",
      "train loss:0.0011004974622468137\n",
      "train loss:0.00038734403316539114\n",
      "train loss:0.006079675961844604\n",
      "train loss:0.0165602661700515\n",
      "train loss:0.0002522839791523186\n",
      "train loss:0.007041025812213573\n",
      "train loss:0.0014215770601167766\n",
      "train loss:0.0024053072254907135\n",
      "train loss:0.001501276340691702\n",
      "train loss:0.008724031731147558\n",
      "train loss:0.000834851515326355\n",
      "train loss:0.000598619678302534\n",
      "=== epoch:17, train acc:0.996, test acc:0.988 ===\n",
      "train loss:0.015000335584021179\n",
      "train loss:0.0020395143403206437\n",
      "train loss:0.005398002158574607\n",
      "train loss:0.0032755856407781325\n",
      "train loss:0.001176216331697772\n",
      "train loss:0.009291471913123414\n",
      "train loss:0.0009279676300750898\n",
      "train loss:0.001978752288768808\n",
      "train loss:0.0002654426556548096\n",
      "train loss:0.0036543371108794078\n",
      "train loss:0.0014261540212752678\n",
      "train loss:0.017106247076169017\n",
      "train loss:0.0036998205700760683\n",
      "train loss:0.004442212871803545\n",
      "train loss:0.0018582637316589725\n",
      "train loss:0.004269837025867424\n",
      "train loss:0.020298616803947827\n",
      "train loss:0.007183863859469901\n",
      "train loss:0.0006574556368809001\n",
      "train loss:0.009062076636599865\n",
      "train loss:0.0001037694308418121\n",
      "train loss:0.010387916549230125\n",
      "train loss:0.0030009640819380397\n",
      "train loss:0.008495195624851697\n",
      "train loss:0.0009641967732272108\n",
      "train loss:0.0006874085847948996\n",
      "train loss:0.011004810518626182\n",
      "train loss:0.0013636156913600186\n",
      "train loss:0.002248414487824178\n",
      "train loss:0.0005562224649206328\n",
      "train loss:0.00042536074852992316\n",
      "train loss:0.004820774692075974\n",
      "train loss:0.002617215995103197\n",
      "train loss:0.0016863744006953227\n",
      "train loss:0.00022066027491835606\n",
      "train loss:0.0033371041604788555\n",
      "train loss:0.00023072212220894838\n",
      "train loss:0.002788536570586489\n",
      "train loss:0.02155338370230658\n",
      "train loss:0.0009986498449192746\n",
      "train loss:0.017693592627864695\n",
      "train loss:0.005244700012982324\n",
      "train loss:0.0028664513040770577\n",
      "train loss:0.0016581799647667204\n",
      "train loss:0.0019231325052337699\n",
      "train loss:0.0022312859278161615\n",
      "train loss:0.00010754057320955025\n",
      "train loss:0.006810501504035824\n",
      "train loss:0.0005682007105387875\n",
      "train loss:0.043711265216816696\n",
      "train loss:9.476393521953421e-05\n",
      "train loss:0.004027391213569132\n",
      "train loss:0.005047445494221635\n",
      "train loss:0.01443494380989029\n",
      "train loss:0.01099341765122511\n",
      "train loss:0.0007688058879851071\n",
      "train loss:0.0005858943073191203\n",
      "train loss:0.0015939598711737749\n",
      "train loss:0.0035851883297951187\n",
      "train loss:0.0013877497846922502\n",
      "train loss:0.0004260932329795787\n",
      "train loss:0.004053376576462325\n",
      "train loss:3.866213065885545e-05\n",
      "train loss:0.00040642876445288925\n",
      "train loss:0.0003228237125600063\n",
      "train loss:0.01177506387214481\n",
      "train loss:0.0019285422256714781\n",
      "train loss:0.000671444046017882\n",
      "train loss:0.01746378667933789\n",
      "train loss:0.0003262450186801789\n",
      "train loss:2.8602426146849472e-05\n",
      "train loss:0.0006002242718698058\n",
      "train loss:0.0006006449521148568\n",
      "train loss:0.0002811156830438136\n",
      "train loss:0.0006304878342699145\n",
      "train loss:0.0014572720744146935\n",
      "train loss:0.02389538935263589\n",
      "train loss:0.00018847901488129625\n",
      "train loss:0.0009791605808014297\n",
      "train loss:0.003323491846621507\n",
      "train loss:0.0028073681042992127\n",
      "train loss:0.007406443956346303\n",
      "train loss:0.0010352986276791628\n",
      "train loss:0.0049593962030737865\n",
      "train loss:5.9739414797270355e-05\n",
      "train loss:0.005055370870347784\n",
      "train loss:0.0005790312359526337\n",
      "train loss:0.006238022565157802\n",
      "train loss:0.0006044342410076371\n",
      "train loss:0.000307764603431679\n",
      "train loss:0.0001815134986752176\n",
      "train loss:0.0009227815709081066\n",
      "train loss:0.00059351832104645\n",
      "train loss:0.0010259027022467954\n",
      "train loss:0.00047257420004684136\n",
      "train loss:0.0346680621148006\n",
      "train loss:0.008164752569131808\n",
      "train loss:0.004255105566953822\n",
      "train loss:0.0018371310792997977\n",
      "train loss:0.01026703894160389\n",
      "train loss:0.000932224146493904\n",
      "train loss:0.0008341795457256618\n",
      "train loss:0.002757379093108959\n",
      "train loss:0.0017644282841539477\n",
      "train loss:0.0009719761962153955\n",
      "train loss:0.006372507491442475\n",
      "train loss:0.004600071061427724\n",
      "train loss:0.0005463040714634674\n",
      "train loss:0.001893304350844155\n",
      "train loss:0.02564557396137802\n",
      "train loss:0.0009064715917917429\n",
      "train loss:0.0009007170551765064\n",
      "train loss:0.008025410844975723\n",
      "train loss:0.025470214136716747\n",
      "train loss:0.003964151371574449\n",
      "train loss:0.0018581738428897\n",
      "train loss:0.002424611444358512\n",
      "train loss:0.007624740058106109\n",
      "train loss:0.0008725336928001737\n",
      "train loss:0.001960766552243066\n",
      "train loss:0.0007432044747708956\n",
      "train loss:0.0005189094774862882\n",
      "train loss:0.00015416637787274174\n",
      "train loss:0.0018529012790371238\n",
      "train loss:0.0004972008300381989\n",
      "train loss:0.0019391624379110533\n",
      "train loss:0.003061265688173774\n",
      "train loss:0.002027399971947718\n",
      "train loss:0.0029213806554220546\n",
      "train loss:0.0012184952041711392\n",
      "train loss:0.00205350697151364\n",
      "train loss:0.00939060911855383\n",
      "train loss:0.0017508020504359099\n",
      "train loss:0.005303676559828665\n",
      "train loss:0.0003551749071651707\n",
      "train loss:0.0018101176649435715\n",
      "train loss:0.001507611814765145\n",
      "train loss:0.0011181565732809823\n",
      "train loss:0.0012649549242168513\n",
      "train loss:0.0004352172581359183\n",
      "train loss:0.003225853261483564\n",
      "train loss:0.017754877368861395\n",
      "train loss:0.001935455978655913\n",
      "train loss:0.000108703922282932\n",
      "train loss:0.00018750643506515143\n",
      "train loss:0.00019532234188341345\n",
      "train loss:0.00604484809322964\n",
      "train loss:0.00890562904972292\n",
      "train loss:0.0008770438980991551\n",
      "train loss:0.0004270150583020487\n",
      "train loss:0.01210301283903048\n",
      "train loss:0.004638648565104277\n",
      "train loss:0.0035401506360294576\n",
      "train loss:0.0045634502114842825\n",
      "train loss:0.024944504509828727\n",
      "train loss:0.0054097927019288675\n",
      "train loss:0.022140445819050007\n",
      "train loss:0.008328488509356906\n",
      "train loss:0.015134028325113829\n",
      "train loss:0.0011470747390898504\n",
      "train loss:0.01576602184093532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005316844756237568\n",
      "train loss:0.003717128006524262\n",
      "train loss:0.016011445196161482\n",
      "train loss:0.0004187710186335384\n",
      "train loss:0.0015191226807231267\n",
      "train loss:0.0004895812730261569\n",
      "train loss:0.00010524491537476122\n",
      "train loss:0.004661476106343454\n",
      "train loss:0.0047266629544416225\n",
      "train loss:0.0012247376667264402\n",
      "train loss:0.00022151439827525766\n",
      "train loss:0.0023491406441486897\n",
      "train loss:0.001792877545022327\n",
      "train loss:0.000845574799354858\n",
      "train loss:8.28987299251683e-05\n",
      "train loss:0.004124502149520574\n",
      "train loss:0.005165376852917747\n",
      "train loss:0.0012500820724456992\n",
      "train loss:0.0007775891362714436\n",
      "train loss:0.0010506577743560632\n",
      "train loss:0.002607122579490065\n",
      "train loss:0.00019805096002685458\n",
      "train loss:0.001895900593339444\n",
      "train loss:0.0021400418860028805\n",
      "train loss:0.0023627464440175005\n",
      "train loss:0.0008175315372795693\n",
      "train loss:0.0025423302123549155\n",
      "train loss:0.0014871122035554746\n",
      "train loss:0.024296403264102064\n",
      "train loss:0.004071244344184686\n",
      "train loss:0.0017588584974336362\n",
      "train loss:0.004338148028098283\n",
      "train loss:0.0004610220097612395\n",
      "train loss:0.04089593462532825\n",
      "train loss:0.002973707985693805\n",
      "train loss:0.0015118358323397746\n",
      "train loss:0.0030679397358582107\n",
      "train loss:0.0003191327508467149\n",
      "train loss:0.0018176465787905877\n",
      "train loss:0.00013691885426416283\n",
      "train loss:0.00020551929507957997\n",
      "train loss:0.005574612154481623\n",
      "train loss:0.0023742084897450935\n",
      "train loss:0.0005532030277898831\n",
      "train loss:0.0006728090126909008\n",
      "train loss:0.00013173369734025892\n",
      "train loss:0.0006939231360943203\n",
      "train loss:0.0001500569227130992\n",
      "train loss:0.0024098215095272584\n",
      "train loss:0.004179240859571031\n",
      "train loss:0.00426452573948494\n",
      "train loss:0.021906003623602906\n",
      "train loss:0.0006881641693074317\n",
      "train loss:0.004501803886322105\n",
      "train loss:0.0006381787587500579\n",
      "train loss:0.0015429632579368054\n",
      "train loss:0.002978081061966453\n",
      "train loss:0.0005887678371174218\n",
      "train loss:0.0043260217246128335\n",
      "train loss:8.69007118082242e-05\n",
      "train loss:0.002392471985058007\n",
      "train loss:0.0020963678251775674\n",
      "train loss:0.0008482293296934966\n",
      "train loss:0.0026133993591382415\n",
      "train loss:0.01200430950562501\n",
      "train loss:0.0014876429753460285\n",
      "train loss:0.0031055829554576327\n",
      "train loss:0.0008126652887297177\n",
      "train loss:0.0027866583663472\n",
      "train loss:0.00025322949759658947\n",
      "train loss:0.0017726237829491578\n",
      "train loss:0.00014077491514813422\n",
      "train loss:0.0006249209611356637\n",
      "train loss:0.0006639961383248606\n",
      "train loss:0.002039081206563551\n",
      "train loss:0.0002345951236669414\n",
      "train loss:0.004013034658993571\n",
      "train loss:0.003369825643284351\n",
      "train loss:0.0035949305791302486\n",
      "train loss:0.00016947084299329406\n",
      "train loss:0.001143859202125678\n",
      "train loss:0.0001649985580139363\n",
      "train loss:0.01361702812285861\n",
      "train loss:0.0029512917748646833\n",
      "train loss:0.0006155445732777772\n",
      "train loss:0.019058890797729114\n",
      "train loss:0.0015294006092246458\n",
      "train loss:0.00027450772129615584\n",
      "train loss:0.001169743197146458\n",
      "train loss:0.0007506047536257801\n",
      "train loss:0.0003089626520397126\n",
      "train loss:0.0004987639043312502\n",
      "train loss:0.000737578896118889\n",
      "train loss:0.0068281200041449145\n",
      "train loss:0.0029044021692869577\n",
      "train loss:0.0032193119885135153\n",
      "train loss:0.0003032331755021213\n",
      "train loss:0.005115755646874422\n",
      "train loss:0.002598177114478916\n",
      "train loss:0.0049712275238010615\n",
      "train loss:0.015735708617454717\n",
      "train loss:0.0018509226675373545\n",
      "train loss:0.0016868066941453778\n",
      "train loss:0.004758350280264398\n",
      "train loss:0.000742826350687372\n",
      "train loss:0.0005949290072343474\n",
      "train loss:0.00668148765324096\n",
      "train loss:0.0002678095300180089\n",
      "train loss:0.00017293577990180924\n",
      "train loss:0.000155915834428503\n",
      "train loss:0.00035761543150251876\n",
      "train loss:0.0018874234101891954\n",
      "train loss:0.004077010684763415\n",
      "train loss:0.006734704082757243\n",
      "train loss:0.01204108131418147\n",
      "train loss:0.003420952353572499\n",
      "train loss:0.00043089492864310813\n",
      "train loss:0.0022074741929909584\n",
      "train loss:0.002044591137146516\n",
      "train loss:0.00876152941969575\n",
      "train loss:0.0023590605924976985\n",
      "train loss:0.0020319618635124344\n",
      "train loss:0.0003463362020904811\n",
      "train loss:0.004564708075950842\n",
      "train loss:0.0004860194589887472\n",
      "train loss:0.0009418807134975856\n",
      "train loss:0.0016707524877659899\n",
      "train loss:0.0005356804065175471\n",
      "train loss:0.0012727133589281983\n",
      "train loss:0.00015819453269093735\n",
      "train loss:0.02069206448619483\n",
      "train loss:0.0018845139369303534\n",
      "train loss:0.007297429493017315\n",
      "train loss:0.0011653824897397312\n",
      "train loss:0.0008182150221015966\n",
      "train loss:0.002270058137739506\n",
      "train loss:0.0012182654730442846\n",
      "train loss:0.00016665607172009454\n",
      "train loss:0.0002777154019094411\n",
      "train loss:0.0004712205664561313\n",
      "train loss:0.004818103670052279\n",
      "train loss:0.0036975803286821603\n",
      "train loss:0.000675021255108932\n",
      "train loss:0.00560442223570402\n",
      "train loss:0.0027595871266029625\n",
      "train loss:0.005315404820762644\n",
      "train loss:0.00025067685986951643\n",
      "train loss:0.00017455635680695472\n",
      "train loss:0.00048522368151516495\n",
      "train loss:0.00039499605335717875\n",
      "train loss:0.015045797757135396\n",
      "train loss:0.000687624967466007\n",
      "train loss:0.010792251064236364\n",
      "train loss:0.0017567991668439966\n",
      "train loss:0.003617128477126357\n",
      "train loss:0.0007696275156008761\n",
      "train loss:0.0006498163323994127\n",
      "train loss:0.00982071537891065\n",
      "train loss:0.0008505479373426375\n",
      "train loss:0.0015373903402134182\n",
      "train loss:0.0013003888116707252\n",
      "train loss:0.00045565760173493124\n",
      "train loss:0.002740190130484761\n",
      "train loss:0.0044585553450839635\n",
      "train loss:0.0006562585416580108\n",
      "train loss:0.0026610179393090137\n",
      "train loss:0.0010154254989834628\n",
      "train loss:0.0008055849023088804\n",
      "train loss:0.0057500325949915165\n",
      "train loss:0.008992762847813076\n",
      "train loss:0.00011665371395400381\n",
      "train loss:0.0008350629808783497\n",
      "train loss:0.003065782030330501\n",
      "train loss:0.00038709967785523707\n",
      "train loss:0.00043530558001580164\n",
      "train loss:0.011357875278685946\n",
      "train loss:0.00016787455364074136\n",
      "train loss:0.003461328600824025\n",
      "train loss:0.0029467017608423005\n",
      "train loss:0.0010284708218426366\n",
      "train loss:0.010016569946441636\n",
      "train loss:0.00010842260175283245\n",
      "train loss:0.0013570545417884627\n",
      "train loss:0.0010333397914270453\n",
      "train loss:0.00255010598024351\n",
      "train loss:0.007039533051305668\n",
      "train loss:0.0007872144934073451\n",
      "train loss:0.001774414435342407\n",
      "train loss:0.002250198061554307\n",
      "train loss:0.0006421980678129318\n",
      "train loss:0.0010447935054188702\n",
      "train loss:0.00024713311294330723\n",
      "train loss:0.0004861185901427126\n",
      "train loss:0.004969219068791048\n",
      "train loss:0.0024599166230661195\n",
      "train loss:0.003964285053515597\n",
      "train loss:0.002765775691571577\n",
      "train loss:0.0003800721526455253\n",
      "train loss:0.0020503880376068003\n",
      "train loss:0.0028290050322257966\n",
      "train loss:0.01997139153112477\n",
      "train loss:0.0054477686047222805\n",
      "train loss:0.0009254543395491816\n",
      "train loss:0.0026321568811615947\n",
      "train loss:0.00013373566713680804\n",
      "train loss:0.0005399552821994154\n",
      "train loss:0.00037054500990453917\n",
      "train loss:0.004580439853965209\n",
      "train loss:0.0016895227217488215\n",
      "train loss:0.0008818459809241945\n",
      "train loss:0.00039755881962777906\n",
      "train loss:0.009216703976478599\n",
      "train loss:0.0008793377923037354\n",
      "train loss:0.004209493438628449\n",
      "train loss:0.0006136578766438948\n",
      "train loss:0.005044080245675363\n",
      "train loss:0.003299072383515543\n",
      "train loss:0.0020554842618523733\n",
      "train loss:0.0015187566987729516\n",
      "train loss:0.0006890728102610344\n",
      "train loss:0.007441143359964085\n",
      "train loss:0.007384114601230256\n",
      "train loss:0.00034564730392174674\n",
      "train loss:0.00013930333147695465\n",
      "train loss:0.000480509267917301\n",
      "train loss:0.00029479488024336726\n",
      "train loss:0.00026279562974291566\n",
      "train loss:0.0009694879833719054\n",
      "train loss:0.00034209072312109894\n",
      "train loss:0.00030049382636593064\n",
      "train loss:0.008267657208824991\n",
      "train loss:0.0014484840194271037\n",
      "train loss:0.009555151251521411\n",
      "train loss:0.0011098318719737663\n",
      "train loss:0.0006295583205579402\n",
      "train loss:0.0008129114926573068\n",
      "train loss:0.004039945140703199\n",
      "train loss:0.00121336609489117\n",
      "train loss:0.011915190236669482\n",
      "train loss:0.0006631511149033535\n",
      "train loss:0.0018102927502042334\n",
      "train loss:0.0007844293783160022\n",
      "train loss:0.005732494945890308\n",
      "train loss:0.0006490508360187464\n",
      "train loss:0.00046707995576912386\n",
      "train loss:0.002663420392858809\n",
      "train loss:0.0022475523915902935\n",
      "train loss:0.0013133033802390616\n",
      "train loss:9.61733937641603e-05\n",
      "train loss:4.091755951854754e-05\n",
      "train loss:0.002610844229188887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0027725081466840906\n",
      "train loss:0.00048353314784230125\n",
      "train loss:0.008222379992971273\n",
      "train loss:0.0017545031197584745\n",
      "train loss:0.0006410708914430831\n",
      "train loss:0.0015546451158357593\n",
      "train loss:0.0013431631940357316\n",
      "train loss:0.00096849299899281\n",
      "train loss:0.008322581695289355\n",
      "train loss:0.0038507810368644414\n",
      "train loss:0.0027468599029602963\n",
      "train loss:0.0023547773031642816\n",
      "train loss:0.00755737361434334\n",
      "train loss:0.00024640222723393843\n",
      "train loss:0.006507165779612867\n",
      "train loss:0.0008886318864876301\n",
      "train loss:0.0029417187658193795\n",
      "train loss:0.0002399146718512617\n",
      "train loss:0.0016748689023216965\n",
      "train loss:0.0016552335941466486\n",
      "train loss:0.005193452478452601\n",
      "train loss:0.001598810181570271\n",
      "train loss:0.00014777422291621187\n",
      "train loss:0.0032326986566458137\n",
      "train loss:0.005693381648902695\n",
      "train loss:0.002476782319510522\n",
      "train loss:0.0020364029672263074\n",
      "train loss:0.0006873763852912834\n",
      "train loss:8.692855011389754e-05\n",
      "train loss:0.0003613677381533305\n",
      "train loss:0.0010277984612018\n",
      "train loss:0.011818564732674432\n",
      "train loss:0.0009781093753442856\n",
      "train loss:0.0027844666751426442\n",
      "train loss:0.0060859782404552205\n",
      "train loss:0.0031484288242189184\n",
      "train loss:0.002969288140512108\n",
      "train loss:0.000132730929508171\n",
      "train loss:0.00012071784391269873\n",
      "train loss:0.008257964305299766\n",
      "train loss:0.0011579857337460301\n",
      "train loss:0.019082078824813734\n",
      "train loss:0.0011923744556030461\n",
      "train loss:0.0003058060533408668\n",
      "train loss:0.01004079027876479\n",
      "train loss:0.00031653022651432274\n",
      "train loss:0.0008024540068301693\n",
      "train loss:0.0018562696456142945\n",
      "train loss:0.0006480215853422484\n",
      "train loss:0.03717911760837039\n",
      "train loss:2.3036025058174307e-05\n",
      "train loss:0.00021915748396019897\n",
      "train loss:0.0006564507903176299\n",
      "train loss:0.0027958153262386556\n",
      "train loss:0.0022448134980036956\n",
      "train loss:0.00236352566299931\n",
      "train loss:0.002450417096651895\n",
      "train loss:0.002064309283121529\n",
      "train loss:0.002057384781898853\n",
      "train loss:0.001345057318150791\n",
      "train loss:0.00013886049530805738\n",
      "train loss:0.009495290222839809\n",
      "train loss:0.005162234997478355\n",
      "train loss:0.0010301471784164228\n",
      "train loss:0.00572962537874926\n",
      "train loss:0.00032876591178717047\n",
      "train loss:0.0014691492189666266\n",
      "train loss:0.00010243939805600743\n",
      "train loss:0.0012370738347378272\n",
      "train loss:0.0001372118583771413\n",
      "train loss:0.00018122532270371344\n",
      "train loss:2.633015861258521e-05\n",
      "train loss:0.0010149761866262645\n",
      "train loss:0.0013007107721182958\n",
      "train loss:0.0011737905729714807\n",
      "train loss:0.0030462052471340907\n",
      "train loss:0.0018321330731558094\n",
      "train loss:0.021756442560595\n",
      "train loss:0.0009361840056606351\n",
      "train loss:0.00891636473130402\n",
      "train loss:0.0009110361769762407\n",
      "train loss:0.0026548823926941935\n",
      "train loss:0.00012420709946878424\n",
      "train loss:0.0009903746527210916\n",
      "train loss:0.00033429714735137855\n",
      "train loss:0.00020716581428351509\n",
      "train loss:0.004155616259045122\n",
      "train loss:0.00875024375509405\n",
      "train loss:0.0033547818953114\n",
      "train loss:0.00021078708450920848\n",
      "train loss:0.00043711200056117407\n",
      "train loss:0.0010149698480659674\n",
      "train loss:0.0057594771464187875\n",
      "train loss:0.003810247414187039\n",
      "train loss:0.0021442964719689053\n",
      "train loss:0.001988231896519052\n",
      "train loss:0.0017608511786971022\n",
      "train loss:0.005002461139742411\n",
      "train loss:0.00017246599973256497\n",
      "train loss:0.022771137580746514\n",
      "train loss:0.0005524887364624606\n",
      "train loss:0.00029509664150374125\n",
      "train loss:0.007282483947625838\n",
      "train loss:0.001925114822946991\n",
      "train loss:0.003628955076391817\n",
      "train loss:0.006197215278729249\n",
      "train loss:0.003960825176420018\n",
      "train loss:0.0002926069166787905\n",
      "train loss:0.0003922169223007187\n",
      "train loss:0.0003488402287994799\n",
      "train loss:0.010147419996275879\n",
      "train loss:0.007544320883550037\n",
      "train loss:0.005719235138135604\n",
      "train loss:0.0019252946737507348\n",
      "train loss:2.352460125799665e-05\n",
      "train loss:0.006329439715568405\n",
      "train loss:0.004843241688007382\n",
      "train loss:0.0028868910262800944\n",
      "train loss:0.001196473738968562\n",
      "train loss:0.0009285213534042758\n",
      "train loss:0.00028620481611261816\n",
      "train loss:0.01950020581237138\n",
      "train loss:0.000686298654758056\n",
      "train loss:0.005457958647568489\n",
      "train loss:0.0013585002861521748\n",
      "train loss:0.002307462238922187\n",
      "train loss:0.0029108746460857716\n",
      "train loss:0.001963144959888168\n",
      "train loss:0.002592701963797787\n",
      "train loss:0.00038151059931300303\n",
      "train loss:0.004952194726684373\n",
      "train loss:0.0028158111004572294\n",
      "train loss:0.0027516687362301234\n",
      "train loss:0.0003251572100966588\n",
      "train loss:0.0029056055908690615\n",
      "train loss:0.0008925477080396568\n",
      "train loss:0.0010413682253536003\n",
      "train loss:0.00016639616014960584\n",
      "train loss:0.0019372179675102822\n",
      "train loss:0.0037719489280880984\n",
      "train loss:0.0008876957653495236\n",
      "train loss:0.0009281971089665041\n",
      "train loss:0.0005129565275996431\n",
      "train loss:0.0064904833820327865\n",
      "train loss:0.0007401192882113533\n",
      "train loss:0.0006319044948816632\n",
      "train loss:0.0012469042643718357\n",
      "train loss:0.0005776182872873268\n",
      "train loss:0.001164926413719483\n",
      "train loss:0.0010961567820672131\n",
      "train loss:0.00018772657327069365\n",
      "train loss:0.0007489673186907443\n",
      "train loss:0.0027052534080233776\n",
      "train loss:0.0005473595462942845\n",
      "train loss:0.0015926711347844789\n",
      "train loss:9.679745454940647e-05\n",
      "train loss:0.0015626342027068787\n",
      "train loss:0.0030863315808488927\n",
      "train loss:0.0003607082073208781\n",
      "train loss:0.005174213787947436\n",
      "train loss:0.0006694782428118612\n",
      "train loss:0.0010461610386504855\n",
      "train loss:0.0002844445857124478\n",
      "train loss:0.0007270710728610407\n",
      "train loss:0.0011179823718009971\n",
      "train loss:0.001094033413643276\n",
      "train loss:0.000497395661967747\n",
      "train loss:0.00011108855923339095\n",
      "train loss:0.0021399318465059173\n",
      "train loss:0.0021043873203579204\n",
      "train loss:0.0012006045427208718\n",
      "train loss:0.0008041592393895334\n",
      "train loss:0.00013337217351233233\n",
      "train loss:0.0031913318426293456\n",
      "train loss:0.009991133648236939\n",
      "train loss:0.00038507568105220754\n",
      "train loss:0.00011968048159612636\n",
      "train loss:0.0007188039500226743\n",
      "train loss:0.0002700203862465387\n",
      "train loss:0.0022089155627087183\n",
      "train loss:0.0002412060589115761\n",
      "train loss:0.0002701692633031705\n",
      "train loss:0.003659587032025323\n",
      "train loss:0.00012952050055979958\n",
      "train loss:0.002333948744644569\n",
      "train loss:0.0012004908897057188\n",
      "train loss:0.0002048894411440267\n",
      "train loss:0.004109042136086782\n",
      "=== epoch:18, train acc:0.998, test acc:0.988 ===\n",
      "train loss:0.00033182784473589016\n",
      "train loss:0.00036402961933842894\n",
      "train loss:0.00045080647407818225\n",
      "train loss:0.0013882014570931682\n",
      "train loss:0.0009038095323059636\n",
      "train loss:0.000929527663928654\n",
      "train loss:0.0002184281640754487\n",
      "train loss:0.000443638859438265\n",
      "train loss:0.0029734108629214952\n",
      "train loss:0.00044506258474480247\n",
      "train loss:0.00014858110581819005\n",
      "train loss:0.004530592482995487\n",
      "train loss:0.00027178037924501284\n",
      "train loss:0.00015722621861450243\n",
      "train loss:8.709010081581469e-05\n",
      "train loss:0.0012491801619489858\n",
      "train loss:0.005233649356750742\n",
      "train loss:0.0002365641012982562\n",
      "train loss:0.0015736358164697491\n",
      "train loss:0.0001994674097830227\n",
      "train loss:0.012730913580133459\n",
      "train loss:0.0021935423670625775\n",
      "train loss:0.011961976673691182\n",
      "train loss:0.00011493453312266531\n",
      "train loss:0.00019141884798762527\n",
      "train loss:0.00021975910586671167\n",
      "train loss:0.00033349076835808493\n",
      "train loss:0.0016191410530715525\n",
      "train loss:7.669047360024288e-05\n",
      "train loss:0.0033084997353364978\n",
      "train loss:0.000264556605574992\n",
      "train loss:0.00014735102587242735\n",
      "train loss:0.0006873483481723057\n",
      "train loss:0.00205962645689416\n",
      "train loss:0.0014884844696974938\n",
      "train loss:0.0026760889663372377\n",
      "train loss:4.649251415816597e-05\n",
      "train loss:0.0028414924740744417\n",
      "train loss:0.0007425805224968574\n",
      "train loss:0.00017813544212801543\n",
      "train loss:0.0017746660758206543\n",
      "train loss:9.415465553356376e-05\n",
      "train loss:5.209140880724219e-05\n",
      "train loss:0.0037642160693920623\n",
      "train loss:0.0007611027814978783\n",
      "train loss:0.006262304767598382\n",
      "train loss:0.0028957692549215187\n",
      "train loss:0.0006815754563666743\n",
      "train loss:0.0013280800416143846\n",
      "train loss:0.00023967883802559692\n",
      "train loss:0.005383859723261308\n",
      "train loss:0.0008933430129699535\n",
      "train loss:0.0006875768027077568\n",
      "train loss:0.0005425452474361297\n",
      "train loss:0.00010311756676856899\n",
      "train loss:0.00025907288227806723\n",
      "train loss:0.0009415733686092827\n",
      "train loss:0.0008298608643323055\n",
      "train loss:0.0004544589380173162\n",
      "train loss:6.774987097119521e-05\n",
      "train loss:0.00012347586630708234\n",
      "train loss:0.0009765514131884558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009657541275697852\n",
      "train loss:0.000633914158415184\n",
      "train loss:0.00019215534910072004\n",
      "train loss:0.0005655523069983915\n",
      "train loss:0.00020188499651034068\n",
      "train loss:0.007093198486393516\n",
      "train loss:0.00046871598482297\n",
      "train loss:0.00029730228427076995\n",
      "train loss:0.0020490996829266943\n",
      "train loss:0.00022125815588388217\n",
      "train loss:0.0018922076612829936\n",
      "train loss:0.006136220619674277\n",
      "train loss:0.00026259041233632973\n",
      "train loss:0.00012385636970188503\n",
      "train loss:0.0011562467523125682\n",
      "train loss:0.0002690824512112044\n",
      "train loss:0.0022901607297339905\n",
      "train loss:0.005595351631050745\n",
      "train loss:0.0035625347277322807\n",
      "train loss:0.0008460723640791653\n",
      "train loss:0.0016798905546159231\n",
      "train loss:0.0010910434069956575\n",
      "train loss:0.0015401816390599912\n",
      "train loss:0.002075672725058617\n",
      "train loss:0.00320722856132096\n",
      "train loss:0.022877056472850713\n",
      "train loss:0.0002536392573765157\n",
      "train loss:0.0016515998578582275\n",
      "train loss:0.0024753994838951753\n",
      "train loss:0.0011321400242447707\n",
      "train loss:0.0020205225608919317\n",
      "train loss:0.0011693982598055693\n",
      "train loss:0.0028754400555155058\n",
      "train loss:0.0038102641425915695\n",
      "train loss:0.011586998914221696\n",
      "train loss:0.0010137986395090375\n",
      "train loss:0.00315238959101276\n",
      "train loss:0.0019699200337859085\n",
      "train loss:0.002035676558141391\n",
      "train loss:0.0021918100947097606\n",
      "train loss:0.0011346864231911592\n",
      "train loss:0.0010905083564004985\n",
      "train loss:0.010345731064276836\n",
      "train loss:0.001898841036503497\n",
      "train loss:0.0003364113035252588\n",
      "train loss:0.0005918298119934052\n",
      "train loss:0.0005333309631235727\n",
      "train loss:0.0010195144121398054\n",
      "train loss:0.014980555377251577\n",
      "train loss:0.0036342197826552745\n",
      "train loss:0.0034469634685477864\n",
      "train loss:0.0018204720561123705\n",
      "train loss:0.0035243437525546728\n",
      "train loss:0.0004317391992681797\n",
      "train loss:0.003041261220353446\n",
      "train loss:0.004666426273131704\n",
      "train loss:0.012044801608073008\n",
      "train loss:0.0067151218821434044\n",
      "train loss:0.0016920513956880025\n",
      "train loss:0.0007898732510015175\n",
      "train loss:0.003648486206490797\n",
      "train loss:0.03417612374986154\n",
      "train loss:0.0007824097520588375\n",
      "train loss:0.0034679495963090435\n",
      "train loss:7.21319690966697e-05\n",
      "train loss:0.00186173572273402\n",
      "train loss:0.00046558733844399245\n",
      "train loss:0.0007223455198602418\n",
      "train loss:0.0007185778129614224\n",
      "train loss:0.00040846180635077813\n",
      "train loss:0.0017850929042343402\n",
      "train loss:0.0017220390600836543\n",
      "train loss:0.00020851676770172994\n",
      "train loss:0.0008178195946441033\n",
      "train loss:8.200751973084101e-05\n",
      "train loss:0.000326946654162229\n",
      "train loss:0.0009140596849800252\n",
      "train loss:0.00011875296478623241\n",
      "train loss:0.0005222993595203842\n",
      "train loss:0.00013560853725290406\n",
      "train loss:0.00017750414936877867\n",
      "train loss:0.0024722719769455486\n",
      "train loss:0.0032062152314089295\n",
      "train loss:0.0005052006363205287\n",
      "train loss:0.011986983245239481\n",
      "train loss:0.005277068766640553\n",
      "train loss:0.0008679899344346315\n",
      "train loss:0.000254262179559346\n",
      "train loss:0.00045982461991334446\n",
      "train loss:5.072811000335253e-05\n",
      "train loss:0.00043043787493688297\n",
      "train loss:0.0023118322021984366\n",
      "train loss:0.0008958065068035946\n",
      "train loss:0.0024593464490076907\n",
      "train loss:0.00020655605566749055\n",
      "train loss:0.001829011910773648\n",
      "train loss:0.0007796431535388652\n",
      "train loss:0.00011074889361223097\n",
      "train loss:0.01735030847409883\n",
      "train loss:0.00081789490857695\n",
      "train loss:2.935628414891106e-05\n",
      "train loss:0.0013440797597259577\n",
      "train loss:0.0005903491220288278\n",
      "train loss:0.0012486006691471026\n",
      "train loss:0.00012323043474718923\n",
      "train loss:0.00017696249182354168\n",
      "train loss:0.00018894799188287745\n",
      "train loss:0.0030659762765999888\n",
      "train loss:0.0010808193035726857\n",
      "train loss:8.900906811500263e-05\n",
      "train loss:0.0025104809180487324\n",
      "train loss:0.001364141243997028\n",
      "train loss:0.0028508209933509982\n",
      "train loss:0.0003175038323252959\n",
      "train loss:0.0015792496124677907\n",
      "train loss:3.026545644264578e-05\n",
      "train loss:0.00034977846524420397\n",
      "train loss:0.0011105896627138945\n",
      "train loss:0.002172496322858959\n",
      "train loss:0.0002445572471822856\n",
      "train loss:0.0030107453705909117\n",
      "train loss:6.754180278775917e-05\n",
      "train loss:0.0015299364063483636\n",
      "train loss:0.0026710147996579538\n",
      "train loss:0.0009582785194180389\n",
      "train loss:0.013217976894214903\n",
      "train loss:0.0021553413740793793\n",
      "train loss:0.0005628118745677254\n",
      "train loss:0.00045202884268811215\n",
      "train loss:0.015556534589902747\n",
      "train loss:0.00041864727115491316\n",
      "train loss:0.001466881092711873\n",
      "train loss:0.0011246469869708369\n",
      "train loss:2.6001383363064455e-05\n",
      "train loss:0.002127058571562296\n",
      "train loss:0.0003155314929661195\n",
      "train loss:0.0009209088249917337\n",
      "train loss:0.0009315001814633446\n",
      "train loss:0.001512631865864229\n",
      "train loss:0.0006936752639417252\n",
      "train loss:0.00019554787937607347\n",
      "train loss:0.0016762173439567533\n",
      "train loss:0.0015023251333170077\n",
      "train loss:0.0016041534568576815\n",
      "train loss:0.00020926180059526722\n",
      "train loss:0.0033387193735030228\n",
      "train loss:0.002343941463889585\n",
      "train loss:0.00026443146842900883\n",
      "train loss:0.0015260268799428217\n",
      "train loss:0.004586753804350105\n",
      "train loss:0.0022171157600644766\n",
      "train loss:7.330496810687766e-05\n",
      "train loss:0.0008936306361036928\n",
      "train loss:0.001973286518526355\n",
      "train loss:0.004279584500372307\n",
      "train loss:0.00015181299189732423\n",
      "train loss:0.0011927704366831587\n",
      "train loss:0.00021284695419312917\n",
      "train loss:0.0005517886681455144\n",
      "train loss:0.0030051900876596365\n",
      "train loss:0.00047833378316086786\n",
      "train loss:0.0005744663025269497\n",
      "train loss:0.0028135906643809794\n",
      "train loss:0.0009172168714350093\n",
      "train loss:0.0014884722019322177\n",
      "train loss:0.00020569667243091022\n",
      "train loss:0.00011251988105557214\n",
      "train loss:0.00027973255671202466\n",
      "train loss:0.0028141681299795798\n",
      "train loss:3.9244517815731095e-05\n",
      "train loss:0.0017192025303843397\n",
      "train loss:0.0013769549095822959\n",
      "train loss:0.0016666792845859368\n",
      "train loss:8.604566602361349e-05\n",
      "train loss:0.0002930896901302903\n",
      "train loss:0.0018894006410121746\n",
      "train loss:0.0011163450606819097\n",
      "train loss:0.0018746981713466872\n",
      "train loss:0.0002648264733301963\n",
      "train loss:0.00014176341098424535\n",
      "train loss:0.00036037091569090623\n",
      "train loss:0.00018294008396974683\n",
      "train loss:0.00022956084431549547\n",
      "train loss:0.0006631542189288453\n",
      "train loss:0.0007219109447008198\n",
      "train loss:0.001438956464186458\n",
      "train loss:0.0015213538885404901\n",
      "train loss:0.0032260739354844576\n",
      "train loss:0.00301273315857866\n",
      "train loss:0.0033336379287258818\n",
      "train loss:0.00020117567542576778\n",
      "train loss:0.0011268290048245858\n",
      "train loss:0.001196928321756107\n",
      "train loss:0.0006579010656852611\n",
      "train loss:0.0007441468010658575\n",
      "train loss:7.155811143463017e-05\n",
      "train loss:0.0019138611196887092\n",
      "train loss:0.002196696212573597\n",
      "train loss:0.00022131852016852614\n",
      "train loss:0.0004252505416145664\n",
      "train loss:0.0021638912682829118\n",
      "train loss:0.0004691014316585361\n",
      "train loss:0.004841112778221047\n",
      "train loss:0.0001652096998021364\n",
      "train loss:9.687046273619436e-05\n",
      "train loss:0.00034119776293497773\n",
      "train loss:0.0022358600586177653\n",
      "train loss:0.0020159956816948473\n",
      "train loss:0.0034485136400254873\n",
      "train loss:0.0016440865915060803\n",
      "train loss:9.607723555879347e-05\n",
      "train loss:0.0019341005290282696\n",
      "train loss:0.02837563420624182\n",
      "train loss:7.037414818166483e-05\n",
      "train loss:0.00137504530096378\n",
      "train loss:9.629601116047321e-05\n",
      "train loss:0.0002241740784429374\n",
      "train loss:0.0018452948147698672\n",
      "train loss:0.001768809365421402\n",
      "train loss:0.0008017171055304167\n",
      "train loss:0.00046505685526509343\n",
      "train loss:0.0021756215818124584\n",
      "train loss:0.0006833412106698148\n",
      "train loss:0.001372941237485617\n",
      "train loss:0.0022478646483903276\n",
      "train loss:0.0005847342742090855\n",
      "train loss:0.00960671509135173\n",
      "train loss:0.00043237572293223315\n",
      "train loss:0.0001795413895689808\n",
      "train loss:0.0039005794043547163\n",
      "train loss:0.009573040066020914\n",
      "train loss:0.0011343262406745375\n",
      "train loss:0.0004947030050375971\n",
      "train loss:0.0003711961692603989\n",
      "train loss:0.0018040315090268007\n",
      "train loss:0.0033266598706305378\n",
      "train loss:0.00039162740693413805\n",
      "train loss:0.00025340980005787077\n",
      "train loss:0.0012431316229886593\n",
      "train loss:0.0005234795749769596\n",
      "train loss:1.540846006829091e-05\n",
      "train loss:0.00029864433958272027\n",
      "train loss:0.003936971183282528\n",
      "train loss:0.0020315773531907238\n",
      "train loss:0.0008592176377663511\n",
      "train loss:0.0007439401009739518\n",
      "train loss:0.00071378395553316\n",
      "train loss:0.0017756935296408152\n",
      "train loss:0.0001956114633276603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010331758053919672\n",
      "train loss:0.0011252306118334702\n",
      "train loss:0.0025497847315245105\n",
      "train loss:0.00011067583146382904\n",
      "train loss:0.00021575682799152045\n",
      "train loss:0.0015581764828165778\n",
      "train loss:0.0003562767973035017\n",
      "train loss:0.0012856108293555274\n",
      "train loss:0.00043945418791528526\n",
      "train loss:0.0019656873514746417\n",
      "train loss:0.00018019172857714017\n",
      "train loss:0.0008505273176235913\n",
      "train loss:0.00017383019562147096\n",
      "train loss:0.00020063856986176826\n",
      "train loss:0.0002103393378141319\n",
      "train loss:0.0038834900641092425\n",
      "train loss:0.00017091439453843592\n",
      "train loss:0.001731645389351314\n",
      "train loss:0.003789380265149747\n",
      "train loss:0.0002399428981647005\n",
      "train loss:0.0001853319670876227\n",
      "train loss:0.0017259839819434237\n",
      "train loss:0.0011150664410768168\n",
      "train loss:0.00017948863779962117\n",
      "train loss:0.00027853200239677506\n",
      "train loss:0.0022830193149734656\n",
      "train loss:0.0009477801198963035\n",
      "train loss:0.0017214744385027118\n",
      "train loss:0.0002792435443038623\n",
      "train loss:0.000148873230290084\n",
      "train loss:0.00020174424257919478\n",
      "train loss:0.0006050147741477772\n",
      "train loss:0.0003899990104199715\n",
      "train loss:0.0020712984492877694\n",
      "train loss:0.0025301158799520772\n",
      "train loss:3.317628655924719e-05\n",
      "train loss:0.0011803683402421647\n",
      "train loss:8.129277286885296e-05\n",
      "train loss:0.0012727336888173032\n",
      "train loss:0.0027991461776158888\n",
      "train loss:0.00039182751764199787\n",
      "train loss:6.735004629686694e-05\n",
      "train loss:0.0006081208664748709\n",
      "train loss:0.0002074454641439376\n",
      "train loss:0.0002100922598118911\n",
      "train loss:0.001464895341812571\n",
      "train loss:0.0006893280449009315\n",
      "train loss:2.1801897793009454e-05\n",
      "train loss:0.020256061255697642\n",
      "train loss:0.00025382477392835547\n",
      "train loss:0.001675158515452072\n",
      "train loss:0.0005776232941413222\n",
      "train loss:0.0014579560092232724\n",
      "train loss:0.0010402011326954466\n",
      "train loss:0.0004460379591005953\n",
      "train loss:0.00019004906476969508\n",
      "train loss:0.00015345668831253867\n",
      "train loss:0.0013770450928960402\n",
      "train loss:0.008458251714852618\n",
      "train loss:0.00016535190909717837\n",
      "train loss:0.0007339771977908694\n",
      "train loss:0.0005175142940042892\n",
      "train loss:0.00017387577569408637\n",
      "train loss:0.00016288226071637486\n",
      "train loss:0.0036651700467471952\n",
      "train loss:0.0015563620812661088\n",
      "train loss:0.00127971368253907\n",
      "train loss:0.009173600269369073\n",
      "train loss:0.0032579399773944567\n",
      "train loss:0.0021493190345761126\n",
      "train loss:0.005127062098462385\n",
      "train loss:0.0001541669012967783\n",
      "train loss:0.00030585406269612557\n",
      "train loss:0.0004800907223000312\n",
      "train loss:0.005702004971706576\n",
      "train loss:0.012318722656432307\n",
      "train loss:0.0012097390026993716\n",
      "train loss:0.0004205031757516802\n",
      "train loss:0.0016148154957353529\n",
      "train loss:0.0017379059085310964\n",
      "train loss:0.0020511137152805694\n",
      "train loss:0.00192904854496561\n",
      "train loss:0.00014066682026849786\n",
      "train loss:0.0012881908479842003\n",
      "train loss:0.0003775686221869571\n",
      "train loss:0.002964160823848941\n",
      "train loss:0.004936137242478668\n",
      "train loss:0.0003514937373878628\n",
      "train loss:0.00027078047310525303\n",
      "train loss:0.005027993730562635\n",
      "train loss:0.00031828619817223213\n",
      "train loss:0.0001319021816270675\n",
      "train loss:0.0034649657810612313\n",
      "train loss:0.0008175828192125512\n",
      "train loss:0.004138056681541126\n",
      "train loss:0.002816742955560097\n",
      "train loss:0.0009308080581887458\n",
      "train loss:0.0007354067379747981\n",
      "train loss:0.0030552948614671472\n",
      "train loss:0.0015214419453283168\n",
      "train loss:0.000617155626636557\n",
      "train loss:0.005703398104112357\n",
      "train loss:0.00015447762494345346\n",
      "train loss:5.51564834605597e-05\n",
      "train loss:7.633457607625489e-05\n",
      "train loss:1.082664442583012e-05\n",
      "train loss:7.741177876756768e-05\n",
      "train loss:0.00018671703315722925\n",
      "train loss:0.0007617729002553895\n",
      "train loss:0.003042405900681272\n",
      "train loss:0.0003628885708216181\n",
      "train loss:0.00018797414491089008\n",
      "train loss:0.0004472858735254503\n",
      "train loss:0.00047379688732269147\n",
      "train loss:0.00030819671029231054\n",
      "train loss:0.003753971497465843\n",
      "train loss:6.728881828414676e-05\n",
      "train loss:0.0012563720484591778\n",
      "train loss:0.0001718194043366564\n",
      "train loss:0.0003434669131706667\n",
      "train loss:0.0014422498335987693\n",
      "train loss:0.0031469423433984904\n",
      "train loss:0.0005118375277349147\n",
      "train loss:0.0006349516650693568\n",
      "train loss:0.0013360485451759958\n",
      "train loss:0.0005264233982942183\n",
      "train loss:0.0005786994600515002\n",
      "train loss:0.00046562965341923073\n",
      "train loss:0.0005906127666667169\n",
      "train loss:0.0029605438771267735\n",
      "train loss:0.0010423697904694516\n",
      "train loss:0.0002015903505200237\n",
      "train loss:0.0005386430113622764\n",
      "train loss:0.0007660257431986277\n",
      "train loss:0.0013320953023056123\n",
      "train loss:0.0002631598189225932\n",
      "train loss:0.0017030867124162965\n",
      "train loss:0.0005362293109729099\n",
      "train loss:0.001792435298201991\n",
      "train loss:0.0010882153243515326\n",
      "train loss:1.7013792635378768e-05\n",
      "train loss:8.548098224622689e-05\n",
      "train loss:0.00026763569557982264\n",
      "train loss:0.002445994689950748\n",
      "train loss:0.00025348860871182136\n",
      "train loss:0.00014953601950218966\n",
      "train loss:0.0008703164249365164\n",
      "train loss:0.0005335732409825805\n",
      "train loss:3.584063176456744e-05\n",
      "train loss:2.1045397799590065e-05\n",
      "train loss:0.0001661615356425962\n",
      "train loss:0.002166589025759689\n",
      "train loss:0.0007667434214742386\n",
      "train loss:9.932146217518576e-05\n",
      "train loss:0.00017139371194228027\n",
      "train loss:0.002044342018749262\n",
      "train loss:0.0009222941511795828\n",
      "train loss:0.0003957204610593493\n",
      "train loss:0.0003492482789748668\n",
      "train loss:0.0007484120822678994\n",
      "train loss:9.337167895197904e-05\n",
      "train loss:0.0001721327811246187\n",
      "train loss:0.002211652473965229\n",
      "train loss:4.570386223349357e-05\n",
      "train loss:2.2116882875514538e-05\n",
      "train loss:8.239653852770031e-05\n",
      "train loss:0.00028491052272774226\n",
      "train loss:5.9325154029950306e-05\n",
      "train loss:8.193049719438638e-05\n",
      "train loss:0.0005251204425439406\n",
      "train loss:0.002985580725365452\n",
      "train loss:0.00016312226942068054\n",
      "train loss:0.00024182387900749874\n",
      "train loss:0.0025469444457791412\n",
      "train loss:0.0005512788359217377\n",
      "train loss:0.00024761933517973735\n",
      "train loss:0.0001937998172169736\n",
      "train loss:0.00012653011232870056\n",
      "train loss:0.0005363767858954571\n",
      "train loss:0.004606854615524713\n",
      "train loss:0.0018449743782685667\n",
      "train loss:0.0014979493854483286\n",
      "train loss:0.00024214438401957215\n",
      "train loss:0.0004906703272839291\n",
      "train loss:9.420500923392399e-05\n",
      "train loss:3.0638141284314746e-05\n",
      "train loss:0.00018034153856360443\n",
      "train loss:0.0012193878708767136\n",
      "train loss:0.0022298721746296184\n",
      "train loss:8.101760379070283e-05\n",
      "train loss:0.002300006621029262\n",
      "train loss:0.002758127116139198\n",
      "train loss:0.0017082771152001116\n",
      "train loss:0.0028064151908743264\n",
      "train loss:0.0020257292071144566\n",
      "train loss:4.8853096590206646e-05\n",
      "train loss:0.0006305161683669208\n",
      "train loss:0.0012390675896824027\n",
      "train loss:9.333053364903347e-05\n",
      "train loss:0.0008482786698632425\n",
      "train loss:0.0025884989309924024\n",
      "train loss:0.001993326247000796\n",
      "train loss:0.0005325224645737971\n",
      "train loss:0.00023553468589091042\n",
      "train loss:0.003923141743772305\n",
      "train loss:0.0020724836972234083\n",
      "train loss:0.0001640336674113351\n",
      "train loss:0.0015651067456468315\n",
      "train loss:0.002169628671389123\n",
      "train loss:0.00035782594910261457\n",
      "train loss:0.0004518336000377562\n",
      "train loss:0.00038358081008783206\n",
      "train loss:0.0017102321004392124\n",
      "train loss:0.0029902198239752835\n",
      "train loss:0.0002623532382766894\n",
      "train loss:0.0008665455708823564\n",
      "train loss:8.562545127020272e-05\n",
      "train loss:0.00034854601468602814\n",
      "train loss:0.0009210998253856093\n",
      "train loss:0.0015895074553174183\n",
      "train loss:0.00021244614747587443\n",
      "train loss:0.004833450762528297\n",
      "train loss:0.0018627092904269927\n",
      "train loss:4.286829969776456e-05\n",
      "train loss:0.0005858209332173037\n",
      "train loss:0.0007832974804599089\n",
      "train loss:0.0013135895530467885\n",
      "train loss:0.0017440025885690443\n",
      "train loss:7.806195833230237e-05\n",
      "train loss:0.0014350086456694547\n",
      "train loss:0.0010999461706582049\n",
      "train loss:0.0003348440217732468\n",
      "train loss:0.0008525477908350798\n",
      "train loss:6.27783686340711e-05\n",
      "train loss:3.8165197490860496e-05\n",
      "train loss:0.002442930283277211\n",
      "train loss:0.0006920636305957336\n",
      "train loss:5.2142235424772284e-05\n",
      "train loss:0.0013516877972967745\n",
      "train loss:6.333899819746774e-05\n",
      "train loss:0.0008073698758496638\n",
      "train loss:0.0012491833489165025\n",
      "train loss:0.0015475146540890024\n",
      "train loss:0.0045410628555719165\n",
      "train loss:0.0009165649713969145\n",
      "train loss:0.0008850772617613467\n",
      "train loss:0.0009125729422147616\n",
      "train loss:0.0002373216143758159\n",
      "train loss:0.001339782406659158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0005237869717367578\n",
      "train loss:0.0012137663447033577\n",
      "train loss:0.000345595428334606\n",
      "train loss:0.000274491683957673\n",
      "train loss:8.033599116974644e-05\n",
      "train loss:2.038541035695977e-05\n",
      "train loss:0.0002020365379577348\n",
      "train loss:4.88307114561794e-05\n",
      "train loss:0.0015587376489999594\n",
      "train loss:0.002808168365339596\n",
      "train loss:4.6950018480629166e-05\n",
      "train loss:0.0010705982351449004\n",
      "train loss:0.00014820230075923238\n",
      "train loss:0.010163151767921881\n",
      "train loss:0.002394669163245994\n",
      "train loss:0.00012635279032013956\n",
      "train loss:0.00024636753036075027\n",
      "train loss:0.00034574169587382324\n",
      "train loss:8.471081313200591e-05\n",
      "train loss:0.0018083294977843372\n",
      "train loss:0.0011118997955324042\n",
      "train loss:0.0019208261528783476\n",
      "train loss:0.002574451242432943\n",
      "train loss:0.000723381052216296\n",
      "train loss:0.0004992134256051891\n",
      "train loss:0.002045221711121923\n",
      "train loss:0.004186277733954042\n",
      "train loss:0.00024229142661063373\n",
      "train loss:0.0005373562511658603\n",
      "train loss:0.00046109174236437717\n",
      "train loss:0.0005920130833592181\n",
      "train loss:0.00022593993872002408\n",
      "train loss:0.0010510383598398797\n",
      "train loss:0.0015868963162013223\n",
      "train loss:0.0007505803629551265\n",
      "train loss:0.002716007729449279\n",
      "train loss:0.0024156885401216267\n",
      "train loss:0.0014130317743086445\n",
      "train loss:0.00019453667549366684\n",
      "train loss:0.0012622585436918936\n",
      "=== epoch:19, train acc:1.0, test acc:0.983 ===\n",
      "train loss:0.00187466705023767\n",
      "train loss:0.001021817662853922\n",
      "train loss:0.0009911138948531272\n",
      "train loss:5.8544674434555506e-05\n",
      "train loss:0.001155475205975509\n",
      "train loss:0.00021336958419754823\n",
      "train loss:0.00014478612503573884\n",
      "train loss:0.0026185941825210028\n",
      "train loss:0.0005827271893484626\n",
      "train loss:0.001850554025028537\n",
      "train loss:0.0030256341112245688\n",
      "train loss:0.004650314067409405\n",
      "train loss:3.4020286031831856e-05\n",
      "train loss:0.004715752228837835\n",
      "train loss:0.00020866475845112448\n",
      "train loss:0.0006651097503668927\n",
      "train loss:0.000708861980765476\n",
      "train loss:0.0026647991789637265\n",
      "train loss:0.01524550173172036\n",
      "train loss:3.892485020206028e-05\n",
      "train loss:0.0021531030018333203\n",
      "train loss:0.0005929603039418505\n",
      "train loss:0.0029860336271872153\n",
      "train loss:3.593651311548129e-05\n",
      "train loss:0.012037244409183592\n",
      "train loss:0.0017005143313500743\n",
      "train loss:0.0022839068076821855\n",
      "train loss:0.013697022439391904\n",
      "train loss:0.0004152838668527134\n",
      "train loss:0.0003932052609327641\n",
      "train loss:0.0009640442188646012\n",
      "train loss:0.0005404136710915656\n",
      "train loss:0.0011849612276285714\n",
      "train loss:0.0006302935110148657\n",
      "train loss:0.0034644352955743797\n",
      "train loss:0.005961716883090785\n",
      "train loss:0.0014674612775921962\n",
      "train loss:0.0011913091246441895\n",
      "train loss:0.00045719802715937465\n",
      "train loss:0.029277216740436103\n",
      "train loss:0.002046633968812545\n",
      "train loss:0.0003606954476554161\n",
      "train loss:0.0016344352561839407\n",
      "train loss:0.0001766454870507858\n",
      "train loss:0.0006008393407488242\n",
      "train loss:0.0016006887770688497\n",
      "train loss:0.006129130437348423\n",
      "train loss:0.0030057170513630616\n",
      "train loss:0.0067488515019147235\n",
      "train loss:0.0011236958981639417\n",
      "train loss:0.0021270740166023116\n",
      "train loss:3.200410669232013e-05\n",
      "train loss:0.0033348029488923796\n",
      "train loss:0.00021435204952762084\n",
      "train loss:0.00043249895179062447\n",
      "train loss:0.0014908544352298244\n",
      "train loss:0.0005269770820622748\n",
      "train loss:0.001516450105174981\n",
      "train loss:0.0026195940241601655\n",
      "train loss:0.005439444475624634\n",
      "train loss:0.004492638424408555\n",
      "train loss:0.0028846637682029795\n",
      "train loss:0.00026314903074864745\n",
      "train loss:0.003859397199370667\n",
      "train loss:0.002497585455181121\n",
      "train loss:0.0019078034007094932\n",
      "train loss:0.0006719376431646755\n",
      "train loss:0.001547485711870189\n",
      "train loss:0.004591741388859932\n",
      "train loss:0.0016257561783326912\n",
      "train loss:0.0030205789985349933\n",
      "train loss:0.0018543940872426776\n",
      "train loss:0.008885724529609739\n",
      "train loss:0.0014208724922652432\n",
      "train loss:0.0005066150466608336\n",
      "train loss:0.002451396304038329\n",
      "train loss:0.001949787896055408\n",
      "train loss:0.0020970030698540905\n",
      "train loss:0.0012705271456203177\n",
      "train loss:0.00012964558162899148\n",
      "train loss:0.003236098343742701\n",
      "train loss:0.002940540319986136\n",
      "train loss:0.00143247578336482\n",
      "train loss:0.00048170472394066876\n",
      "train loss:6.412681403833835e-05\n",
      "train loss:0.004209119366956095\n",
      "train loss:0.0020820820278748585\n",
      "train loss:0.00121294169177835\n",
      "train loss:0.0007629107256742722\n",
      "train loss:0.0009569251983357455\n",
      "train loss:0.0007914785468481307\n",
      "train loss:0.001020712311216165\n",
      "train loss:0.007496529529100368\n",
      "train loss:0.0032967771088296747\n",
      "train loss:0.0002253182330605513\n",
      "train loss:0.008850791077623986\n",
      "train loss:0.00013158106193099375\n",
      "train loss:0.001057647041927454\n",
      "train loss:0.0006284865412054466\n",
      "train loss:0.009175905449718337\n",
      "train loss:0.00025938159247918175\n",
      "train loss:3.408620565599486e-05\n",
      "train loss:0.002276145541493327\n",
      "train loss:0.00822427314393046\n",
      "train loss:0.0027499890719760943\n",
      "train loss:0.0003809938594341376\n",
      "train loss:0.0017974479968660547\n",
      "train loss:3.07766798951197e-05\n",
      "train loss:0.0008234136315903327\n",
      "train loss:0.00030011620273062955\n",
      "train loss:0.001989711560016723\n",
      "train loss:0.0004118169533194502\n",
      "train loss:0.00016931948026563143\n",
      "train loss:0.001883320051287019\n",
      "train loss:0.0029102105591579065\n",
      "train loss:0.004390295770876045\n",
      "train loss:0.0012542946743496221\n",
      "train loss:0.0011677139830396444\n",
      "train loss:0.0015193302970771202\n",
      "train loss:0.003494118578892853\n",
      "train loss:0.0002607478844295902\n",
      "train loss:5.9858693926005714e-06\n",
      "train loss:0.0017177131918021376\n",
      "train loss:0.0005482351792408759\n",
      "train loss:0.003053375036947864\n",
      "train loss:0.005779253424911349\n",
      "train loss:0.0013628834141089516\n",
      "train loss:0.007275456772893851\n",
      "train loss:0.0011193464294081109\n",
      "train loss:0.016355682488760077\n",
      "train loss:0.0024111521164285337\n",
      "train loss:0.0007189858611265107\n",
      "train loss:0.002125278725221638\n",
      "train loss:0.0018202919826694204\n",
      "train loss:0.0015914898459125132\n",
      "train loss:0.0014405720938953745\n",
      "train loss:0.0010386538887988662\n",
      "train loss:0.0006109600496011754\n",
      "train loss:0.0013565325816600482\n",
      "train loss:0.00024361488461987224\n",
      "train loss:0.0030126859835826344\n",
      "train loss:0.0004160765001626103\n",
      "train loss:0.00052958973081086\n",
      "train loss:0.0026597848409753884\n",
      "train loss:0.00046988996153743043\n",
      "train loss:0.0004700107655126235\n",
      "train loss:6.471832338571657e-05\n",
      "train loss:0.00012579806965691483\n",
      "train loss:0.00016957175570720578\n",
      "train loss:0.0006946126714326234\n",
      "train loss:0.0011742077178426497\n",
      "train loss:0.00011593362619414934\n",
      "train loss:0.0003332189282137122\n",
      "train loss:0.0008958171418886377\n",
      "train loss:0.00012602478551841716\n",
      "train loss:0.008083443248363877\n",
      "train loss:0.00046212231069359436\n",
      "train loss:0.0018291910437475622\n",
      "train loss:0.0034040463891087227\n",
      "train loss:9.728058653074093e-05\n",
      "train loss:0.0001222340895264071\n",
      "train loss:0.0006859312911798732\n",
      "train loss:0.0013539541755680647\n",
      "train loss:0.0013708855567934341\n",
      "train loss:0.0009528314306830235\n",
      "train loss:0.0015349562233724079\n",
      "train loss:0.004125868794621155\n",
      "train loss:0.0030379640799804786\n",
      "train loss:0.0011290765786004823\n",
      "train loss:0.0017341636810226317\n",
      "train loss:0.0007393048191075085\n",
      "train loss:0.0016100780593067974\n",
      "train loss:0.0006922864458985981\n",
      "train loss:0.001245193898944379\n",
      "train loss:6.041053696800507e-05\n",
      "train loss:0.0007141142949304449\n",
      "train loss:0.0038300675693482716\n",
      "train loss:0.0004304042992375308\n",
      "train loss:0.0025186825149276794\n",
      "train loss:0.008696938303591823\n",
      "train loss:0.0006753362381132271\n",
      "train loss:0.0032252461833762896\n",
      "train loss:8.854664177484598e-05\n",
      "train loss:0.001873830296160908\n",
      "train loss:0.002270172273691146\n",
      "train loss:0.0005442423231558237\n",
      "train loss:0.0006078631606798553\n",
      "train loss:0.0035884518661951996\n",
      "train loss:0.00024937345495481503\n",
      "train loss:0.001753581409020965\n",
      "train loss:8.747893208033271e-05\n",
      "train loss:0.003021929125520565\n",
      "train loss:0.004550399476924295\n",
      "train loss:0.00019395787383909836\n",
      "train loss:0.003882488502795203\n",
      "train loss:0.0012452787171054879\n",
      "train loss:0.002039838979455942\n",
      "train loss:0.0016666341551105968\n",
      "train loss:8.937585869559471e-05\n",
      "train loss:0.0011023907251746796\n",
      "train loss:0.00017114075076226883\n",
      "train loss:0.0005378391599844282\n",
      "train loss:0.0001425396591190988\n",
      "train loss:0.00012668699440435951\n",
      "train loss:0.000879220715850057\n",
      "train loss:0.001060996629847088\n",
      "train loss:0.0003288814239661641\n",
      "train loss:0.0014535273302915756\n",
      "train loss:0.00010720481485142693\n",
      "train loss:0.002309566810815367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0008274757576873257\n",
      "train loss:0.00027825432621269024\n",
      "train loss:0.0015437088213243152\n",
      "train loss:0.00016949268299596736\n",
      "train loss:0.003368262515415213\n",
      "train loss:0.001519342069186037\n",
      "train loss:0.001136313729331816\n",
      "train loss:0.017828703958187878\n",
      "train loss:0.0015224543430546423\n",
      "train loss:0.0002755191321889325\n",
      "train loss:0.0004144195829916411\n",
      "train loss:0.003013400914500312\n",
      "train loss:0.0001627268474746044\n",
      "train loss:0.003352280995073217\n",
      "train loss:0.0031113445173416\n",
      "train loss:0.0010652876837886867\n",
      "train loss:0.003521597266551621\n",
      "train loss:0.001454968196756571\n",
      "train loss:0.0007454498658905846\n",
      "train loss:0.006720198936613282\n",
      "train loss:0.0028327897033114404\n",
      "train loss:0.005138938258533129\n",
      "train loss:0.0014330940121072403\n",
      "train loss:0.0004001914208980033\n",
      "train loss:8.499394041655678e-05\n",
      "train loss:0.0001962519034108587\n",
      "train loss:0.00041336878948563437\n",
      "train loss:0.0030629638912631997\n",
      "train loss:0.0007566156792479634\n",
      "train loss:0.0025056219248720713\n",
      "train loss:0.03635890632635083\n",
      "train loss:0.0010839587067001395\n",
      "train loss:0.0024561709474576502\n",
      "train loss:0.00036368291269043104\n",
      "train loss:0.009201379391471304\n",
      "train loss:0.0008670229988954619\n",
      "train loss:0.0036791550986587586\n",
      "train loss:0.001262793968981302\n",
      "train loss:0.011986550717551234\n",
      "train loss:0.0006703005747560158\n",
      "train loss:0.0008351922932058832\n",
      "train loss:0.003593557654995257\n",
      "train loss:0.001425760655921676\n",
      "train loss:0.0001699546131243885\n",
      "train loss:0.0019589566908016502\n",
      "train loss:0.00024496636646213104\n",
      "train loss:0.0006422272485183728\n",
      "train loss:0.0015233332681537251\n",
      "train loss:0.0016278429874880976\n",
      "train loss:4.756357578721786e-05\n",
      "train loss:0.0026208430266760376\n",
      "train loss:0.002561413846034456\n",
      "train loss:0.004976674025043054\n",
      "train loss:0.0036074455006208307\n",
      "train loss:0.003469049164197357\n",
      "train loss:0.0027889214167582583\n",
      "train loss:0.0009585215740688528\n",
      "train loss:0.00022560474986317014\n",
      "train loss:8.820568700865233e-05\n",
      "train loss:0.0019248548951447623\n",
      "train loss:0.001834211799783875\n",
      "train loss:0.001907670455031939\n",
      "train loss:0.000312429379962996\n",
      "train loss:0.0010297315959040133\n",
      "train loss:0.000572365473941232\n",
      "train loss:0.003125101639175872\n",
      "train loss:0.0009236659578247902\n",
      "train loss:0.002113776092230038\n",
      "train loss:0.001197463006789144\n",
      "train loss:0.0004024317145935985\n",
      "train loss:0.0016363714527254096\n",
      "train loss:0.000657100771016655\n",
      "train loss:0.0018342825194366359\n",
      "train loss:0.0034338747630731025\n",
      "train loss:0.0005632350923150192\n",
      "train loss:0.001678295145043006\n",
      "train loss:0.002604459568327147\n",
      "train loss:0.005054250391733821\n",
      "train loss:0.00839317360900698\n",
      "train loss:0.00047354747409388047\n",
      "train loss:0.00028724971440039924\n",
      "train loss:0.0017844645442009546\n",
      "train loss:7.662730836900744e-05\n",
      "train loss:0.0018756159773990436\n",
      "train loss:0.0012727202212014003\n",
      "train loss:0.01050272859951745\n",
      "train loss:0.000131048127903615\n",
      "train loss:0.0030773254010525025\n",
      "train loss:0.004082317543936556\n",
      "train loss:0.00023704651407831194\n",
      "train loss:0.0001296889785130248\n",
      "train loss:5.5862401839944107e-05\n",
      "train loss:0.001850130803471477\n",
      "train loss:0.000592361853226039\n",
      "train loss:0.0029329286122069327\n",
      "train loss:0.00029560648077170653\n",
      "train loss:0.002220529624159342\n",
      "train loss:0.0005150528565935639\n",
      "train loss:0.0008710808509890069\n",
      "train loss:0.004890144015821413\n",
      "train loss:0.0002459598170676166\n",
      "train loss:7.721202813877953e-05\n",
      "train loss:0.005128720597399406\n",
      "train loss:0.0016454487812392038\n",
      "train loss:0.0011247556027318515\n",
      "train loss:0.00014215987312495498\n",
      "train loss:0.00196487148277799\n",
      "train loss:0.0003798806837959918\n",
      "train loss:0.0009429377236632527\n",
      "train loss:0.0004477922559485342\n",
      "train loss:0.004629144359165463\n",
      "train loss:9.799737670639313e-06\n",
      "train loss:0.0002867408843141435\n",
      "train loss:0.0014426881514319515\n",
      "train loss:0.0009591833384015183\n",
      "train loss:0.002572304024722116\n",
      "train loss:0.0019347180644781051\n",
      "train loss:0.0011184708386013228\n",
      "train loss:0.0013488507762811637\n",
      "train loss:0.00036153442204947637\n",
      "train loss:0.001403387696117226\n",
      "train loss:0.0026319796626209668\n",
      "train loss:0.0005150937723528009\n",
      "train loss:0.0012192466680551772\n",
      "train loss:0.000981032510466897\n",
      "train loss:0.0008258159774598541\n",
      "train loss:0.00036518729821352527\n",
      "train loss:0.0070324225032230596\n",
      "train loss:0.0013766919458456847\n",
      "train loss:0.00028779492638810063\n",
      "train loss:0.002708087771186781\n",
      "train loss:0.0005108531518345846\n",
      "train loss:0.025487955689342298\n",
      "train loss:0.006130192849501136\n",
      "train loss:0.0003600787306008624\n",
      "train loss:0.00030631803863574974\n",
      "train loss:0.0006474826738810774\n",
      "train loss:0.005136944626915834\n",
      "train loss:0.0010752957083311919\n",
      "train loss:0.0005226310280459487\n",
      "train loss:0.00040580620593693817\n",
      "train loss:0.0028386001702221803\n",
      "train loss:0.00012277731895076816\n",
      "train loss:0.0003165907287717547\n",
      "train loss:0.0009397830288237469\n",
      "train loss:0.002551620408056043\n",
      "train loss:0.0014418484771401166\n",
      "train loss:0.007423016238260724\n",
      "train loss:0.0001199259018522214\n",
      "train loss:0.006322382931176047\n",
      "train loss:0.010715843775984599\n",
      "train loss:0.0016462166235822501\n",
      "train loss:0.0011442266408550057\n",
      "train loss:3.094087519017985e-05\n",
      "train loss:0.0012672921086605102\n",
      "train loss:0.00012965243049319872\n",
      "train loss:0.011448300027384872\n",
      "train loss:0.0019006856746656194\n",
      "train loss:0.0031748384300513497\n",
      "train loss:0.009244727242109228\n",
      "train loss:0.0020701716623047\n",
      "train loss:0.00048798783753801486\n",
      "train loss:0.00015186080447352862\n",
      "train loss:0.00012092831525036716\n",
      "train loss:0.00028987734897397864\n",
      "train loss:0.0040750007165046825\n",
      "train loss:0.007486161186114174\n",
      "train loss:7.406413492208345e-05\n",
      "train loss:0.0001016427968799985\n",
      "train loss:0.0003842286355511404\n",
      "train loss:5.1775619873025744e-05\n",
      "train loss:0.00510204025873359\n",
      "train loss:8.771329836397593e-05\n",
      "train loss:0.003656485444971233\n",
      "train loss:0.0018974852624151744\n",
      "train loss:0.00011184755555439127\n",
      "train loss:0.0022579943226591053\n",
      "train loss:0.005523227979949094\n",
      "train loss:0.0020000768721175595\n",
      "train loss:0.0009098762397386348\n",
      "train loss:0.0006960998530068462\n",
      "train loss:0.0019159347384919223\n",
      "train loss:0.0027816691084185025\n",
      "train loss:0.0007254997909992561\n",
      "train loss:0.0005538454534436563\n",
      "train loss:0.0011922280396089806\n",
      "train loss:0.0029159989901557004\n",
      "train loss:0.0037252304256545736\n",
      "train loss:0.0004880967999035281\n",
      "train loss:0.0022281697480024875\n",
      "train loss:0.001258685087137297\n",
      "train loss:6.999583440840489e-05\n",
      "train loss:0.00011466387254468642\n",
      "train loss:0.00019778373495267078\n",
      "train loss:0.0006337804165597367\n",
      "train loss:5.783681917827522e-05\n",
      "train loss:1.821666388680541e-05\n",
      "train loss:0.0009944062262392279\n",
      "train loss:0.0004203310894424071\n",
      "train loss:0.0022374679329177534\n",
      "train loss:0.00021123676043723543\n",
      "train loss:0.00018963209121965836\n",
      "train loss:0.0010818382617116904\n",
      "train loss:1.4102916530873189e-05\n",
      "train loss:0.001920052037504246\n",
      "train loss:0.005210064185393676\n",
      "train loss:0.0027774165432746523\n",
      "train loss:0.0005870227158222337\n",
      "train loss:0.0010001256502921254\n",
      "train loss:0.015337464763329199\n",
      "train loss:0.00017353235963547773\n",
      "train loss:0.0001514319349606255\n",
      "train loss:0.0003436522693464175\n",
      "train loss:0.0003227104510504327\n",
      "train loss:0.0006988216184043594\n",
      "train loss:0.0002580986291354518\n",
      "train loss:0.003451274600514502\n",
      "train loss:0.0003077436777348398\n",
      "train loss:0.0003412236412042922\n",
      "train loss:0.0015433192822899607\n",
      "train loss:0.002221362317284345\n",
      "train loss:0.0016240309113487476\n",
      "train loss:0.015073312868608019\n",
      "train loss:0.0005569657364017595\n",
      "train loss:0.00036325720844360333\n",
      "train loss:0.0018912992650874112\n",
      "train loss:2.3688942773713112e-05\n",
      "train loss:0.002253773095802254\n",
      "train loss:0.0025550257286247103\n",
      "train loss:0.0007788012657419336\n",
      "train loss:0.002442807646282877\n",
      "train loss:0.00012038352050972221\n",
      "train loss:0.0002409792288611823\n",
      "train loss:0.003176139184811912\n",
      "train loss:0.0005368950847898809\n",
      "train loss:0.001747035065404619\n",
      "train loss:0.005080675626435524\n",
      "train loss:0.0008224522825923178\n",
      "train loss:0.001799858819344885\n",
      "train loss:0.00046989506113776023\n",
      "train loss:0.001469714647999372\n",
      "train loss:0.0025559046111854637\n",
      "train loss:0.004392495448775875\n",
      "train loss:0.00040633125867962867\n",
      "train loss:9.898129980316528e-05\n",
      "train loss:0.00026790538438415735\n",
      "train loss:0.0008395912724382587\n",
      "train loss:0.002252565388833623\n",
      "train loss:0.00020098484943929383\n",
      "train loss:0.0015006904056794393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00044152592507382837\n",
      "train loss:0.00012332838729382808\n",
      "train loss:0.0026539188111858623\n",
      "train loss:0.00024848236479407\n",
      "train loss:0.02139915217278724\n",
      "train loss:0.011849700848349139\n",
      "train loss:4.613860839296402e-05\n",
      "train loss:0.00190854586826694\n",
      "train loss:0.0003580221384047198\n",
      "train loss:0.00020952975583362243\n",
      "train loss:0.002447975014975789\n",
      "train loss:0.0002479546998557293\n",
      "train loss:0.00026143565802861485\n",
      "train loss:0.00020025544129458696\n",
      "train loss:0.0003883480678757111\n",
      "train loss:8.427272360478114e-05\n",
      "train loss:0.00917819817187446\n",
      "train loss:0.00014135966410432898\n",
      "train loss:0.0027249007868005914\n",
      "train loss:0.0025746134395401034\n",
      "train loss:0.000295330629264989\n",
      "train loss:0.003328974774670354\n",
      "train loss:0.00577644039244447\n",
      "train loss:0.00041293038220372737\n",
      "train loss:0.00234712605659708\n",
      "train loss:0.0009277101032879093\n",
      "train loss:0.00016220109657199462\n",
      "train loss:0.0011940580847498597\n",
      "train loss:0.0008626577094034013\n",
      "train loss:2.4155459305534766e-05\n",
      "train loss:0.0012536402287445924\n",
      "train loss:0.00012931428715540834\n",
      "train loss:0.00043670722779540894\n",
      "train loss:0.003468513750375651\n",
      "train loss:0.0011877874015097643\n",
      "train loss:0.009568689482785723\n",
      "train loss:0.0014855141617398419\n",
      "train loss:0.0048441048250917025\n",
      "train loss:0.0001900366062716691\n",
      "train loss:6.067797822618522e-05\n",
      "train loss:0.00014435045348988243\n",
      "train loss:0.007231414565777131\n",
      "train loss:0.0003808024673445119\n",
      "train loss:6.24416436749454e-05\n",
      "train loss:0.0002679875475144915\n",
      "train loss:0.001011640765095738\n",
      "train loss:0.00109564427479049\n",
      "train loss:0.0040609016451576664\n",
      "train loss:0.001878546989969965\n",
      "train loss:0.0005591499368887627\n",
      "train loss:0.0017077657856241631\n",
      "train loss:0.003045956465693335\n",
      "train loss:0.003353272954523034\n",
      "train loss:0.00013218804158356788\n",
      "train loss:0.0019706993531079394\n",
      "train loss:0.00034514952338998597\n",
      "train loss:0.012105425577158435\n",
      "train loss:0.00362193781523887\n",
      "train loss:0.0018764828241524022\n",
      "train loss:0.0007320974205652681\n",
      "train loss:0.00041856570543076467\n",
      "train loss:0.00024505509080999607\n",
      "train loss:0.014026398197829406\n",
      "train loss:0.0004752911263304919\n",
      "train loss:0.00019401829457464044\n",
      "train loss:2.7531444838239484e-05\n",
      "train loss:0.00013781121847159132\n",
      "train loss:0.00018061537499395648\n",
      "train loss:0.0036161736475268315\n",
      "train loss:0.0020990978128808723\n",
      "train loss:0.00016662562888858866\n",
      "train loss:0.00031097299758516103\n",
      "train loss:0.0013151602140955181\n",
      "train loss:0.0010754631480404274\n",
      "train loss:0.0003364329025821665\n",
      "train loss:0.0026402836753688062\n",
      "train loss:0.0005510774002516045\n",
      "train loss:0.0005341011285706414\n",
      "train loss:0.006493566785533891\n",
      "train loss:0.002259268835314197\n",
      "train loss:0.000603009760193056\n",
      "train loss:0.008509029951867593\n",
      "train loss:0.000896943932926625\n",
      "train loss:0.0007939103989657838\n",
      "train loss:0.0002864392759389526\n",
      "train loss:9.532599936444428e-05\n",
      "train loss:0.0012877922448938856\n",
      "train loss:0.0008606594931060113\n",
      "train loss:0.0037640696555161866\n",
      "train loss:0.0017077043372920803\n",
      "train loss:0.002940370300518245\n",
      "train loss:0.00222037363442683\n",
      "train loss:0.0024874733466552293\n",
      "train loss:0.0011783440985364889\n",
      "train loss:0.0001322023085034421\n",
      "train loss:0.0010690657437381556\n",
      "train loss:0.005833386564698269\n",
      "train loss:0.004853231340621239\n",
      "train loss:0.0001699394201467512\n",
      "train loss:6.593120705815432e-05\n",
      "train loss:0.0017704726573449458\n",
      "train loss:0.001178169469887383\n",
      "train loss:0.00016891564967169714\n",
      "train loss:0.0029902669062523753\n",
      "train loss:0.0018998932717383212\n",
      "train loss:0.0001773961943713061\n",
      "train loss:0.0005397446322139383\n",
      "train loss:0.0009932866350825464\n",
      "train loss:0.0010653991205340008\n",
      "train loss:0.001583831408102638\n",
      "train loss:0.0035623937636223265\n",
      "train loss:0.01346704913128121\n",
      "train loss:8.083025485181134e-05\n",
      "train loss:3.473026211665996e-05\n",
      "train loss:0.00028510978119277277\n",
      "train loss:0.0001535071992225102\n",
      "train loss:0.0012980341661901467\n",
      "train loss:0.00017325744339402084\n",
      "train loss:0.0009816618546154927\n",
      "train loss:0.00042928186459822195\n",
      "train loss:9.680334181035701e-05\n",
      "train loss:0.003498496019511707\n",
      "train loss:0.0003368223283254882\n",
      "train loss:0.00047410081284287794\n",
      "train loss:0.0036474393553762264\n",
      "train loss:0.0026832854102288506\n",
      "train loss:0.0025212334083430515\n",
      "train loss:0.006493682201286478\n",
      "train loss:0.0016935909931238627\n",
      "train loss:0.0035456976049600014\n",
      "train loss:0.0010903219978075278\n",
      "train loss:0.0030852584989705355\n",
      "train loss:7.505621416122781e-05\n",
      "train loss:0.0020823903110746313\n",
      "train loss:0.005654057137608696\n",
      "train loss:0.0008823659682866363\n",
      "train loss:0.0043969318766032585\n",
      "train loss:0.00010383719553785751\n",
      "train loss:0.0015109295169497467\n",
      "train loss:0.00017370609239834934\n",
      "=== epoch:20, train acc:0.999, test acc:0.985 ===\n",
      "train loss:0.0024120204348467927\n",
      "train loss:0.00022446504642216868\n",
      "train loss:0.00024366294583326985\n",
      "train loss:0.001444950334548528\n",
      "train loss:0.0013888638273212523\n",
      "train loss:0.0016693391115192848\n",
      "train loss:0.000320429530986419\n",
      "train loss:0.0007759187693027326\n",
      "train loss:2.2557257837622215e-05\n",
      "train loss:0.01028007904845334\n",
      "train loss:0.0001254911254239791\n",
      "train loss:0.0007408417913744046\n",
      "train loss:0.0001139924888993317\n",
      "train loss:0.00026361551142848575\n",
      "train loss:8.78246288665654e-05\n",
      "train loss:8.404484719110537e-05\n",
      "train loss:0.0005766291954387043\n",
      "train loss:0.0017969773513703668\n",
      "train loss:0.0005489747576644057\n",
      "train loss:0.003098536937276934\n",
      "train loss:0.00046555577963797753\n",
      "train loss:0.0010779378480359559\n",
      "train loss:0.00041628589236544376\n",
      "train loss:0.004842972061239059\n",
      "train loss:9.667293319957945e-05\n",
      "train loss:0.00021325557309648905\n",
      "train loss:2.619676777667446e-05\n",
      "train loss:0.000663348287642996\n",
      "train loss:0.0015119682390450117\n",
      "train loss:0.00022329857692765374\n",
      "train loss:0.0007385422361083187\n",
      "train loss:1.1072843384593127e-05\n",
      "train loss:0.0017511847465727824\n",
      "train loss:0.00032334968645999026\n",
      "train loss:9.037208024128605e-05\n",
      "train loss:0.00020051331682723666\n",
      "train loss:0.0016149722592435681\n",
      "train loss:0.019948609497893774\n",
      "train loss:0.0013558298859821802\n",
      "train loss:0.0016285618321361056\n",
      "train loss:0.0005118933157283059\n",
      "train loss:0.006580650897985863\n",
      "train loss:0.0015403525157579399\n",
      "train loss:2.7121726563142943e-05\n",
      "train loss:0.00018849714084056985\n",
      "train loss:0.00021867049662833388\n",
      "train loss:0.0014144036481431718\n",
      "train loss:0.0006823861576884358\n",
      "train loss:0.0021085180184873967\n",
      "train loss:0.00034900031295667926\n",
      "train loss:0.0008861629323524814\n",
      "train loss:0.0004151837973661163\n",
      "train loss:0.0011125933447918661\n",
      "train loss:0.0004921626969084054\n",
      "train loss:0.00016734176368306532\n",
      "train loss:0.004163508198596563\n",
      "train loss:0.0019228941592294344\n",
      "train loss:0.0002265991344069316\n",
      "train loss:0.00014491369223702214\n",
      "train loss:0.00023436990229753842\n",
      "train loss:0.005901611245427472\n",
      "train loss:0.0003876029145553137\n",
      "train loss:0.0021879089492655326\n",
      "train loss:0.0014876139949498149\n",
      "train loss:0.00044281656948506914\n",
      "train loss:5.5252474489766934e-05\n",
      "train loss:0.00019220879066306887\n",
      "train loss:0.01721753943247597\n",
      "train loss:0.00013151444985375408\n",
      "train loss:0.0003651513609275315\n",
      "train loss:0.0008643811365496325\n",
      "train loss:0.00010552902099213818\n",
      "train loss:0.00014217810553086307\n",
      "train loss:0.000582576499492639\n",
      "train loss:0.000924368016389982\n",
      "train loss:0.0016709497592261172\n",
      "train loss:0.0012399939123258585\n",
      "train loss:0.0014359006091517882\n",
      "train loss:0.0008058675910969347\n",
      "train loss:0.0019147131454866843\n",
      "train loss:0.00036515031599004295\n",
      "train loss:0.00037177609446408763\n",
      "train loss:0.004218569183279396\n",
      "train loss:1.6909537164956213e-05\n",
      "train loss:0.0057250826429449475\n",
      "train loss:0.0002687399893625522\n",
      "train loss:2.0867201597472018e-05\n",
      "train loss:0.000803532762547656\n",
      "train loss:0.0020233980153677496\n",
      "train loss:0.001510578595157892\n",
      "train loss:0.0002445987652503945\n",
      "train loss:0.0010331706471205092\n",
      "train loss:3.667945896962985e-05\n",
      "train loss:0.0004914619132870142\n",
      "train loss:0.00020451045289374115\n",
      "train loss:0.001587508015433372\n",
      "train loss:0.0008351542466975523\n",
      "train loss:0.0018335829949096658\n",
      "train loss:0.0003518713579520299\n",
      "train loss:0.00029279369668917555\n",
      "train loss:0.00014508870625683926\n",
      "train loss:0.005643938862884009\n",
      "train loss:0.0006934007472915891\n",
      "train loss:3.167070058565228e-05\n",
      "train loss:0.003740167022132967\n",
      "train loss:0.0020475069196364353\n",
      "train loss:0.0002488385397599536\n",
      "train loss:0.003237591112153083\n",
      "train loss:0.00012870796149499794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006429568403377939\n",
      "train loss:0.00010879681872360952\n",
      "train loss:0.00038526002056967607\n",
      "train loss:0.000408178277478003\n",
      "train loss:0.0010688215290277385\n",
      "train loss:0.003490317816327643\n",
      "train loss:7.932051706119596e-05\n",
      "train loss:0.00038639695453069825\n",
      "train loss:0.0040723254195348295\n",
      "train loss:0.0009857277443193692\n",
      "train loss:0.0003256469103827564\n",
      "train loss:0.005932820078370987\n",
      "train loss:0.0007413159503955015\n",
      "train loss:0.001869217657271575\n",
      "train loss:6.543780898268266e-05\n",
      "train loss:0.000626853278283771\n",
      "train loss:0.0031686893418335325\n",
      "train loss:5.040335873991184e-05\n",
      "train loss:0.0019388249391201215\n",
      "train loss:0.0038313971226461786\n",
      "train loss:0.00035950019573522556\n",
      "train loss:0.023193125754233747\n",
      "train loss:0.0006219964352496355\n",
      "train loss:0.0007561850967117977\n",
      "train loss:0.00028187670329219447\n",
      "train loss:0.0002413066183497329\n",
      "train loss:0.0007002301690738513\n",
      "train loss:0.0007587468657056963\n",
      "train loss:4.4745020067953e-05\n",
      "train loss:0.0015958301324444733\n",
      "train loss:0.0013377620582784163\n",
      "train loss:0.0007334262197392485\n",
      "train loss:7.827940734340375e-05\n",
      "train loss:1.5358278308950644e-05\n",
      "train loss:0.006143698663169416\n",
      "train loss:0.00011373611880823405\n",
      "train loss:0.004474960274331436\n",
      "train loss:0.0015245153469209006\n",
      "train loss:0.0007327379509531507\n",
      "train loss:9.778668228125531e-05\n",
      "train loss:0.0003000884302692707\n",
      "train loss:0.0011454368093081453\n",
      "train loss:0.00019704414308203432\n",
      "train loss:0.0002653945017861581\n",
      "train loss:0.006421715909424256\n",
      "train loss:0.00016163665590309903\n",
      "train loss:0.0008360822808785132\n",
      "train loss:0.0010498688104985656\n",
      "train loss:0.0021432052677595893\n",
      "train loss:0.00013947050648359933\n",
      "train loss:0.0011021092608255161\n",
      "train loss:0.0004970557746035787\n",
      "train loss:0.0034339441039190934\n",
      "train loss:0.002014990562702136\n",
      "train loss:0.0006589232436133645\n",
      "train loss:0.00024175199746403353\n",
      "train loss:0.0004392081883150678\n",
      "train loss:0.0018691706762349386\n",
      "train loss:0.0007965331647901756\n",
      "train loss:2.1173024994637404e-05\n",
      "train loss:2.5635066518303775e-05\n",
      "train loss:0.0005722879175264176\n",
      "train loss:5.872713839849405e-05\n",
      "train loss:0.00031995677483353987\n",
      "train loss:0.00019278907201035318\n",
      "train loss:0.000626364151952882\n",
      "train loss:0.0005892479344750209\n",
      "train loss:1.1927454339134712e-05\n",
      "train loss:0.00016490894329423443\n",
      "train loss:0.0016438688327481746\n",
      "train loss:0.0002573884263039882\n",
      "train loss:0.0010864643100750178\n",
      "train loss:0.0009334605140919237\n",
      "train loss:0.0005700184037435985\n",
      "train loss:0.0001611029922230698\n",
      "train loss:0.00028112902241725997\n",
      "train loss:0.0005085158809620425\n",
      "train loss:0.0004948635986927689\n",
      "train loss:0.006392118852156113\n",
      "train loss:0.0007033103707039316\n",
      "train loss:0.002049035922139346\n",
      "train loss:0.0011838668538195732\n",
      "train loss:0.0014555939577178267\n",
      "train loss:0.0003468940402672025\n",
      "train loss:0.0012187954375037164\n",
      "train loss:0.0002536842805743222\n",
      "train loss:0.0010460389485371906\n",
      "train loss:0.0002046736252869255\n",
      "train loss:0.0047499901368233885\n",
      "train loss:0.0004744313953303395\n",
      "train loss:9.8556863390979e-05\n",
      "train loss:0.002558484742342388\n",
      "train loss:0.00207087373973504\n",
      "train loss:0.0001891885640043178\n",
      "train loss:0.0005249034219451042\n",
      "train loss:0.0036394678828840926\n",
      "train loss:0.00042878989906203484\n",
      "train loss:0.01669072400082324\n",
      "train loss:0.0025523943067895342\n",
      "train loss:0.0003670247665778866\n",
      "train loss:0.001902951523972968\n",
      "train loss:0.006792241630734131\n",
      "train loss:0.002356310869125376\n",
      "train loss:0.00012846460910463794\n",
      "train loss:0.028459598073472415\n",
      "train loss:0.0002604746592106726\n",
      "train loss:0.0024625594695280176\n",
      "train loss:0.0019678099612989\n",
      "train loss:4.358307195076516e-05\n",
      "train loss:0.0003229924093756915\n",
      "train loss:8.596367437814122e-05\n",
      "train loss:0.007688095659671499\n",
      "train loss:0.0015743678749708559\n",
      "train loss:0.0003928059030866718\n",
      "train loss:0.017080428841759768\n",
      "train loss:8.291652261146511e-05\n",
      "train loss:1.843114665541083e-05\n",
      "train loss:0.0011054188562829757\n",
      "train loss:0.0017143576076283698\n",
      "train loss:0.00027133209742297425\n",
      "train loss:0.00029253097465112846\n",
      "train loss:0.00546534334524218\n",
      "train loss:0.00012925517244185577\n",
      "train loss:0.0011028588011265758\n",
      "train loss:0.000913224169825059\n",
      "train loss:0.0012263194717423217\n",
      "train loss:0.00017735918622213985\n",
      "train loss:7.453354851215425e-05\n",
      "train loss:0.0034047600191419985\n",
      "train loss:0.0014878349570063276\n",
      "train loss:0.0003333863378927191\n",
      "train loss:0.00017052132529396177\n",
      "train loss:0.020552221039499212\n",
      "train loss:0.0011582234948467932\n",
      "train loss:0.0003715553650634116\n",
      "train loss:4.8395582040485395e-05\n",
      "train loss:0.0047780349460678825\n",
      "train loss:0.0005194362372462247\n",
      "train loss:0.0016423470656535418\n",
      "train loss:0.0007660338669303109\n",
      "train loss:0.0005819454835500491\n",
      "train loss:0.00029603256220902006\n",
      "train loss:0.00042698451256078\n",
      "train loss:0.0010881934161717025\n",
      "train loss:9.344771612811188e-05\n",
      "train loss:0.0014590724249866785\n",
      "train loss:0.008103353249536463\n",
      "train loss:0.0001007258568187498\n",
      "train loss:0.0003961318596803623\n",
      "train loss:0.0009226929492946656\n",
      "train loss:0.0015274998303699528\n",
      "train loss:0.0013501234741308279\n",
      "train loss:0.012803786270990658\n",
      "train loss:0.0022688697218318237\n",
      "train loss:0.002378819332706761\n",
      "train loss:0.0007855921571341371\n",
      "train loss:0.000409424245128449\n",
      "train loss:0.001640216675935574\n",
      "train loss:0.00024195384386463203\n",
      "train loss:0.0006285839215121954\n",
      "train loss:0.0017663752667963955\n",
      "train loss:0.003798317483950904\n",
      "train loss:0.0022489384087130567\n",
      "train loss:0.003820427829226403\n",
      "train loss:0.0032562142447269183\n",
      "train loss:0.006134516392713177\n",
      "train loss:0.0008144730284295237\n",
      "train loss:0.00014505140168426857\n",
      "train loss:0.0001422398835969581\n",
      "train loss:9.433698284875253e-06\n",
      "train loss:0.0002541561878511535\n",
      "train loss:0.002032855895723478\n",
      "train loss:0.001865041566555563\n",
      "train loss:0.00017774323306241196\n",
      "train loss:0.0010177511498351964\n",
      "train loss:0.0005515772931627002\n",
      "train loss:0.0013987958688553648\n",
      "train loss:0.0017509033647269356\n",
      "train loss:0.0009298392992228206\n",
      "train loss:0.0014229250005149505\n",
      "train loss:0.0016413649008620136\n",
      "train loss:0.0005597174158042836\n",
      "train loss:0.0003780215265072682\n",
      "train loss:0.0003188222999673752\n",
      "train loss:0.00026693433175048334\n",
      "train loss:0.00034371569875859555\n",
      "train loss:7.058433997082317e-05\n",
      "train loss:0.00872937502394894\n",
      "train loss:0.0018124426153123747\n",
      "train loss:0.0018870284211297964\n",
      "train loss:0.00025256368509997266\n",
      "train loss:0.0002131692767713332\n",
      "train loss:0.0007183426832142632\n",
      "train loss:6.044245661696915e-05\n",
      "train loss:0.00016850434136388856\n",
      "train loss:0.0031231704749783767\n",
      "train loss:0.0003732603972003381\n",
      "train loss:0.002009094317114169\n",
      "train loss:0.0007433909498351628\n",
      "train loss:0.001626291843350898\n",
      "train loss:0.0013532655673482018\n",
      "train loss:0.01613204063302717\n",
      "train loss:0.0009347569909497033\n",
      "train loss:0.00183749834930514\n",
      "train loss:8.74296463984173e-05\n",
      "train loss:0.002432667258540205\n",
      "train loss:0.00018118969651977225\n",
      "train loss:0.0018751698630790359\n",
      "train loss:0.0007425405512360046\n",
      "train loss:0.00021446121536754733\n",
      "train loss:0.0007467689784356695\n",
      "train loss:0.0001576825611630419\n",
      "train loss:8.51195044993903e-05\n",
      "train loss:4.245394296821476e-05\n",
      "train loss:0.0002512029116989982\n",
      "train loss:0.0025372105579931793\n",
      "train loss:0.00047250551527758494\n",
      "train loss:0.0014605367319159338\n",
      "train loss:0.00030731262159508667\n",
      "train loss:0.000947456483291777\n",
      "train loss:7.826850076350533e-05\n",
      "train loss:0.004342265490677735\n",
      "train loss:0.0016578033771532325\n",
      "train loss:0.00011007957309995641\n",
      "train loss:0.004515705035374529\n",
      "train loss:0.001211361895853781\n",
      "train loss:0.001224509449993811\n",
      "train loss:0.00027592604090870276\n",
      "train loss:7.028709504566746e-06\n",
      "train loss:0.0008593638514323398\n",
      "train loss:0.034891638254683346\n",
      "train loss:0.00013244414128058527\n",
      "train loss:4.462108022613782e-05\n",
      "train loss:0.00048695888168174634\n",
      "train loss:0.0008936840242737451\n",
      "train loss:0.0003285736643260572\n",
      "train loss:0.0005831787074648586\n",
      "train loss:0.002042887677968242\n",
      "train loss:0.0003859998245464137\n",
      "train loss:0.0007584528402505869\n",
      "train loss:0.0001224096466045221\n",
      "train loss:0.00020671941161514885\n",
      "train loss:0.0019639689955943166\n",
      "train loss:0.000838471685004781\n",
      "train loss:0.0063085295323285625\n",
      "train loss:0.00026725624347918327\n",
      "train loss:0.00030372304740555934\n",
      "train loss:0.0013450915795082845\n",
      "train loss:0.001002909075223178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0012575402359686213\n",
      "train loss:0.000698277014308734\n",
      "train loss:0.00016123192051365005\n",
      "train loss:0.0003294242640458054\n",
      "train loss:0.0007618484991294054\n",
      "train loss:0.00015376393025758061\n",
      "train loss:0.00021621993950046004\n",
      "train loss:0.0003973985555794158\n",
      "train loss:0.0009628657985397298\n",
      "train loss:5.5594891150391866e-05\n",
      "train loss:7.504452098799856e-05\n",
      "train loss:0.00017795204249442605\n",
      "train loss:0.002112692660170543\n",
      "train loss:0.0003627062861828817\n",
      "train loss:0.00012457025137863973\n",
      "train loss:0.0008525553277071935\n",
      "train loss:0.0024322060423610896\n",
      "train loss:0.0001850106366334217\n",
      "train loss:0.0012841448381032893\n",
      "train loss:0.0009542456044282434\n",
      "train loss:0.0015471810623390342\n",
      "train loss:0.0016118890800689038\n",
      "train loss:0.0008174386190366839\n",
      "train loss:0.0019073630331813045\n",
      "train loss:0.0014527604508357875\n",
      "train loss:0.00017633487025598343\n",
      "train loss:6.559032704565615e-05\n",
      "train loss:0.002083713016273064\n",
      "train loss:0.00044594871947720486\n",
      "train loss:0.0005603098197732153\n",
      "train loss:0.00020751188243491706\n",
      "train loss:0.0002919090465677153\n",
      "train loss:0.0002467407341790226\n",
      "train loss:4.0181205820208004e-05\n",
      "train loss:0.0021942703766435387\n",
      "train loss:0.00041080956289019565\n",
      "train loss:0.00022666958776827964\n",
      "train loss:0.005153454847534476\n",
      "train loss:0.0007797858756084769\n",
      "train loss:0.006479222045851592\n",
      "train loss:0.0017090237526809966\n",
      "train loss:0.0011907352244170588\n",
      "train loss:0.0001425491132330495\n",
      "train loss:0.00033337234352941294\n",
      "train loss:0.0002397581736843403\n",
      "train loss:0.0021054060971166326\n",
      "train loss:0.002772168032703251\n",
      "train loss:0.0015200519547256246\n",
      "train loss:0.0022881155797944723\n",
      "train loss:0.0004790143164207959\n",
      "train loss:0.0001469759818679323\n",
      "train loss:0.0003130344845340604\n",
      "train loss:0.0008144659571617406\n",
      "train loss:6.722996045389751e-05\n",
      "train loss:0.00019249063202539198\n",
      "train loss:0.000700586241947828\n",
      "train loss:0.0007500677427273538\n",
      "train loss:0.0006003697852580916\n",
      "train loss:0.000939273166593985\n",
      "train loss:0.00035519008905609146\n",
      "train loss:0.00037829336290519546\n",
      "train loss:4.7826985945582324e-05\n",
      "train loss:1.7244941251355167e-05\n",
      "train loss:0.0014100556350823462\n",
      "train loss:0.00017200471820549197\n",
      "train loss:5.2021808966254385e-05\n",
      "train loss:0.0020157190904117436\n",
      "train loss:7.061727595932922e-05\n",
      "train loss:0.0003763688089353581\n",
      "train loss:0.00012176195579380242\n",
      "train loss:0.0011526286477650765\n",
      "train loss:0.002292485309733526\n",
      "train loss:0.00015813567579244563\n",
      "train loss:5.56042186118845e-05\n",
      "train loss:0.0006751306400150153\n",
      "train loss:0.002489864780099712\n",
      "train loss:0.0008086980675355704\n",
      "train loss:0.0012844593031958703\n",
      "train loss:0.00037508292366868656\n",
      "train loss:0.0013161363620486845\n",
      "train loss:6.175228211254455e-05\n",
      "train loss:0.001723287288882164\n",
      "train loss:1.2414330085275174e-05\n",
      "train loss:0.0005866336872457972\n",
      "train loss:8.461002109075197e-05\n",
      "train loss:0.0006360695456378731\n",
      "train loss:0.0014840596140259172\n",
      "train loss:0.0011502263762965057\n",
      "train loss:0.00018541861675446718\n",
      "train loss:0.0006430584163889614\n",
      "train loss:0.0018912176654306636\n",
      "train loss:0.0016988234054234178\n",
      "train loss:3.7265739549312784e-05\n",
      "train loss:0.00016469851218374343\n",
      "train loss:0.0009499537313491038\n",
      "train loss:0.0002928754566273803\n",
      "train loss:0.0007256637795399523\n",
      "train loss:0.00015069752186516717\n",
      "train loss:9.228772752448484e-06\n",
      "train loss:0.00014685900382806972\n",
      "train loss:0.011416611266711937\n",
      "train loss:0.0008234832303708835\n",
      "train loss:0.0003068647280922513\n",
      "train loss:0.0018507459120985104\n",
      "train loss:0.00029200564404997245\n",
      "train loss:0.0009022729736477913\n",
      "train loss:0.0023831328192285357\n",
      "train loss:0.001228454880829559\n",
      "train loss:0.0009375714339669816\n",
      "train loss:0.001485928929806253\n",
      "train loss:0.00029187043244083093\n",
      "train loss:0.001594479086180173\n",
      "train loss:0.004311396700427894\n",
      "train loss:0.0010065977139960026\n",
      "train loss:0.00033038615432942305\n",
      "train loss:0.0003476042795902596\n",
      "train loss:0.00035990759599653546\n",
      "train loss:0.0008796472018039925\n",
      "train loss:0.0005001534912525109\n",
      "train loss:0.000344958031473785\n",
      "train loss:7.400278173064827e-05\n",
      "train loss:7.644752218261352e-05\n",
      "train loss:0.00013140133897541424\n",
      "train loss:0.00015088176505368315\n",
      "train loss:0.0006293706530850371\n",
      "train loss:0.0008992600296170662\n",
      "train loss:0.022628558399837444\n",
      "train loss:0.0012048568342282278\n",
      "train loss:0.0013202359073759807\n",
      "train loss:0.0001576522972347902\n",
      "train loss:0.00014673669501198244\n",
      "train loss:0.0001347367545329532\n",
      "train loss:0.0017550488026028968\n",
      "train loss:0.002541069586142976\n",
      "train loss:0.0060670207047122\n",
      "train loss:8.86477376294161e-05\n",
      "train loss:0.0008256107446870554\n",
      "train loss:0.00026553021704005123\n",
      "train loss:8.740448864966257e-05\n",
      "train loss:0.002116416075833003\n",
      "train loss:0.0013667259326614431\n",
      "train loss:0.000172036633823051\n",
      "train loss:0.00010073840203288536\n",
      "train loss:3.688450848342485e-05\n",
      "train loss:6.89104353574999e-05\n",
      "train loss:0.00013763589887420602\n",
      "train loss:0.0005071183994621264\n",
      "train loss:0.004298952494522747\n",
      "train loss:0.0035664780202948904\n",
      "train loss:0.00019308112141815873\n",
      "train loss:0.0020584917912742536\n",
      "train loss:0.0007433084150758895\n",
      "train loss:0.0007655312748384461\n",
      "train loss:0.0018924988175464052\n",
      "train loss:0.000715298801733587\n",
      "train loss:0.001067862584586995\n",
      "train loss:0.000961370229656027\n",
      "train loss:0.0009483711958480369\n",
      "train loss:0.000763258755140448\n",
      "train loss:0.00025869390189161635\n",
      "train loss:0.0014883702601511137\n",
      "train loss:0.00018734712689038205\n",
      "train loss:0.001981094184937\n",
      "train loss:0.000890943908853223\n",
      "train loss:0.00025828089590038816\n",
      "train loss:0.002419211902069906\n",
      "train loss:0.002157805721293832\n",
      "train loss:0.005099823445280174\n",
      "train loss:0.0019877389167809773\n",
      "train loss:0.0003710991522752969\n",
      "train loss:3.0350965925979737e-05\n",
      "train loss:0.007057599353114144\n",
      "train loss:0.0004955606741159949\n",
      "train loss:0.03903722674867707\n",
      "train loss:0.00013066173592761948\n",
      "train loss:0.00017200333016992482\n",
      "train loss:4.267878209194229e-05\n",
      "train loss:0.0005345847379898991\n",
      "train loss:0.0009654787113009042\n",
      "train loss:6.684154535089165e-05\n",
      "train loss:3.422972718494273e-05\n",
      "train loss:0.0004374085153981009\n",
      "train loss:0.00010605422631979766\n",
      "train loss:0.0007450831996313023\n",
      "train loss:0.005448335638340585\n",
      "train loss:0.00011507296237116752\n",
      "train loss:0.0019097921367164606\n",
      "train loss:0.005923093415978618\n",
      "train loss:0.00014478927946061528\n",
      "train loss:0.00010997964215278604\n",
      "train loss:0.0029143249917907756\n",
      "train loss:0.00021612415143030844\n",
      "train loss:9.192050178753798e-05\n",
      "train loss:6.0954277636150824e-05\n",
      "train loss:0.0021767922237992156\n",
      "train loss:0.0010245512220197314\n",
      "train loss:0.0034151517519458038\n",
      "train loss:0.004178192310734444\n",
      "train loss:0.0011747815045827466\n",
      "train loss:9.298120685451156e-05\n",
      "train loss:8.652062583895682e-05\n",
      "train loss:0.0006586532596616677\n",
      "train loss:0.0006767445673840335\n",
      "train loss:5.690339609424239e-05\n",
      "train loss:0.009818891792913655\n",
      "train loss:0.00045830501727235016\n",
      "train loss:0.0003584765182425544\n",
      "train loss:0.00010193099625006882\n",
      "train loss:0.0014071766308987974\n",
      "train loss:0.0012450387798307516\n",
      "train loss:0.0004943954402548258\n",
      "train loss:2.9244816917451975e-05\n",
      "train loss:0.0038520526766998727\n",
      "train loss:0.0007271316814864063\n",
      "train loss:0.002267713801133476\n",
      "train loss:0.001520211232128453\n",
      "train loss:0.0002888821811002997\n",
      "train loss:0.0011501649100265794\n",
      "train loss:8.929514038438248e-05\n",
      "train loss:0.0002890928471438191\n",
      "train loss:0.0013848058421839077\n",
      "train loss:0.009424853845569273\n",
      "train loss:0.00038746364553549957\n",
      "train loss:0.0012643191949512095\n",
      "train loss:0.00619833852963887\n",
      "train loss:0.0006656375399852304\n",
      "train loss:0.0001334221691609774\n",
      "train loss:0.0013977550621297149\n",
      "train loss:0.0003076085975487701\n",
      "train loss:0.001069146442567082\n",
      "train loss:0.0006644352663779976\n",
      "train loss:0.0009513823449862208\n",
      "train loss:0.0033043025009560152\n",
      "train loss:0.0005892665499996592\n",
      "train loss:0.0036174552456552257\n",
      "train loss:0.0022191512694251826\n",
      "train loss:0.003680544126891322\n",
      "train loss:0.00087640267557846\n",
      "train loss:0.022625151630331186\n",
      "train loss:0.0006755234765579527\n",
      "train loss:0.00022580039601494868\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9884\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from source.dataset01.mnist import load_mnist\n",
    "from source.common01.trainer import Trainer\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"pickle/cnn_params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee6f8f",
   "metadata": {},
   "source": [
    "# CNNの可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e08165",
   "metadata": {},
   "source": [
    "以下は、1層目の可視化。学習前のフィルターはランダムに初期化されているが、学習を終えたフィルターは規則性がある。<br>\n",
    "白から黒へグラデーションするフィルターや、塊のある領域（blob）を持つフィルターへ更新されている。<br>\n",
    "これは、エッジに反応するフィルターへ更新されていることを示す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9815aa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 学習前 ==========\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 学習後 ==========\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# ランダム初期化後の重み\n",
    "print(\"========== 学習前 ==========\")\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 学習後の重み\n",
    "network.load_params(\"pickle/cnn_params.pkl\")\n",
    "print(\"========== 学習後 ==========\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a60f598",
   "metadata": {},
   "source": [
    "CNNでは、層が深くなるに従って抽出される情報はより抽象化されていく。<br>\n",
    "例えば、最初の層は単純なエッジに反応し、続いてテクスチャに反応し、そしてより複雑な物体のパーツに反応するようになるといった具合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619c561",
   "metadata": {},
   "source": [
    "# 代表的なCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea930e8",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ecf36",
   "metadata": {},
   "source": [
    "![](image/08_LeNet.png)\n",
    "引用：LeCun, Yann, et al. \"Object recognition with gradient-based learning.\" Shape, contour and grouping in computer vision. Springer, Berlin, Heidelberg, 1999. 319-345."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af04984f",
   "metadata": {},
   "source": [
    "1998年に提案された、手書き数字を認識するネットワークで、初めてのCNN。<br>\n",
    "現在主流のCNNとは異なり、活性化関数はReLUではなくSigmoid、Maxプーリングではなくsubsamplingによる中間データサイズ縮小が行われている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727daa5c",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e802c4",
   "metadata": {},
   "source": [
    "LeNetと異なる点は以下。\n",
    "- 活性化関数がReLU\n",
    "- LRN（Local Response Normalization）という局所的正規化を用いる\n",
    "- Dropoutを使用する\n",
    "\n",
    "\n",
    "\n",
    "LeNetから約20年の間、ビッグデータ入手が容易になったことや、大量並列計算を得意とするGPUの普及など、コンピュータ技術に大きな進歩があった。\n",
    "AlexNetの基本構造はLeNetと大きくは変わらないが、ディープラーニングの発展の大きな原動力になった。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
