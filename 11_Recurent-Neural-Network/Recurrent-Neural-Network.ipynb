{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6806e98",
   "metadata": {},
   "source": [
    "# 再帰型ニューラルネットワーク（RNN）とは"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84195ddb",
   "metadata": {},
   "source": [
    "データが一方向だけに進む（**フィードフォワード**）構造と異なり、ループする構造を持つ。ループを展開したイメージが以下。<br>\n",
    "出力$\\mathrm{h}_{t}$は**隠れ状態**（hidden state）や**隠れ状態ベクトル**（hidden state vector）と呼ばれ、「状態」が1単位ごとに更新される。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc4bc3",
   "metadata": {},
   "source": [
    "![](RNNimage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ab3d7",
   "metadata": {},
   "source": [
    "## Truncated BPTT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a9bee",
   "metadata": {},
   "source": [
    "RNNでの誤差逆伝播法は、時間方向に展開する意味で、**BPTT**（Backpropagation Through Time）と呼ばれる。<br>\n",
    "BPTTでは、時間サイズが大きくなると逆伝播時の勾配が不安定になる問題や、各時刻の中間データを記憶するためメモリ使用量が増加する問題がある。<br><br>\n",
    "そこで、ネットワークを適当な長さで切り、それぞれの小さなネットワークに対して誤差逆伝播法を行う**Truncated BPTT**が有効。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36d3582",
   "metadata": {},
   "source": [
    "![](TruncatedBPTT.png)\n",
    "それぞれのブロックの計算には、前ブロックの最後の隠れ状態を使うため、**順伝播のつながりは維持される**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d45a2",
   "metadata": {},
   "source": [
    "## ミニバッチ学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc15a0c",
   "metadata": {},
   "source": [
    "ミニバッチ学習は、各バッチの開始位置をオフセットとしてずらし、データをシーケンシャルに与えることで可能になる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7478d7a3",
   "metadata": {},
   "source": [
    "# RNNの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b50b158",
   "metadata": {},
   "source": [
    "![](TimeRNNimage.png)\n",
    "$T$個のRNNレイヤを連結したネットワークをTime RNNレイヤとする。<br>\n",
    "RNNの1ステップの処理をRNNクラスで実装、そして$T$ステップの処理をまとめて行うレイヤをTimeRNNクラスとして実装する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35372982",
   "metadata": {},
   "source": [
    "## RNNレイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f1903",
   "metadata": {},
   "source": [
    "![](RNNlayer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e8ddd",
   "metadata": {},
   "source": [
    "RNNレイヤで行う計算は以下の数式で表されるもの。\n",
    "$$\\mathrm{h}_{t}=\\tanh \\left( \\mathrm{h}_{t-1}\\mathrm{W}_{\\mathrm{h}}+\\mathrm{x}_{t}\\mathrm{W}_{\\mathrm{x}}+\\mathrm{b}\\right)$$\n",
    "$\\mathrm{h}_{t-1}$　：時刻$t-1$における出力　$(N\\times H)$<br>\n",
    "$\\mathrm{W}_{\\mathrm{h}}$：出力を次時刻の出力に変換するための重み　$(H\\times H)$<br>\n",
    "$\\mathrm{x}_{t}$　：時刻$t$における出力　$(N\\times D)$<br>\n",
    "$\\mathrm{W}_{\\mathrm{x}}$：入力$\\mathrm{x}$を出力$\\mathrm{h}$ に変換するための重み　$(D\\times H)$<br>\n",
    "$\\mathrm{b}$　：バイアス　(ブロードキャスト)<br>\n",
    "$\\mathrm{h}_{t}$　：時刻$t$における出力　$(N\\times H)$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c99a03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b): # 引数:重みWx、Wh、バイアス\n",
    "        self.params = [Wx, Wh, b] # メンバ変数paramsにリストとして保存\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)] # 勾配を初期化しgradsに格納\n",
    "        self.cache = None # 逆伝播の計算に使用する中間データをcacheとし、Noneで初期化\n",
    "        \n",
    "    def forward(self, x, h_prev): # 下からの入力x、前RNNレイヤから受け取る入力h_prev\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b # 式の通り\n",
    "        h_next = np.tanh(t) # 式の通り\n",
    "        \n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next # 現時刻の出力（=次時刻レイヤへの入力）\n",
    "    \n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "       \n",
    "        dt = dh_next * (1 - h_next ** 2) # tanhレイヤ\n",
    "        db = np.sum(dt, axis=0) # 加算レイヤ\n",
    "        dWh = np.dot(h_prev.T, dt) # MaMulレイヤ\n",
    "        dh_prev = np.dot(dt, Wh.T)\n",
    "        dWx = np.dot(x.T, dt) # MaMulレイヤ\n",
    "        dx = np.dot(dt, Wx.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a0720",
   "metadata": {},
   "source": [
    "## TimeRNNレイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6ab8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None # RNNレイヤをリストで保持\n",
    "        \n",
    "        self.h = None # forward()時の最後のRNNレイヤの隠れ状態を保持\n",
    "        self.dh = None # backward()時のひとつ前のブロックへの隠れ状態の勾配を保持\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self,h): # 隠れ状態を設定\n",
    "        self.h = h\n",
    "        \n",
    "    def reset_state(self): # 隠れ状態をリセット\n",
    "        self.h = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape # バッチサイズN、時系列データの数T、入力ベクトルの次元数D → 形状(N, T, D)\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        \n",
    "        if not self.stateful or self.h is None: # 初回呼び出し時（self.hがNone）、メンバ変数statefulがFalseの場合\n",
    "            self.h = np.zeros((N, H), dtype='f') # hをゼロ行列でリセット\n",
    "            \n",
    "        for t in range(T): # T回RNNレイヤ\n",
    "            layer = RNN(*self.params) # RNNレイヤ生成\n",
    "            self.h = layer.forward(xs[:, t, :], self.h) # 隠れ状態を計算\n",
    "            hs[:, t, :] = self.h # hsの該当するインデックス（時刻）に設定\n",
    "            self.layers.append(layer) # メンバ変数layersに追加\n",
    "            \n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape # バッチサイズN、時系列データの数T、隠れ状態ベクトルの次元数H → 形状(N, T, H)\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)): # 順伝播とは逆順\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh) # 合算した勾配\n",
    "            dxs[:, t, :] = dx # 該当するインデックスに代入\n",
    "            \n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad # 各RNNレイヤの重みの勾配を加算\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad # 最終的な結果を上書き\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be5afd",
   "metadata": {},
   "source": [
    "# RNNLMの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4eb98e",
   "metadata": {},
   "source": [
    "RNNによる言語モデルを実装する。\n",
    "![](RNNLMimage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6bf4c7",
   "metadata": {},
   "source": [
    "## Timeレイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f21afa3",
   "metadata": {},
   "source": [
    "TimeEmbeddingレイヤとTimeAffineレイヤはレイヤを$T$個だけ用意し、個別に処理するだけ。<br>\n",
    "TimeSoftmaxWithLossレイヤでは、$L=\\dfrac{1}{T}\\left( L_{0}+L_{1}+\\ldots +L_{T-1}\\right)$の通り、それぞれの損失の平均を計算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33108018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.layers import Embedding, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f79f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.layers = None\n",
    "        self.W = W\n",
    "\n",
    "    def forward(self, xs):\n",
    "        N, T = xs.shape\n",
    "        V, D = self.W.shape\n",
    "\n",
    "        out = np.empty((N, T, D), dtype='f')\n",
    "        self.layers = []\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = Embedding(self.W)\n",
    "            out[:, t, :] = layer.forward(xs[:, t])\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, T, D = dout.shape\n",
    "\n",
    "        grad = 0\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            layer.backward(dout[:, t, :])\n",
    "            grad += layer.grads[0]\n",
    "\n",
    "        self.grads[0][...] = grad\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f305ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAffine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        rx = x.reshape(N*T, -1)\n",
    "        out = np.dot(rx, W) + b\n",
    "        self.x = x\n",
    "        return out.reshape(N, T, -1)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        x = self.x\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        dout = dout.reshape(N*T, -1)\n",
    "        rx = x.reshape(N*T, -1)\n",
    "\n",
    "        db = np.sum(dout, axis=0)\n",
    "        dW = np.dot(rx.T, dout)\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dx = dx.reshape(*x.shape)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa0b1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "        self.ignore_label = -1\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        N, T, V = xs.shape\n",
    "\n",
    "        if ts.ndim == 3:  # 教師ラベルがone-hotベクトルの場合\n",
    "            ts = ts.argmax(axis=2)\n",
    "\n",
    "        mask = (ts != self.ignore_label)\n",
    "\n",
    "        # バッチ分と時系列分をまとめる（reshape）\n",
    "        xs = xs.reshape(N * T, V)\n",
    "        ts = ts.reshape(N * T)\n",
    "        mask = mask.reshape(N * T)\n",
    "\n",
    "        ys = softmax(xs)\n",
    "        ls = np.log(ys[np.arange(N * T), ts])\n",
    "        ls *= mask  # ignore_labelに該当するデータは損失を0にする\n",
    "        loss = -np.sum(ls)\n",
    "        loss /= mask.sum()\n",
    "\n",
    "        self.cache = (ts, ys, mask, (N, T, V))\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ts, ys, mask, (N, T, V) = self.cache\n",
    "\n",
    "        dx = ys\n",
    "        dx[np.arange(N * T), ts] -= 1\n",
    "        dx *= dout\n",
    "        dx /= mask.sum()\n",
    "        dx *= mask[:, np.newaxis]  # ignore_labelに該当するデータは勾配を0にする\n",
    "\n",
    "        dx = dx.reshape((N, T, V))\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b4852",
   "metadata": {},
   "source": [
    "## SimpleRnnlmの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "262d7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 重みの初期化　（RNNとAffineにおいてXavierの初期値を利用）\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270a4b0a",
   "metadata": {},
   "source": [
    "## 言語モデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ce06e",
   "metadata": {},
   "source": [
    "言語モデルの予測性能の評価の指標として、**パープレキシティ**（perplexity）がよく用いられる。<br>\n",
    "パープレキシティは確率の逆数を表し、値は予測される候補の数と、直感的に解釈することができ、値が小さいほど良いモデルであることを示す。<br><br>\n",
    "$$L=-\\dfrac{1}{N}\\sum _{n}\\sum _{k}t_{nk}\\log y_{nk}$$<br>\n",
    "$$\\mathrm{perplexity} =e^{L}$$\n",
    "L：交差エントロピー誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9a5ac",
   "metadata": {},
   "source": [
    "## 学習の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e09a8d7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus size: 1000, vocabulary size: 418\n",
      "| epoch 1 | perplexity 386.32\n",
      "| epoch 2 | perplexity 262.50\n",
      "| epoch 3 | perplexity 225.75\n",
      "| epoch 4 | perplexity 215.18\n",
      "| epoch 5 | perplexity 206.24\n",
      "| epoch 6 | perplexity 202.35\n",
      "| epoch 7 | perplexity 198.37\n",
      "| epoch 8 | perplexity 197.43\n",
      "| epoch 9 | perplexity 191.05\n",
      "| epoch 10 | perplexity 192.99\n",
      "| epoch 11 | perplexity 188.90\n",
      "| epoch 12 | perplexity 193.12\n",
      "| epoch 13 | perplexity 190.14\n",
      "| epoch 14 | perplexity 190.06\n",
      "| epoch 15 | perplexity 189.28\n",
      "| epoch 16 | perplexity 186.37\n",
      "| epoch 17 | perplexity 184.09\n",
      "| epoch 18 | perplexity 181.40\n",
      "| epoch 19 | perplexity 183.48\n",
      "| epoch 20 | perplexity 183.97\n",
      "| epoch 21 | perplexity 182.67\n",
      "| epoch 22 | perplexity 178.71\n",
      "| epoch 23 | perplexity 176.22\n",
      "| epoch 24 | perplexity 176.76\n",
      "| epoch 25 | perplexity 173.76\n",
      "| epoch 26 | perplexity 173.48\n",
      "| epoch 27 | perplexity 170.08\n",
      "| epoch 28 | perplexity 167.00\n",
      "| epoch 29 | perplexity 163.98\n",
      "| epoch 30 | perplexity 159.24\n",
      "| epoch 31 | perplexity 164.38\n",
      "| epoch 32 | perplexity 157.13\n",
      "| epoch 33 | perplexity 156.79\n",
      "| epoch 34 | perplexity 151.94\n",
      "| epoch 35 | perplexity 152.27\n",
      "| epoch 36 | perplexity 144.66\n",
      "| epoch 37 | perplexity 140.31\n",
      "| epoch 38 | perplexity 135.96\n",
      "| epoch 39 | perplexity 130.06\n",
      "| epoch 40 | perplexity 126.54\n",
      "| epoch 41 | perplexity 125.78\n",
      "| epoch 42 | perplexity 119.93\n",
      "| epoch 43 | perplexity 112.72\n",
      "| epoch 44 | perplexity 108.59\n",
      "| epoch 45 | perplexity 104.91\n",
      "| epoch 46 | perplexity 103.36\n",
      "| epoch 47 | perplexity 96.60\n",
      "| epoch 48 | perplexity 92.29\n",
      "| epoch 49 | perplexity 87.59\n",
      "| epoch 50 | perplexity 84.52\n",
      "| epoch 51 | perplexity 79.95\n",
      "| epoch 52 | perplexity 77.40\n",
      "| epoch 53 | perplexity 72.67\n",
      "| epoch 54 | perplexity 69.45\n",
      "| epoch 55 | perplexity 65.45\n",
      "| epoch 56 | perplexity 61.97\n",
      "| epoch 57 | perplexity 59.90\n",
      "| epoch 58 | perplexity 54.33\n",
      "| epoch 59 | perplexity 52.21\n",
      "| epoch 60 | perplexity 49.41\n",
      "| epoch 61 | perplexity 47.00\n",
      "| epoch 62 | perplexity 44.54\n",
      "| epoch 63 | perplexity 40.56\n",
      "| epoch 64 | perplexity 38.79\n",
      "| epoch 65 | perplexity 36.98\n",
      "| epoch 66 | perplexity 35.51\n",
      "| epoch 67 | perplexity 33.97\n",
      "| epoch 68 | perplexity 30.07\n",
      "| epoch 69 | perplexity 29.41\n",
      "| epoch 70 | perplexity 28.75\n",
      "| epoch 71 | perplexity 27.60\n",
      "| epoch 72 | perplexity 25.03\n",
      "| epoch 73 | perplexity 23.96\n",
      "| epoch 74 | perplexity 23.21\n",
      "| epoch 75 | perplexity 21.98\n",
      "| epoch 76 | perplexity 19.54\n",
      "| epoch 77 | perplexity 18.72\n",
      "| epoch 78 | perplexity 17.63\n",
      "| epoch 79 | perplexity 16.55\n",
      "| epoch 80 | perplexity 15.59\n",
      "| epoch 81 | perplexity 14.47\n",
      "| epoch 82 | perplexity 14.55\n",
      "| epoch 83 | perplexity 12.89\n",
      "| epoch 84 | perplexity 12.42\n",
      "| epoch 85 | perplexity 11.94\n",
      "| epoch 86 | perplexity 11.06\n",
      "| epoch 87 | perplexity 10.45\n",
      "| epoch 88 | perplexity 9.60\n",
      "| epoch 89 | perplexity 9.22\n",
      "| epoch 90 | perplexity 8.71\n",
      "| epoch 91 | perplexity 8.42\n",
      "| epoch 92 | perplexity 8.71\n",
      "| epoch 93 | perplexity 7.99\n",
      "| epoch 94 | perplexity 7.63\n",
      "| epoch 95 | perplexity 6.99\n",
      "| epoch 96 | perplexity 6.98\n",
      "| epoch 97 | perplexity 6.26\n",
      "| epoch 98 | perplexity 5.86\n",
      "| epoch 99 | perplexity 5.57\n",
      "| epoch 100 | perplexity 5.36\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # 隠れ状態ベクトルの要素数\n",
    "time_size = 5  # Truncated BPTTの展開する時間サイズ\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 学習データの読み込み（データセットを小さくする）\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]  # 入力\n",
    "ts = corpus[1:]  # 出力（教師ラベル）\n",
    "data_size = len(xs)\n",
    "print('corpus size: %d, vocabulary size: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 学習時に使用する変数\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# モデルの生成\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# ミニバッチの各サンプルの読み込み開始位置を計算\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # ミニバッチの取得\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size] # コーパスサイズで割った余り\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size] # 読み込む場所がコーパスサイズを超えてしまう対策\n",
    "            time_idx += 1\n",
    "\n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # エポックごとにパープレキシティの評価\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| epoch %d | perplexity %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n",
    "\n",
    "# グラフの描画\n",
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b257c871",
   "metadata": {},
   "source": [
    "最後の方では、パープレキシティが、最小値である1に近づいている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb43714",
   "metadata": {},
   "source": [
    "## RnnlmTrainerの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fba59a",
   "metadata": {},
   "source": [
    "RNNLMの学習の際、毎回同じような長いコードを書かずに済むように、以上の学習の処理をまとめる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "008b9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnlmTrainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.time_idx = None\n",
    "        self.ppl_list = None\n",
    "        self.eval_interval = None\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def get_batch(self, x, t, batch_size, time_size):\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "\n",
    "        data_size = len(x)\n",
    "        jump = data_size // batch_size\n",
    "        offsets = [i * jump for i in range(batch_size)]  # バッチの各サンプルの読み込み開始位置\n",
    "\n",
    "        for time in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, time] = x[(offset + self.time_idx) % data_size]\n",
    "                batch_t[i, time] = t[(offset + self.time_idx) % data_size]\n",
    "            self.time_idx += 1\n",
    "        return batch_x, batch_t\n",
    "\n",
    "    def fit(self, xs, ts, max_epoch=10, batch_size=20, time_size=35,\n",
    "            max_grad=None, eval_interval=20):\n",
    "        data_size = len(xs)\n",
    "        max_iters = data_size // (batch_size * time_size)\n",
    "        self.time_idx = 0\n",
    "        self.ppl_list = []\n",
    "        self.eval_interval = eval_interval\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch):\n",
    "            for iters in range(max_iters):\n",
    "                batch_x, batch_t = self.get_batch(xs, ts, batch_size, time_size)\n",
    "\n",
    "                # 勾配を求め、パラメータを更新\n",
    "                loss = model.forward(batch_x, batch_t)\n",
    "                model.backward()\n",
    "                params, grads = remove_duplicate(model.params, model.grads)  # 共有された重みを1つに集約\n",
    "                if max_grad is not None:\n",
    "                    clip_grads(grads, max_grad)\n",
    "                optimizer.update(params, grads)\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "\n",
    "                # パープレキシティの評価\n",
    "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "                    ppl = np.exp(total_loss / loss_count)\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print('| epoch %d |  iter %d / %d | time %d[s] | perplexity %.2f'\n",
    "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, ppl))\n",
    "                    self.ppl_list.append(float(ppl))\n",
    "                    total_loss, loss_count = 0, 0\n",
    "\n",
    "            self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = numpy.arange(len(self.ppl_list))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.ppl_list, label='train')\n",
    "        plt.xlabel('iterations (x' + str(self.eval_interval) + ')')\n",
    "        plt.ylabel('perplexity')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f372c547",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 19 | time 0[s] | perplexity 417.43\n",
      "| epoch 2 |  iter 1 / 19 | time 0[s] | perplexity 363.43\n",
      "| epoch 3 |  iter 1 / 19 | time 0[s] | perplexity 259.26\n",
      "| epoch 4 |  iter 1 / 19 | time 0[s] | perplexity 223.64\n",
      "| epoch 5 |  iter 1 / 19 | time 0[s] | perplexity 212.83\n",
      "| epoch 6 |  iter 1 / 19 | time 0[s] | perplexity 209.94\n",
      "| epoch 7 |  iter 1 / 19 | time 0[s] | perplexity 201.16\n",
      "| epoch 8 |  iter 1 / 19 | time 0[s] | perplexity 200.50\n",
      "| epoch 9 |  iter 1 / 19 | time 0[s] | perplexity 195.11\n",
      "| epoch 10 |  iter 1 / 19 | time 0[s] | perplexity 190.88\n",
      "| epoch 11 |  iter 1 / 19 | time 0[s] | perplexity 192.45\n",
      "| epoch 12 |  iter 1 / 19 | time 0[s] | perplexity 189.29\n",
      "| epoch 13 |  iter 1 / 19 | time 0[s] | perplexity 192.22\n",
      "| epoch 14 |  iter 1 / 19 | time 0[s] | perplexity 186.99\n",
      "| epoch 15 |  iter 1 / 19 | time 0[s] | perplexity 185.87\n",
      "| epoch 16 |  iter 1 / 19 | time 0[s] | perplexity 189.23\n",
      "| epoch 17 |  iter 1 / 19 | time 0[s] | perplexity 187.44\n",
      "| epoch 18 |  iter 1 / 19 | time 0[s] | perplexity 182.84\n",
      "| epoch 19 |  iter 1 / 19 | time 0[s] | perplexity 179.02\n",
      "| epoch 20 |  iter 1 / 19 | time 0[s] | perplexity 179.10\n",
      "| epoch 21 |  iter 1 / 19 | time 0[s] | perplexity 176.09\n",
      "| epoch 22 |  iter 1 / 19 | time 0[s] | perplexity 175.24\n",
      "| epoch 23 |  iter 1 / 19 | time 0[s] | perplexity 176.42\n",
      "| epoch 24 |  iter 1 / 19 | time 0[s] | perplexity 174.33\n",
      "| epoch 25 |  iter 1 / 19 | time 0[s] | perplexity 166.95\n",
      "| epoch 26 |  iter 1 / 19 | time 0[s] | perplexity 168.16\n",
      "| epoch 27 |  iter 1 / 19 | time 1[s] | perplexity 165.03\n",
      "| epoch 28 |  iter 1 / 19 | time 1[s] | perplexity 165.08\n",
      "| epoch 29 |  iter 1 / 19 | time 1[s] | perplexity 158.57\n",
      "| epoch 30 |  iter 1 / 19 | time 1[s] | perplexity 154.56\n",
      "| epoch 31 |  iter 1 / 19 | time 1[s] | perplexity 154.06\n",
      "| epoch 32 |  iter 1 / 19 | time 1[s] | perplexity 146.02\n",
      "| epoch 33 |  iter 1 / 19 | time 1[s] | perplexity 145.88\n",
      "| epoch 34 |  iter 1 / 19 | time 1[s] | perplexity 143.49\n",
      "| epoch 35 |  iter 1 / 19 | time 1[s] | perplexity 135.13\n",
      "| epoch 36 |  iter 1 / 19 | time 1[s] | perplexity 132.58\n",
      "| epoch 37 |  iter 1 / 19 | time 1[s] | perplexity 134.01\n",
      "| epoch 38 |  iter 1 / 19 | time 1[s] | perplexity 120.43\n",
      "| epoch 39 |  iter 1 / 19 | time 1[s] | perplexity 118.70\n",
      "| epoch 40 |  iter 1 / 19 | time 1[s] | perplexity 114.92\n",
      "| epoch 41 |  iter 1 / 19 | time 1[s] | perplexity 109.43\n",
      "| epoch 42 |  iter 1 / 19 | time 1[s] | perplexity 108.28\n",
      "| epoch 43 |  iter 1 / 19 | time 1[s] | perplexity 102.19\n",
      "| epoch 44 |  iter 1 / 19 | time 1[s] | perplexity 99.00\n",
      "| epoch 45 |  iter 1 / 19 | time 1[s] | perplexity 92.69\n",
      "| epoch 46 |  iter 1 / 19 | time 1[s] | perplexity 88.71\n",
      "| epoch 47 |  iter 1 / 19 | time 1[s] | perplexity 86.44\n",
      "| epoch 48 |  iter 1 / 19 | time 1[s] | perplexity 83.13\n",
      "| epoch 49 |  iter 1 / 19 | time 2[s] | perplexity 80.02\n",
      "| epoch 50 |  iter 1 / 19 | time 2[s] | perplexity 72.97\n",
      "| epoch 51 |  iter 1 / 19 | time 2[s] | perplexity 71.32\n",
      "| epoch 52 |  iter 1 / 19 | time 2[s] | perplexity 66.68\n",
      "| epoch 53 |  iter 1 / 19 | time 2[s] | perplexity 63.45\n",
      "| epoch 54 |  iter 1 / 19 | time 2[s] | perplexity 59.97\n",
      "| epoch 55 |  iter 1 / 19 | time 2[s] | perplexity 56.89\n",
      "| epoch 56 |  iter 1 / 19 | time 2[s] | perplexity 53.84\n",
      "| epoch 57 |  iter 1 / 19 | time 2[s] | perplexity 53.02\n",
      "| epoch 58 |  iter 1 / 19 | time 2[s] | perplexity 48.08\n",
      "| epoch 59 |  iter 1 / 19 | time 2[s] | perplexity 45.89\n",
      "| epoch 60 |  iter 1 / 19 | time 2[s] | perplexity 42.71\n",
      "| epoch 61 |  iter 1 / 19 | time 2[s] | perplexity 40.66\n",
      "| epoch 62 |  iter 1 / 19 | time 2[s] | perplexity 38.68\n",
      "| epoch 63 |  iter 1 / 19 | time 2[s] | perplexity 36.41\n",
      "| epoch 64 |  iter 1 / 19 | time 2[s] | perplexity 34.63\n",
      "| epoch 65 |  iter 1 / 19 | time 2[s] | perplexity 32.72\n",
      "| epoch 66 |  iter 1 / 19 | time 2[s] | perplexity 30.75\n",
      "| epoch 67 |  iter 1 / 19 | time 2[s] | perplexity 28.94\n",
      "| epoch 68 |  iter 1 / 19 | time 2[s] | perplexity 26.68\n",
      "| epoch 69 |  iter 1 / 19 | time 2[s] | perplexity 26.08\n",
      "| epoch 70 |  iter 1 / 19 | time 2[s] | perplexity 24.62\n",
      "| epoch 71 |  iter 1 / 19 | time 2[s] | perplexity 22.44\n",
      "| epoch 72 |  iter 1 / 19 | time 3[s] | perplexity 21.24\n",
      "| epoch 73 |  iter 1 / 19 | time 3[s] | perplexity 20.23\n",
      "| epoch 74 |  iter 1 / 19 | time 3[s] | perplexity 18.85\n",
      "| epoch 75 |  iter 1 / 19 | time 3[s] | perplexity 17.73\n",
      "| epoch 76 |  iter 1 / 19 | time 3[s] | perplexity 16.80\n",
      "| epoch 77 |  iter 1 / 19 | time 3[s] | perplexity 16.54\n",
      "| epoch 78 |  iter 1 / 19 | time 3[s] | perplexity 15.59\n",
      "| epoch 79 |  iter 1 / 19 | time 3[s] | perplexity 14.57\n",
      "| epoch 80 |  iter 1 / 19 | time 3[s] | perplexity 13.59\n",
      "| epoch 81 |  iter 1 / 19 | time 3[s] | perplexity 13.00\n",
      "| epoch 82 |  iter 1 / 19 | time 3[s] | perplexity 12.11\n",
      "| epoch 83 |  iter 1 / 19 | time 3[s] | perplexity 11.55\n",
      "| epoch 84 |  iter 1 / 19 | time 3[s] | perplexity 11.26\n",
      "| epoch 85 |  iter 1 / 19 | time 3[s] | perplexity 10.47\n",
      "| epoch 86 |  iter 1 / 19 | time 3[s] | perplexity 10.18\n",
      "| epoch 87 |  iter 1 / 19 | time 3[s] | perplexity 9.39\n",
      "| epoch 88 |  iter 1 / 19 | time 3[s] | perplexity 9.28\n",
      "| epoch 89 |  iter 1 / 19 | time 3[s] | perplexity 8.94\n",
      "| epoch 90 |  iter 1 / 19 | time 3[s] | perplexity 8.27\n",
      "| epoch 91 |  iter 1 / 19 | time 3[s] | perplexity 7.81\n",
      "| epoch 92 |  iter 1 / 19 | time 3[s] | perplexity 7.32\n",
      "| epoch 93 |  iter 1 / 19 | time 3[s] | perplexity 7.14\n",
      "| epoch 94 |  iter 1 / 19 | time 3[s] | perplexity 6.90\n",
      "| epoch 95 |  iter 1 / 19 | time 4[s] | perplexity 6.67\n",
      "| epoch 96 |  iter 1 / 19 | time 4[s] | perplexity 6.35\n",
      "| epoch 97 |  iter 1 / 19 | time 4[s] | perplexity 5.89\n",
      "| epoch 98 |  iter 1 / 19 | time 4[s] | perplexity 5.58\n",
      "| epoch 99 |  iter 1 / 19 | time 4[s] | perplexity 5.60\n",
      "| epoch 100 |  iter 1 / 19 | time 4[s] | perplexity 5.52\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from dataset import ptb\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNNの隠れ状態ベクトルの要素数\n",
    "time_size = 5  # RNNを展開するサイズ\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 学習データの読み込み\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000  # テスト用にデータセットを小さくする\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "xs = corpus[:-1]  # 入力\n",
    "ts = corpus[1:]  # 出力（教師ラベル）\n",
    "\n",
    "# モデルの生成\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
    "trainer.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
